<!DOCTYPE html><html lang="en" class="h-full"><head><meta http-equiv="Content-Security-Policy" content="default-src 'self' 'unsafe-inline' 'unsafe-eval' data: blob: https://cdnjs.cloudflare.com https://cdn.jsdelivr.net https://code.jquery.com https://unpkg.com https://d3js.org https://threejs.org https://cdn.plot.ly https://stackpath.bootstrapcdn.com https://maps.googleapis.com https://cdn.tailwindcss.com https://ajax.googleapis.com https://kit.fontawesome.com https://cdn.datatables.net https://maxcdn.bootstrapcdn.com https://code.highcharts.com https://tako-static-assets-production.s3.amazonaws.com https://www.youtube.com https://fonts.googleapis.com https://fonts.gstatic.com https://pfst.cf2.poecdn.net https://puc.poecdn.net https://i.imgur.com https://wikimedia.org https://*.icons8.com https://*.giphy.com https://picsum.photos https://images.unsplash.com; frame-src 'self' https://www.youtube.com https://trytako.com; child-src 'self'; manifest-src 'self'; worker-src 'self'; upgrade-insecure-requests; block-all-mixed-content;">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nutanix Enterprise AI LLM Scheduling Simulator - v1</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <script>
        tailwind.config = {
            darkMode: 'class',
            theme: {
                extend: {
                    colors: {
                        primary: '#5D5CDE',
                        'primary-dark': '#4B4AB2',
                        nvidia: '#76B900',
                        meta: '#0068FF',
                        google: '#EA4335',
                        mistral: '#7C3AED',
                        ai21: '#FF6F61',
                        huggingface: '#FFD21E'
                    },
                    keyframes: {
                        float: {
                          '0%, 100%': { transform: 'translateY(0)' },
                          '50%': { transform: 'translateY(-10px)' },
                        },
                        bounce: {
                          '0%, 100%': { transform: 'translateY(0)' },
                          '50%': { transform: 'translateY(-20px)' },
                        },
                        fadeIn: {
                          '0%': { opacity: '0' },
                          '100%': { opacity: '1' },
                        },
                        scaling: {
                          '0%': { transform: 'scale(0.8)', opacity: '0.5' },
                          '100%': { transform: 'scale(1)', opacity: '1' },
                        }
                    },
                    animation: {
                        float: 'float 3s ease-in-out infinite',
                        bounce: 'bounce 1s ease-in-out infinite',
                        fadeIn: 'fadeIn 0.5s ease-in-out forwards',
                        scaling: 'scaling 0.3s ease-in-out forwards',
                    }
                }
            }
        }
    </script>
    <style>
        .node {
            transition: all 0.3s ease-in-out;
            contain: content; /* Improve paint performance */
        }
        .pod {
            transition: all 0.5s ease-in-out;
            will-change: transform, opacity; /* Hint for browser optimization */
        }
        .pending-pod {
            animation: pulse 2s infinite;
        }
        @keyframes pulse {
            0% { opacity: 0.7; }
            50% { opacity: 1; }
            100% { opacity: 0.7; }
        }
        .collapsible-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-in-out;
        }
        .collapsible-content.expanded {
            max-height: 1000px;
        }
        .pod-transition {
            transition: all 0.8s cubic-bezier(0.68, -0.55, 0.27, 1.55);
        }
        .pod-scheduling {
            animation: scheduling 2s forwards;
        }
        @keyframes scheduling {
            0% { transform: translateY(20px); opacity: 0; }
            40% { transform: translateY(-30px); opacity: 0.7; }
            60% { transform: translateY(-30px); opacity: 0.7; }
            100% { transform: translateY(0); opacity: 1; }
        }
        .resource-increment {
            animation: growWidth 1s ease-out forwards;
        }
        @keyframes growWidth {
            from { width: 0; }
        }
        .node-evaluating {
            animation: evaluating 0.5s ease-in-out;
        }
        @keyframes evaluating {
            0% { box-shadow: 0 0 0 2px rgba(93, 92, 222, 0); }
            50% { box-shadow: 0 0 0 2px rgba(93, 92, 222, 0.5); }
            100% { box-shadow: 0 0 0 2px rgba(93, 92, 222, 0); }
        }
        .node-selected {
            animation: selected 0.5s ease-in-out forwards;
        }
        @keyframes selected {
            0% { box-shadow: 0 0 0 2px rgba(93, 92, 222, 0); }
            100% { box-shadow: 0 0 0 2px rgba(93, 92, 222, 1); }
        }
        .progress-bar {
            width: 100%;
            height: 4px;
            background-color: #e2e8f0;
            overflow: hidden;
            position: relative;
        }
        .progress-bar-inner {
            height: 100%;
            background-color: #5D5CDE;
            position: absolute;
            top: 0;
            left: 0;
            animation: progressAnimation 1.5s linear infinite;
        }
        @keyframes progressAnimation {
            0% { left: -50%; width: 50%; }
            100% { left: 100%; width: 50%; }
        }
        
        /* Label with tooltip styling */
        .label-with-tooltip {
            display: flex;
            align-items: center;
            margin-bottom: 0.25rem;
        }
        
        .label-with-tooltip label {
            margin-right: 0.25rem;
        }
        
        /* Enhanced Tooltip styling */
        .tooltip {
            position: relative;
            display: inline-block;
            cursor: help;
        }
        
        .tooltip .tooltip-text {
            visibility: hidden;
            width: 280px;
            background-color: #333;
            color: #fff;
            text-align: left;
            border-radius: 6px;
            padding: 10px;
            position: absolute;
            z-index: 10;
            bottom: 125%;
            right: -10px; /* Position to the right of the icon */
            opacity: 0;
            transition: opacity 0.3s, transform 0.3s;
            font-size: 0.8rem;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
            line-height: 1.5;
            pointer-events: none;
            transform: translateY(10px);
        }
        
        /* Different position variants for tooltips */
        .tooltip.tooltip-right .tooltip-text {
            bottom: auto;
            left: 100%;
            margin-left: 10px;
            top: 50%;
            transform: translateY(-50%);
        }
        
        .tooltip.tooltip-left .tooltip-text {
            bottom: auto;
            right: 100%;
            left: auto;
            margin-right: 10px;
            top: 50%;
            transform: translateY(-50%);
        }
        
        .tooltip.tooltip-bottom .tooltip-text {
            bottom: auto;
            top: 125%;
            transform: translateY(-10px);
        }
        
        /* Arrow styling for different tooltip positions */
        .tooltip .tooltip-text::after {
            content: "";
            position: absolute;
            top: 100%;
            right: 10px; /* Align with the icon */
            border-width: 5px;
            border-style: solid;
            border-color: #333 transparent transparent transparent;
        }
        
        .tooltip.tooltip-right .tooltip-text::after {
            top: 50%;
            left: -10px;
            margin-left: 0;
            margin-top: -5px;
            border-color: transparent #333 transparent transparent;
        }
        
        .tooltip.tooltip-left .tooltip-text::after {
            top: 50%;
            right: -10px;
            left: auto;
            margin-left: 0;
            margin-top: -5px;
            border-color: transparent transparent transparent #333;
        }
        
        .tooltip.tooltip-bottom .tooltip-text::after {
            top: -10px;
            bottom: auto;
            border-color: transparent transparent #333 transparent;
        }
        
        /* Dark mode support for tooltips */
        .dark .tooltip .tooltip-text {
            background-color: #1f2937;
            color: #e2e8f0;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.4);
            border: 1px solid #374151;
        }
        
        .dark .tooltip .tooltip-text::after {
            border-color: #1f2937 transparent transparent transparent;
        }
        
        .dark .tooltip.tooltip-right .tooltip-text::after {
            border-color: transparent #1f2937 transparent transparent;
        }
        
        .dark .tooltip.tooltip-left .tooltip-text::after {
            border-color: transparent transparent transparent #1f2937;
        }
        
        .dark .tooltip.tooltip-bottom .tooltip-text::after {
            border-color: transparent transparent #1f2937 transparent;
        }
        
        .tooltip:hover .tooltip-text {
            visibility: visible;
            opacity: 1;
            transform: translateY(0);
        }
        
        .tooltip.tooltip-right:hover .tooltip-text,
        .tooltip.tooltip-left:hover .tooltip-text {
            transform: translateY(-50%);
        }
        
        .tooltip.tooltip-bottom:hover .tooltip-text {
            transform: translateY(0);
        }

        /* Improve tooltip readability and organization */
        .tooltip-title {
            display: block;
            font-weight: 600;
            margin-bottom: 5px;
            color: #9ca3af;
        }
        
        .tooltip-section {
            margin-top: 6px;
            padding-top: 6px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        .tooltip-list {
            margin-top: 4px;
            margin-bottom: 0;
            padding-left: 15px;
        }
        
        .tooltip-list li {
            margin-bottom: 3px;
        }

        /* Source badge styles */
        .source-badge {
            display: inline-flex;
            align-items: center;
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 0.7rem;
            font-weight: 600;
            margin-left: 0.5rem;
        }
        
        .source-hf {
            background-color: rgba(255, 210, 30, 0.2);
            color: #b7940b;
        }
        
        .dark .source-hf {
            background-color: rgba(255, 210, 30, 0.15);
            color: #ffd21e;
        }
        
        .source-nvidia {
            background-color: rgba(118, 185, 0, 0.2);
            color: #507c00;
        }
        
        .dark .source-nvidia {
            background-color: rgba(118, 185, 0, 0.15);
            color: #76b900;
        }
        
        /* Validated model mark */
        .validated-mark {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 16px;
            height: 16px;
            background-color: #10b981;
            color: white;
            border-radius: 50%;
            font-size: 10px;
            margin-left: 0.25rem;
        }
        
        /* CPU pod style */
        .cpu-pod {
            background-color: #6366F1 !important;
        }
        /* Extra-small text */
        .text-xxs {
            font-size: 0.65rem;
            line-height: 0.75rem;
        }
    </style>
</head>
<body class="bg-gray-100 dark:bg-gray-900 text-gray-800 dark:text-gray-200 min-h-full transition-colors duration-200">
    <div class="container mx-auto px-4 py-6">
        <h1 class="text-3xl font-bold text-center mb-6">Nutanix Enterprise AI LLM Scheduling Simulator - v1</h1>
        <p class="text-center mb-6">Visualize how LLM model deployments are scheduled across Kubernetes nodepools based on compute and GPU requirements</p>

        <div class="grid grid-cols-1 lg:grid-cols-3 gap-6">
            <!-- Model Configuration Panel -->
            <div class="lg:col-span-1 bg-white dark:bg-gray-800 rounded-lg shadow-md p-4">
                <h2 class="text-xl font-semibold mb-4 flex items-center">
                    <i class="fas fa-brain text-primary mr-2"></i> LLM Model Configuration
                </h2>
                
                <div class="space-y-4">
                    <!-- Model Filter with tooltips -->
                    <div class="flex flex-wrap gap-2 mb-2">
                        <div class="label-with-tooltip">
                            <span class="text-sm font-medium">Model Source:</span>
                            <div class="tooltip">
                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                            <span class="tooltip-text">
                                <span class="tooltip-title">Model Source Options</span>
                                Filter models by their source repository:
                                <ul class="tooltip-list">
                                    <li><strong>HuggingFace:</strong> Models from HuggingFace Hub with standard implementations</li>
                                    <li><strong>NVIDIA:</strong> Optimized models from NVIDIA NGC catalog, often with specialized containers and NIM runtime</li>
                                </ul>
                            </span>
                            </div>
                        </div>
                        <div class="flex gap-2">
                            <label class="inline-flex items-center cursor-pointer">
                                <input type="checkbox" id="show-hf" class="sr-only peer" checked="">
                                <div class="relative w-9 h-5 bg-gray-200 peer-focus:outline-none rounded-full peer dark:bg-gray-700 peer-checked:after:translate-x-full rtl:peer-checked:after:-translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:start-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-4 after:w-4 after:transition-all dark:border-gray-600 peer-checked:bg-huggingface"></div>
                                <span class="ml-2 text-sm font-medium">HuggingFace</span>
                            </label>
                            <label class="inline-flex items-center cursor-pointer">
                                <input type="checkbox" id="show-nvidia" class="sr-only peer" checked="">
                                <div class="relative w-9 h-5 bg-gray-200 peer-focus:outline-none rounded-full peer dark:bg-gray-700 peer-checked:after:translate-x-full rtl:peer-checked:after:-translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:start-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-4 after:w-4 after:transition-all dark:border-gray-600 peer-checked:bg-nvidia"></div>
                                <span class="ml-2 text-sm font-medium">NVIDIA</span>
                            </label>
                        </div>
                        <div class="flex items-center w-full">
                            <label class="inline-flex items-center cursor-pointer">
                                <input type="checkbox" id="show-validated-only" class="sr-only peer">
                                <div class="relative w-9 h-5 bg-gray-200 peer-focus:outline-none rounded-full peer dark:bg-gray-700 peer-checked:after:translate-x-full rtl:peer-checked:after:-translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:start-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-4 after:w-4 after:transition-all dark:border-gray-600 peer-checked:bg-green-500"></div>
                                <span class="ml-2 text-sm font-medium">Pre-validated only</span>
                            </label>
                            <div class="tooltip ml-1">
                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                <span class="tooltip-text">
                                    <span class="tooltip-title">Pre-validated Models</span>
                                    
                                    When enabled, only shows models that have been pre-validated for production deployments on Kubernetes.
                                    
                                    <div class="tooltip-section">
                                        Pre-validated models have undergone comprehensive testing for:
                                        <ul class="tooltip-list">
                                            <li>Stability under various load patterns</li>
                                            <li>Performance optimization for target hardware</li>
                                            <li>Resource usage accuracy</li> 
                                            <li>Compatibility with Kubernetes scheduling</li>
                                        </ul>
                                    </div>
                                </span>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Model Selection with tooltip -->
                    <div>
                        <div class="label-with-tooltip">
                            <label for="model" class="block text-sm font-medium">LLM Model</label>
                            <div class="tooltip">
                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                            <span class="tooltip-text">
                                <span class="tooltip-title">Model Selection</span>
                                Choose the LLM model to deploy. Each model has different resource requirements, capabilities, and compatibility with hardware.
                                
                                <div class="tooltip-section">
                                    <strong>Key model attributes:</strong>
                                    <ul class="tooltip-list">
                                        <li>Parameter size (B = billion)</li>
                                        <li>Storage requirements</li>
                                        <li>Context length (maximum tokens)</li>
                                        <li>Required GPU types and counts</li>
                                    </ul>
                                </div>
                                
                                <div class="tooltip-section">
                                    <strong>Model sources:</strong>
                                    <ul class="tooltip-list">
                                        <li>HF icon: Available from HuggingFace</li>
                                        <li>NGC icon: Available from NVIDIA NGC</li>
                                        <li>✓ mark: Pre-validated for production</li>
                                    </ul>
                                </div>
                            </span>
                            </div>
                        </div>
                        <div class="relative">
                            <select id="model" class="w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base appearance-none">
                                <optgroup label="HuggingFace Models">
                                    <!-- AI21 Models -->
                                    <option value="ai21labs-jamba" data-model-name="ai21labs/AI21-Jamba-1.5-Mini" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="ai21" data-developer="AI21" data-context="4K" data-categories="text-generation,chat" data-url="https://hf.co/ai21labs/AI21-Jamba-1.5-Mini" data-model-url="https://hf.co/ai21labs/AI21-Jamba-1.5-Mini" data-desc="Jamba 1.5 Mini model" data-quantization="float16" data-model-size="110">AI21/AI21-Jamba-1.5-Mini (110GB)</option>
                                    
                                    <!-- Google Models -->
                                    <option value="google-gemma-2-2b" data-model-name="google/gemma-2-2b-it" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="google" data-developer="Google" data-context="8K" data-categories="text-generation,instruction-following" data-url="https://hf.co/google/gemma-2-2b-it" data-model-url="https://hf.co/google/gemma-2-2b-it" data-desc="google gemma-2 2B instruct model" data-quantization="float16" data-model-size="10" data-size="2">Google/gemma-2-2b-it (10GB)</option>
                                    
                                    <option value="google-gemma-2-9b" data-model-name="google/gemma-2-9b-it" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="google" data-developer="Google" data-context="8K" data-categories="text-generation,instruction-following" data-url="https://hf.co/google/gemma-2-9b-it" data-model-url="https://hf.co/google/gemma-2-9b-it" data-desc="google gemma-2 9B instruct model" data-quantization="float16" data-model-size="20" data-size="9">Google/gemma-2-9b-it (20GB)</option>
                                    
                                    <!-- Mistral AI Models -->
                                    <option value="mistralai-mixtral-8x22b" data-model-name="mistralai/Mixtral-8x22B-Instruct-v0.1" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="mistral" data-developer="Mistral AI" data-context="32K" data-categories="text-generation,chat,reasoning" data-url="https://hf.co/mistralai/Mixtral-8x22B-Instruct-v0.1" data-model-url="https://hf.co/mistralai/Mixtral-8x22B-Instruct-v0.1" data-desc="mixtral 8x22B instruct v1 model" data-quantization="float16" data-model-size="290">Mistral AI/Mixtral-8x22B-Instruct-v0.1 (290GB)</option>
                                    
                                    <option value="mistralai-mixtral-8x7b" data-model-name="mistralai/Mixtral-8x7B-Instruct-v0.1" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="mistral" data-developer="Mistral AI" data-context="32K" data-categories="text-generation,chat,reasoning" data-url="https://hf.co/mistralai/Mixtral-8x7B-Instruct-v0.1" data-model-url="https://hf.co/mistralai/Mixtral-8x7B-Instruct-v0.1" data-desc="mixtral 8x7B instruct v1 model" data-quantization="float16" data-model-size="200">Mistral AI/Mixtral-8x7B-Instruct-v0.1 (200GB)</option>
                                    
                                    <option value="mistralai-nemo-instruct-2407" data-model-name="mistralai/Mistral-Nemo-Instruct-2407" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="mistral" data-developer="Mistral AI" data-context="32K" data-categories="text-generation,chat" data-url="https://hf.co/mistralai/Mistral-Nemo-Instruct-2407" data-model-url="https://hf.co/mistralai/Mistral-Nemo-Instruct-2407" data-desc="mistral nemo 12B instruct model" data-quantization="float16" data-model-size="50">Mistral AI/Mistral-Nemo-Instruct-2407 (50GB)</option>
                                    
                                    <option value="mistralai-mistral-7b" data-model-name="mistralai/Mistral-7B-Instruct-v0.3" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="mistral" data-developer="Mistral AI" data-context="32K" data-categories="text-generation,chat" data-url="https://hf.co/mistralai/Mistral-7B-Instruct-v0.3" data-model-url="https://hf.co/mistralai/Mistral-7B-Instruct-v0.3" data-desc="mistral 7B instruct v0.3 model" data-quantization="float16" data-model-size="30" data-size="7">Mistral AI/Mistral-7B-Instruct-v0.3 (30GB)</option>
                                    
                                    <!-- Meta CodeLlama Models -->
                                    <option value="meta-codellama-70b" data-model-name="meta-llama/CodeLlama-70b-Instruct-hf" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="16K" data-categories="coding,code-generation,code-completion" data-url="https://hf.co/meta-llama/CodeLlama-70b-Instruct-hf" data-model-url="https://hf.co/meta-llama/CodeLlama-70b-Instruct-hf" data-desc="codellama 70B HF instruct model" data-quantization="float16" data-model-size="280">Meta/CodeLlama-70b-Instruct-hf (280GB)</option>
                                    
                                    <option value="meta-codellama-34b" data-model-name="meta-llama/CodeLlama-34b-Instruct-hf" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="16K" data-categories="coding,code-generation,code-completion" data-url="https://hf.co/meta-llama/CodeLlama-34b-Instruct-hf" data-model-url="https://hf.co/meta-llama/CodeLlama-34b-Instruct-hf" data-desc="codellama 34B HF instruct model" data-quantization="float16" data-model-size="140">Meta/CodeLlama-34b-Instruct-hf (140GB)</option>
                                    
                                    <option value="meta-codellama-13b" data-model-name="meta-llama/CodeLlama-13b-Instruct-hf" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="16K" data-categories="coding,code-generation" data-url="https://hf.co/meta-llama/CodeLlama-13b-Instruct-hf" data-model-url="https://hf.co/meta-llama/CodeLlama-13b-Instruct-hf" data-desc="codellama 13B HF instruct model" data-quantization="float16" data-model-size="60">Meta/CodeLlama-13b-Instruct-hf (60GB)</option>
                                    
                                    <option value="meta-codellama-7b" data-model-name="meta-llama/CodeLlama-7b-Instruct-hf" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="16K" data-categories="coding,code-generation" data-url="https://hf.co/meta-llama/CodeLlama-7b-Instruct-hf" data-model-url="https://hf.co/meta-llama/CodeLlama-7b-Instruct-hf" data-desc="codellama 7B HF instruct model" data-quantization="float16" data-model-size="30" data-size="7">Meta/CodeLlama-7b-Instruct-hf (30GB)</option>
                                    
                                    <!-- Meta Llama Models -->
                                    <option value="meta-llama-2-13b" data-model-name="meta-llama/Llama-2-13b-chat-hf" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="4K" data-categories="text-generation,chat" data-url="https://hf.co/meta-llama/Llama-2-13b-chat-hf" data-model-url="https://hf.co/meta-llama/Llama-2-13b-chat-hf" data-desc="llama2 13B HF Chat model" data-quantization="float16" data-model-size="60">Meta/Llama-2-13b-chat-hf (60GB)</option>
                                    
                                    <option value="meta-llama-3-2-1b" data-model-name="meta-llama/Llama-3.2-1B-Instruct" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="8K" data-categories="text-generation,chat" data-url="https://hf.co/meta-llama/Llama-3.2-1B-Instruct" data-model-url="https://hf.co/meta-llama/Llama-3.2-1B-Instruct" data-desc="Llama-3.2 1B HF Instruct model" data-quantization="float16" data-model-size="10" data-size="1">Meta/Llama-3.2-1B-Instruct (10GB)</option>
                                    
                                    <option value="meta-llama-3-2-3b" data-model-name="meta-llama/Llama-3.2-3B-Instruct" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="8K" data-categories="text-generation,chat" data-url="https://hf.co/meta-llama/Llama-3.2-3B-Instruct" data-model-url="https://hf.co/meta-llama/Llama-3.2-3B-Instruct" data-desc="Llama-3.2 3B HF Instruct model" data-quantization="float16" data-model-size="20" data-size="3">Meta/Llama-3.2-3B-Instruct (20GB)</option>
                                    
                                    <option value="meta-llama-3-1-8b" data-model-name="meta-llama/Meta-Llama-3.1-8B-Instruct" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="128K" data-categories="text-generation,chat,reasoning" data-url="https://hf.co/meta-llama/Meta-Llama-3.1-8B-Instruct" data-model-url="https://hf.co/meta-llama/Meta-Llama-3.1-8B-Instruct" data-desc="Llama-3.1 8B HF Instruct model" data-quantization="float16" data-model-size="40" data-size="8">Meta/Meta-Llama-3.1-8B-Instruct (40GB)</option>
                                    
                                    <option value="meta-llama-3-1-70b" data-model-name="meta-llama/Meta-Llama-3.1-70B-Instruct" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="128K" data-categories="text-generation,chat,reasoning" data-url="https://hf.co/meta-llama/Meta-Llama-3.1-70B-Instruct" data-model-url="https://hf.co/meta-llama/Meta-Llama-3.1-70B-Instruct" data-desc="Llama-3.1 70B HF Instruct model" data-quantization="float16" data-model-size="290" selected>Meta/Meta-Llama-3.1-70B-Instruct (290GB)</option>
                                    
                                    <option value="meta-llama-3-3-70b" data-model-name="meta-llama/Llama-3.3-70B-Instruct" data-model-type="Text Generation" data-source="hf" data-source-hub="HuggingFace" data-validated="true" data-provider="meta" data-developer="Meta" data-context="256K" data-categories="text-generation,chat,reasoning" data-url="https://hf.co/meta-llama/Llama-3.3-70B-Instruct" data-model-url="https://hf.co/meta-llama/Llama-3.3-70B-Instruct" data-desc="Llama-3.3 70B HF Instruct model" data-quantization="float16" data-model-size="290">Meta/Llama-3.3-70B-Instruct (290GB)</option>
                                </optgroup>
                                <optgroup label="NVIDIA NGC Catalog">
                                    <!-- NVIDIA Text Generation Models -->
                                    <option value="nvidia-llama-3-3-70b" data-model-name="Llama-3.3-70b-instruct" data-model-type="Text Generation" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="true" data-provider="nvidia" data-developer="NVIDIA" data-context="256K" data-categories="text-generation,chat,reasoning" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.3-70b-instruct" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.3-70b-instruct" data-desc="Llama-3.3-70b-instruct NIM model" data-quantization="bf16" data-model-size="160">NVIDIA/Llama-3.3-70b-instruct (160GB)</option>
                                    
                                    <option value="nvidia-llama-3-1-70b" data-model-name="Llama-3.1-70b-instruct" data-model-type="Text Generation" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="true" data-provider="nvidia" data-developer="NVIDIA" data-context="128K" data-categories="text-generation,chat" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.1-70b-instruct" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.1-70b-instruct" data-desc="Llama-3.1-70b-instruct NIM model" data-quantization="fp8" data-model-size="160">NVIDIA/Llama-3.1-70b-instruct (160GB)</option>
                                    
                                    <option value="nvidia-llama-3-1-8b" data-model-name="llama-3.1-8b-instruct" data-model-type="Text Generation" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="true" data-provider="nvidia" data-developer="NVIDIA" data-context="128K" data-categories="text-generation,chat" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.1-8b-instruct" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.1-8b-instruct" data-desc="Llama-3.1-8b-instruct NIM model" data-quantization="fp8" data-model-size="50">NVIDIA/llama-3.1-8b-instruct (50GB)</option>
                                    
                                    <option value="nvidia-mixtral-8x7b" data-model-name="Mixtral-8x7B-Instruct-v0.1" data-model-type="Text Generation" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="true" data-provider="nvidia" data-developer="NVIDIA" data-context="32K" data-categories="text-generation,chat" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/mistralai/containers/mixtral-8x7b-instruct-v01" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/mistralai/containers/mixtral-8x7b-instruct-v01" data-desc="Mixtral-8x7B-Instruct-v0.1 NIM model" data-quantization="fp8" data-model-size="110">NVIDIA/Mixtral-8x7B-Instruct-v0.1 (110GB)</option>
                                    
                                    <!-- NVIDIA Special Purpose Models -->
                                    <option value="nvidia-llama-3-1-nemoguard-8b-safety" data-model-name="Llama-3.1-nemoguard-8b-content-safety" data-model-type="Safety" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="true" data-provider="nvidia" data-developer="NVIDIA" data-context="128K" data-categories="safety" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.1-nemoguard-8b-content-safety" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.1-nemoguard-8b-content-safety" data-desc="Llama-3.1-nemoguard-8b-content-safety NIM model" data-quantization="bf16" data-model-size="50">NVIDIA/Llama-3.1-nemoguard-8b-content-safety (50GB)</option>
                                    
                                    <option value="nvidia-llama-3-2-nv-embed" data-model-name="Llama-3.2-nv-embedqa-1b-v2" data-model-type="Embedding" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="true" data-provider="nvidia" data-developer="NVIDIA" data-context="8K" data-categories="embedding" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.2-nv-embedqa-1b-v2" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.2-nv-embedqa-1b-v2" data-desc="Llama-3.2-nv-embedqa-1b-v2 NIM model" data-quantization="fp8" data-model-size="5">NVIDIA/Llama-3.2-nv-embedqa-1b-v2 (5GB)</option>
                                    
                                    <option value="nvidia-llama-3-2-nv-reranker" data-model-name="Llama-3.2-nv-rerankqa-1b-v2" data-model-type="Reranker" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="true" data-provider="nvidia" data-developer="NVIDIA" data-context="8K" data-categories="reranker" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.2-nv-rerankqa-1b-v2" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.2-nv-rerankqa-1b-v2" data-desc="Llama-3.2-nv-rerankqa-1b-v2 NIM model" data-quantization="fp16" data-model-size="5">NVIDIA/Llama-3.2-nv-rerankqa-1b-v2 (5GB)</option>
                                    
                                    <!-- Non-validated models below -->
                                    <option value="nvidia-llama-3-1-70b-pb24b2" data-model-name="Llama-3.1-70b-instruct-pb24h2" data-model-type="Text Generation" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="false" data-provider="nvidia" data-developer="NVIDIA" data-context="128K" data-categories="text-generation,chat" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.1-70b-instruct-pb24h2" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.1-70b-instruct-pb24h2" data-desc="Llama-3.1-70b-instruct-pb24h2 NIM model" data-quantization="fp8" data-model-size="160">NVIDIA/Llama-3.1-70b-instruct-pb24h2 (160GB)</option>
                                    
                                    <option value="nvidia-llama3-8b" data-model-name="Llama3-8b-instruct" data-model-type="Text Generation" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="false" data-provider="nvidia" data-developer="NVIDIA" data-context="128K" data-categories="text-generation,chat" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama3-8b-instruct" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama3-8b-instruct" data-desc="Llama3-8b-instruct NIM model" data-quantization="fp8" data-model-size="50">NVIDIA/Llama3-8b-instruct (50GB)</option>
                                    
                                    <option value="nvidia-llama-3-1-nemoguard-8b-topic" data-model-name="Llama-3.1-nemoguard-8b-topic-control" data-model-type="Safety" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="false" data-provider="nvidia" data-developer="NVIDIA" data-context="128K" data-categories="safety" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.1-nemoguard-8b-topic-control" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.1-nemoguard-8b-topic-control" data-desc="Llama-3.1-nemoguard-8b-topic-control NIM model" data-quantization="bf16" data-model-size="50">NVIDIA/Llama-3.1-nemoguard-8b-topic-control (50GB)</option>
                                    
                                    <option value="nvidia-llama-3-1-nemotron" data-model-name="Llama-3.1-nemotron-70b-instruct" data-model-type="Text Generation" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="false" data-provider="nvidia" data-developer="NVIDIA" data-context="128K" data-categories="text-generation,chat" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.1-nemotron-70b-instruct" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.1-nemotron-70b-instruct" data-desc="Llama-3.1-nemotron-70b-instruct NIM model" data-quantization="fp8" data-model-size="160">NVIDIA/Llama-3.1-nemotron-70b-instruct (160GB)</option>
                                    
                                    <option value="nvidia-mistral-nemo-12b" data-model-name="Mistral-nemo-12b-instruct" data-model-type="Text Generation" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="false" data-provider="nvidia" data-developer="NVIDIA" data-context="32K" data-categories="text-generation,chat" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nv-mistralai/containers/mistral-nemo-12b-instruct" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nv-mistralai/containers/mistral-nemo-12b-instruct" data-desc="Mistral-nemo-12b-instruct" data-quantization="fp8" data-model-size="80">NVIDIA/Mistral-nemo-12b-instruct (80GB)</option>
                                    
                                    <option value="nvidia-arctic-embed" data-model-name="Arctic-embed-l" data-model-type="Embedding" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="false" data-provider="nvidia" data-developer="NVIDIA" data-context="512" data-categories="embedding" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/snowflake/containers/arctic-embed-l" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/snowflake/containers/arctic-embed-l" data-desc="Arctic-embed-l NIM model" data-quantization="fp8" data-model-size="20">NVIDIA/Arctic-embed-l (20GB)</option>
                                    
                                    <option value="nvidia-nv-embedqa" data-model-name="Nv-embedqa-e5-v5" data-model-type="Embedding" data-source="nvidia" data-source-hub="NvidiaNIM" data-validated="false" data-provider="nvidia" data-developer="NVIDIA" data-context="512" data-categories="embedding" data-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/nv-embedqa-e5-v5" data-model-url="https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/nv-embedqa-e5-v5" data-desc="Nv-embedqa-e5-v5 NIM model" data-quantization="fp8" data-model-size="5">NVIDIA/Nv-embedqa-e5-v5 (5GB)</option>
                                </optgroup>
                            </select>
                            <div id="model-icon" class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                <i class="fab fa-facebook text-meta"></i>
                            </div>
                            <div class="absolute inset-y-0 right-0 pr-3 flex items-center pointer-events-none">
                                <i class="fas fa-chevron-down text-gray-400"></i>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Model Card -->
                    <div id="model-card" class="model-card bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-3 flex flex-col overflow-hidden">
                        <!-- Model card content will be dynamically generated -->
                    </div>

                    <!-- CPU Only Toggle with enhanced tooltip -->
                    <div id="cpu-only-section" class="hidden">
                        <div class="flex justify-between items-center py-2 px-3 bg-blue-50 dark:bg-blue-900/30 rounded-lg border border-blue-200 dark:border-blue-800">
                            <div class="flex items-center">
                                <i class="fas fa-microchip text-blue-600 dark:text-blue-400 mr-2"></i>
                                <span class="font-medium text-sm">CPU-Only Deployment</span>
                                <div class="tooltip ml-1">
                                    <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                    <span class="tooltip-text">
                                        <span class="tooltip-title">CPU-Only Deployment</span>
                                        Deploy small models (typically &lt; 10B parameters) on CPU-only nodes for cost efficiency.
                                        
                                        <div class="tooltip-section">
                                            <strong>Benefits:</strong>
                                            <ul class="tooltip-list">
                                                <li>Lower infrastructure cost</li>
                                                <li>Wider availability in cloud environments</li>
                                                <li>Simplified scaling for low-traffic use cases</li>
                                            </ul>
                                        </div>
                                        
                                        <div class="tooltip-section">
                                            <strong>Trade-offs:</strong>
                                            <ul class="tooltip-list">
                                                <li>Significantly slower inference speeds</li>
                                                <li>Limited to smaller models</li>
                                                <li>Higher latency with concurrent requests</li>
                                            </ul>
                                        </div>
                                    </span>
                                </div>
                            </div>
                            <label class="inline-flex items-center cursor-pointer">
                                <input type="checkbox" id="cpu-only-toggle" class="sr-only peer">
                                <div class="relative w-9 h-5 bg-gray-200 peer-focus:outline-none rounded-full peer dark:bg-gray-700 peer-checked:after:translate-x-full rtl:peer-checked:after:-translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:start-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-4 after:w-4 after:transition-all dark:border-gray-600 peer-checked:bg-blue-600"></div>
                            </label>
                        </div>
                    </div>

                    <!-- CPU Resource Settings with tooltips -->
                    <div id="cpu-resource-section" class="hidden space-y-4">
                        <div>
                            <div class="label-with-tooltip">
                                <label for="cpu-count" class="block text-sm font-medium">CPU Cores</label>
                                <div class="tooltip">
                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                <span class="tooltip-text">
                                    <span class="tooltip-title">CPU Cores for CPU-Only Deployment</span>
                                    Number of CPU cores allocated to the model deployment.
                                    
                                    <div class="tooltip-section">
                                        <strong>Guidelines:</strong>
                                        <ul class="tooltip-list">
                                            <li>1-2B parameter models: 2-4 cores</li>
                                            <li>3-7B parameter models: 4-8 cores</li>
                                            <li>8-10B parameter models: 8-16 cores</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="tooltip-section">
                                        Higher core count increases concurrent request handling, but has diminishing returns for single request latency beyond the model's recommended minimum.
                                    </div>
                                </span>
                                </div>
                            </div>
                            <div class="relative">
                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                    <i class="fas fa-microchip text-blue-500"></i>
                                </div>
                                <input type="number" id="cpu-count" min="1" max="32" value="4" class="w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base">
                            </div>
                        </div>
                        <div>
                            <div class="label-with-tooltip">
                                <label for="memory-size" class="block text-sm font-medium">Memory Size (GB)</label>
                                <div class="tooltip">
                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                <span class="tooltip-text">
                                    <span class="tooltip-title">Memory for CPU-Only Deployment</span>
                                    Amount of RAM allocated to the model deployment.
                                    
                                    <div class="tooltip-section">
                                        <strong>Memory requirements:</strong>
                                        <ul class="tooltip-list">
                                            <li>1-2B parameter models: 8-16 GB</li>
                                            <li>3-7B parameter models: 16-32 GB</li>
                                            <li>8-10B parameter models: 32-64 GB</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="tooltip-section">
                                        Insufficient memory will cause the model to crash or experience severe performance degradation. Always allocate enough memory to load the full model plus overhead for input/output and runtime operations.
                                    </div>
                                </span>
                                </div>
                            </div>
                            <div class="relative">
                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                    <i class="fas fa-memory text-green-500"></i>
                                </div>
                                <input type="number" id="memory-size" min="2" max="64" value="16" class="w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base">
                            </div>
                        </div>
                    </div>

                    <!-- Inference Engine with tooltip -->
                    <div id="inference-engine-section">
                        <div class="label-with-tooltip">
                            <label for="inference-engine" class="block text-sm font-medium">Inference Engine</label>
                            <div class="tooltip">
                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                            <span class="tooltip-text">
                                <span class="tooltip-title">Inference Engine</span>
                                Software framework that executes the model and handles inference requests.
                                
                                <div class="tooltip-section">
                                    <strong>Available engines:</strong>
                                    <ul class="tooltip-list">
                                        <li><strong>TGI:</strong> Text Generation Inference - Good stability, supports advanced features like LoRA</li>
                                        <li><strong>vLLM:</strong> Optimized for high throughput and continuous batching with PagedAttention</li>
                                        <li><strong>NVIDIA NIM:</strong> NVIDIA's optimized inference microservices for NVIDIA models</li>
                                    </ul>
                                </div>
                                
                                <div class="tooltip-section">
                                    Each engine has different resource needs, throughput characteristics, and feature support.
                                </div>
                            </span>
                            </div>
                        </div>
                        <div class="relative">
                            <select id="inference-engine" class="w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base appearance-none">
                                <option value="tgi">Text Generation Inference (TGI)</option>
                                <option value="vllm" selected="">vLLM</option>
                            </select>
                            <div id="engine-icon" class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                <i class="fas fa-bolt text-yellow-500"></i>
                            </div>
                            <div class="absolute inset-y-0 right-0 pr-3 flex items-center pointer-events-none">
                                <i class="fas fa-chevron-down text-gray-400"></i>
                            </div>
                        </div>
                    </div>

                    <!-- GPU Type with tooltip -->
                    <div id="gpu-type-section">
                        <div class="label-with-tooltip">
                            <label for="gpu-type" class="block text-sm font-medium">GPU Device Type</label>
                            <div class="tooltip">
                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                            <span class="tooltip-text">
                                <span class="tooltip-title">GPU Device Type</span>
                                The GPU hardware used for model inference. Different models have different compatibility and performance characteristics across GPU types.
                                
                                <div class="tooltip-section">
                                    <strong>Available GPU types:</strong>
                                    <ul class="tooltip-list">
                                        <li><strong>A100-80G:</strong> High performance, 80GB VRAM, good for most models up to 70B</li>
                                        <li><strong>H100-80G:</strong> Latest generation, 80GB VRAM, best performance for all models</li>
                                        <li><strong>L40S-48G:</strong> Mid-tier, 48GB VRAM, economical for models up to 13B</li> 
                                        <li><strong>H100-NVL-94G:</strong> Enhanced H100 with 94GB VRAM, highest capacity for large models</li>
                                    </ul>
                                </div>
                                
                                <div class="tooltip-section">
                                    Larger models require more GPU memory. The list shows only GPUs compatible with your selected model.
                                </div>
                            </span>
                            </div>
                        </div>
                        <div class="relative">
                            <select id="gpu-type" class="w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base appearance-none">
                                <option value="A100-80G">NVIDIA A100-80G</option>
                                <option value="H100-80G" selected="">NVIDIA H100-80G</option>
                                <option value="L40S-48G">NVIDIA L40S-48G</option>
                                <option value="H100-NVL-94G">NVIDIA H100 NVL-94G</option>
                            </select>
                            <div id="gpu-icon" class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                <i class="fas fa-microchip text-green-500"></i>
                            </div>
                            <div class="absolute inset-y-0 right-0 pr-3 flex items-center pointer-events-none">
                                <i class="fas fa-chevron-down text-gray-400"></i>
                            </div>
                        </div>
                    </div>

                    <!-- Advanced Resource Settings with enhanced tooltips -->
                    <div id="advanced-settings-section" class="bg-gray-50 dark:bg-gray-700 rounded-md p-2">
                        <button id="advanced-toggle" class="flex justify-between items-center w-full text-left text-sm font-medium text-gray-700 dark:text-gray-300 focus:outline-none">
                            <span><i class="fas fa-sliders-h mr-2"></i>Advanced Resource Settings</span>
                            <div class="flex items-center">
                                <div class="tooltip mr-2">
                                    <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                    <span class="tooltip-text tooltip-left">
                                        <span class="tooltip-title">Advanced Resource Settings</span>
                                        Fine-tune resource allocation for specialized deployment scenarios.
                                        
                                        <div class="tooltip-section">
                                            <strong>Settings include:</strong>
                                            <ul class="tooltip-list">
                                                <li>GPU count override for multi-GPU scaling</li>
                                                <li>Engine-specific resource multipliers</li>
                                                <li>Custom tuning for different inference engines</li>
                                            </ul>
                                        </div>
                                        
                                        <div class="tooltip-section">
                                            For most deployments, the default settings are recommended. Advanced settings are useful for special cases like high-concurrency workloads or memory-optimized configurations.
                                        </div>
                                    </span>
                                </div>
                                <i id="advanced-icon" class="fas fa-chevron-down"></i>
                            </div>
                        </button>
                        <div id="advanced-content" class="collapsible-content mt-2">
                            <!-- Override GPU count dropdown with tooltip -->
                            <div class="mb-3">
                                <div class="flex justify-between items-center">
                                    <div class="label-with-tooltip">
                                        <label for="override-gpu-select" class="block text-xs font-medium">Override GPU Count</label>
                                        <div class="tooltip">
                                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                            <span class="tooltip-text">
                                                <span class="tooltip-title">GPU Count Override</span>
                                                Manually set the number of GPUs used for model deployment, overriding the model's default recommendation.
                                                
                                                <div class="tooltip-section">
                                                    <strong>Key considerations:</strong>
                                                    <ul class="tooltip-list">
                                                        <li>Higher GPU counts improve throughput for high concurrency workloads</li>
                                                        <li>Some models require minimum GPU counts based on model size</li>
                                                        <li>Using more GPUs than needed wastes resources</li>
                                                        <li>Using fewer GPUs than recommended can cause OOM errors</li>
                                                    </ul>
                                                </div>
                                                
                                                <div class="tooltip-section">
                                                    The dropdown shows only GPU counts that are technically feasible for the selected model and GPU type.
                                                </div>
                                            </span>
                                        </div>
                                    </div>
                                    <label class="inline-flex items-center cursor-pointer">
                                        <input type="checkbox" id="gpu-override-toggle" class="sr-only peer">
                                        <div class="relative w-9 h-5 bg-gray-200 peer-focus:outline-none rounded-full peer dark:bg-gray-700 peer-checked:after:translate-x-full rtl:peer-checked:after:-translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:start-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-4 after:w-4 after:transition-all dark:border-gray-600 peer-checked:bg-primary"></div>
                                    </label>
                                </div>
                                <div class="flex items-center mt-1">
                                    <select id="override-gpu-select" class="w-full px-3 py-1 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-sm disabled:opacity-50 disabled:cursor-not-allowed appearance-none" disabled="">
                                        <option value="1">1 GPU</option>
                                        <option value="2" selected="">2 GPUs</option>
                                        <option value="4">4 GPUs</option>
                                        <option value="8">8 GPUs</option>
                                    </select>
                                </div>
                            </div>
                            
                            <!-- Inference Engine Resource Multipliers with tooltip -->
                            <div>
                                <div class="flex justify-between items-center mb-2">
                                    <h4 class="text-xs uppercase text-gray-500 dark:text-gray-400 font-semibold">
                                    Engine Resource Multipliers
                                    </h4>
                                    <div class="tooltip">
                                        <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                        <span class="tooltip-text tooltip-left">
                                            <span class="tooltip-title">Engine Resource Multipliers</span>
                                            Fine-tune how resource requirements are calculated based on the inference engine.
                                            
                                            <div class="tooltip-section">
                                                <strong>How it works:</strong> Base Resource × Engine Multiplier = Final Resource Requirement
                                            </div>
                                            
                                            <div class="tooltip-section">
                                                <strong>Example:</strong> If a model needs 10 CPU cores and you use vLLM with a 1.2 multiplier, the final requirement will be 12 CPU cores.
                                            </div>
                                            
                                            <div class="tooltip-section">
                                                <strong>Typical multiplier ranges:</strong>
                                                <ul class="tooltip-list">
                                                    <li><strong>TGI:</strong> CPU: 0.8-1.0, Memory: 1.0-1.2</li>
                                                    <li><strong>vLLM:</strong> CPU: 1.0-1.5, Memory: 1.2-1.8</li>
                                                    <li><strong>NVIDIA NIM:</strong> CPU: 0.7-1.0, Memory: 0.7-1.0</li>
                                                </ul>
                                            </div>
                                        </span>
                                    </div>
                                </div>
                                
                                <!-- TGI Engine -->
                                <div class="bg-white dark:bg-gray-800 rounded p-2 mb-2">
                                    <div class="flex items-center justify-between mb-1">
                                        <div class="flex items-center">
                                        <i class="fab fa-hubspot text-blue-500 mr-2"></i>
                                        <span class="text-xs font-medium">TGI</span>
                                        </div>
                                        <div class="tooltip">
                                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                            <span class="tooltip-text tooltip-left">
                                                <span class="tooltip-title">TGI Resource Multipliers</span>
                                                Text Generation Inference typically has moderate resource requirements.
                                                
                                                <div class="tooltip-section">
                                                    <strong>Recommended settings:</strong>
                                                    <ul class="tooltip-list">
                                                        <li>CPU: 0.8-1.0 (less CPU-intensive)</li>
                                                        <li>Memory: 1.0-1.2 (standard memory usage)</li>
                                                    </ul>
                                                </div>
                                            </span>
                                        </div>
                                    </div>
                                    <div class="grid grid-cols-2 gap-2">
                                        <div>
                                            <label for="tgi-cpu" class="block text-xs mb-1">CPU</label>
                                            <input type="number" id="tgi-cpu" min="0.1" max="5" step="0.1" value="1.0" class="w-full px-2 py-1 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-sm">
                                        </div>
                                        <div>
                                            <label for="tgi-memory" class="block text-xs mb-1">Memory</label>
                                            <input type="number" id="tgi-memory" min="0.1" max="5" step="0.1" value="1.0" class="w-full px-2 py-1 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-sm">
                                        </div>
                                    </div>
                                </div>
                                
                                <!-- vLLM Engine -->
                                <div class="bg-white dark:bg-gray-800 rounded p-2 mb-2">
                                    <div class="flex items-center justify-between mb-1">
                                        <div class="flex items-center">
                                        <i class="fas fa-bolt text-yellow-500 mr-2"></i>
                                        <span class="text-xs font-medium">vLLM</span>
                                        </div>
                                        <div class="tooltip">
                                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                            <span class="tooltip-text tooltip-left">
                                                <span class="tooltip-title">vLLM Resource Multipliers</span>
                                                vLLM uses PagedAttention and requires more resources for optimal performance.
                                                
                                                <div class="tooltip-section">
                                                    <strong>Recommended settings:</strong>
                                                    <ul class="tooltip-list">
                                                        <li>CPU: 1.2-1.5 (higher for KV cache management)</li>
                                                        <li>Memory: 1.3-1.8 (needs extra memory for paging)</li>
                                                    </ul>
                                                </div>
                                            </span>
                                        </div>
                                    </div>
                                    <div class="grid grid-cols-2 gap-2">
                                        <div>
                                            <label for="vllm-cpu" class="block text-xs mb-1">CPU</label>
                                            <input type="number" id="vllm-cpu" min="0.1" max="5" step="0.1" value="1.2" class="w-full px-2 py-1 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-sm">
                                        </div>
                                        <div>
                                            <label for="vllm-memory" class="block text-xs mb-1">Memory</label>
                                            <input type="number" id="vllm-memory" min="0.1" max="5" step="0.1" value="1.5" class="w-full px-2 py-1 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-sm">
                                        </div>
                                    </div>
                                </div>
                                
                                <!-- NVIDIA NIM Engine -->
                                <div class="bg-white dark:bg-gray-800 rounded p-2 opacity-50">
                                    <div class="flex items-center justify-between mb-1">
                                        <div class="flex items-center">
                                        <i class="fas fa-microchip text-nvidia mr-2"></i>
                                        <span class="text-xs font-medium">NVIDIA NIM</span>
                                        <span class="ml-2 text-xs text-gray-500">(NVIDIA models only)</span>
                                        </div>
                                        <div class="tooltip">
                                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                            <span class="tooltip-text tooltip-left">
                                                <span class="tooltip-title">NVIDIA NIM Resource Multipliers</span>
                                                NVIDIA's optimized inference microservices often use less resources due to optimizations.
                                                
                                                <div class="tooltip-section">
                                                    <strong>Recommended settings:</strong>
                                                    <ul class="tooltip-list">
                                                        <li>CPU: 0.7-0.9 (highly optimized CPU usage)</li>
                                                        <li>Memory: 0.7-0.9 (memory-efficient implementations)</li>
                                                    </ul>
                                                </div>
                                                
                                                <div class="tooltip-section">
                                                    Only available for NVIDIA-sourced models from NGC catalog.
                                                </div>
                                            </span>
                                        </div>
                                    </div>
                                    <div class="grid grid-cols-2 gap-2">
                                        <div>
                                            <label for="nim-cpu" class="block text-xs mb-1">CPU</label>
                                            <input type="number" id="nim-cpu" min="0.1" max="5" step="0.1" value="0.8" class="w-full px-2 py-1 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-sm" disabled="">
                                        </div>
                                        <div>
                                            <label for="nim-memory" class="block text-xs mb-1">Memory</label>
                                            <input type="number" id="nim-memory" min="0.1" max="5" step="0.1" value="0.8" class="w-full px-2 py-1 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-sm" disabled="">
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Number of Pods with tooltip -->
                    <div>
                        <div class="label-with-tooltip">
                            <label for="replicas" class="block text-sm font-medium">Number of Pods</label>
                            <div class="tooltip">
                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                            <span class="tooltip-text">
                                <span class="tooltip-title">Number of Pods (Replicas)</span>
                                The number of identical model instances to deploy across the cluster.
                                
                                <div class="tooltip-section">
                                    <strong>When to use multiple pods:</strong>
                                    <ul class="tooltip-list">
                                        <li>Horizontal scaling for high throughput</li>
                                        <li>High availability and fault tolerance</li>
                                        <li>Geographic distribution (when simulating multiple clusters)</li>
                                    </ul>
                                </div>
                                
                                <div class="tooltip-section">
                                    <strong>Performance impact:</strong> Each pod requires its own dedicated resources. Multiple pods provide linear throughput scaling but don't improve single-request latency.
                                </div>
                            </span>
                            </div>
                        </div>
                        <div class="relative">
                            <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                <i class="fas fa-cubes text-gray-500"></i>
                            </div>
                            <input type="number" id="replicas" min="1" max="10" value="1" class="w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base">
                        </div>
                    </div>

                    <!-- Deploy Button with tooltip -->
                    <div>
                        <button id="deploy-btn" class="w-full bg-primary hover:bg-primary-dark text-white font-semibold py-2 px-4 rounded transition-colors relative overflow-hidden group">
                            <span class="relative z-10 flex items-center justify-center">
                                <i class="fas fa-rocket mr-2 group-hover:animate-bounce"></i>
                                <span id="deploy-text">Deploy Model</span>
                            </span>
                            <span class="absolute top-0 left-0 w-0 h-full bg-primary-dark group-hover:w-full transition-all duration-300 ease-in-out"></span>
                        </button>
                        <div class="flex justify-end mt-1">
                            <div class="tooltip">
                            <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                            <span class="tooltip-text tooltip-bottom">
                                <span class="tooltip-title">Deploy Model</span>
                                Deploy the configured model to the Kubernetes cluster with the specified resources.
                                
                                <div class="tooltip-section">
                                    <strong>The deployment process:</strong>
                                    <ul class="tooltip-list">
                                        <li>Calculate exact resource requirements</li>
                                        <li>Create Kubernetes pod specifications</li>
                                        <li>Schedule pods based on available node resources</li>
                                        <li>Track deployment status and resource allocation</li>
                                    </ul>
                                </div>
                                
                                <div class="tooltip-section">
                                    Pods will be placed on nodes with sufficient resources and compatible GPU types. If resources are insufficient, pods will be placed in a pending state.
                                </div>
                            </span>
                            </div>
                        </div>
                        <!-- Hidden progress bar (shown during deployment) -->
                        <div id="deploy-progress" class="hidden mt-2">
                            <div class="progress-bar">
                                <div class="progress-bar-inner"></div>
                            </div>
                            <div class="text-xs text-center mt-1 text-primary-dark dark:text-primary" id="deploy-status">Scheduling pods...</div>
                        </div>
                    </div>

                    <!-- Resource Requirements with enhanced tooltip -->
                    <div class="mt-4 p-3 bg-gray-100 dark:bg-gray-700 rounded-md border-l-4 border-primary">
                        <div class="flex justify-between items-center mb-2">
                            <h3 class="font-medium flex items-center">
                            <i class="fas fa-calculator text-primary mr-2"></i>
                            Pod Resource Requirements:
                            </h3>
                            <div class="tooltip">
                                <i class="fas fa-info-circle text-gray-400 text-sm"></i>
                                <span class="tooltip-text tooltip-left">
                                    <span class="tooltip-title">Resource Calculation Method</span>
                                    
                                    <div class="tooltip-section">
                                        <strong>Base requirements are determined by:</strong>
                                        <ul class="tooltip-list">
                                            <li>Model size and architecture</li>
                                            <li>Selected GPU type compatibility</li> 
                                            <li>Inference engine optimization profile</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="tooltip-section">
                                        <strong>Final requirements:</strong>
                                        <ul class="tooltip-list">
                                            <li>CPU: Base CPU × Engine Multiplier</li>
                                            <li>Memory: Base Memory × Engine Multiplier</li> 
                                            <li>GPUs: Either default for model/GPU or override value</li>
                                            <li>Storage: Fixed requirement based on model size</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="tooltip-section">
                                        These requirements determine where pods can be scheduled in the cluster and how many can run simultaneously.
                                    </div>
                                </span>
                            </div>
                        </div>
                        <div class="text-sm space-y-1">
                            <p>
                                <i class="fas fa-memory text-blue-500 mr-1"></i>
                                CPU: <span id="req-cpu" class="font-semibold">16</span> cores
                            </p>
                            <p>
                                <i class="fas fa-database text-green-500 mr-1"></i>
                                Memory: <span id="req-memory" class="font-semibold">64</span> GB
                            </p>
                            <p id="gpu-requirement">
                                <i class="fas fa-microchip text-purple-500 mr-1"></i>
                                GPU: <span id="req-gpu" class="font-semibold">2</span> × <span id="req-gpu-type" class="font-semibold">NVIDIA H100-80G</span>
                            </p>
                            <p id="cpu-only-indicator" class="hidden">
                                <i class="fas fa-microchip text-blue-500 mr-1"></i>
                                <span class="text-blue-600 dark:text-blue-400 font-semibold">CPU-Only Deployment</span> <span class="text-xs text-gray-500 dark:text-gray-400">(No GPU required)</span>
                            </p>
                            <p>
                                <i class="fas fa-hdd text-yellow-500 mr-1"></i>
                                Storage: <span id="req-storage" class="font-semibold">290</span> GB
                            </p>
                            <p id="inference-engine-display">
                                <i class="fas fa-bolt text-yellow-500 mr-1"></i>
                                Engine: <span id="req-engine" class="font-semibold">vLLM</span>
                            </p>
                            <p id="context-length-display">
                                <i class="fas fa-align-left text-purple-500 mr-1"></i>
                                Context Length: <span id="req-context" class="font-semibold">128K</span>
                            </p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Cluster Visualization Panel -->
            <div class="lg:col-span-2">
                <div class="bg-white dark:bg-gray-800 rounded-lg shadow-md p-4 h-full">
                    <div class="flex justify-between items-center mb-4">
                        <h2 class="text-xl font-semibold flex items-center">
                            <i class="fas fa-server text-primary mr-2"></i> Cluster Visualization
                        </h2>
                        <div class="flex space-x-2">
                            <button id="simulate-btn" class="bg-green-500 hover:bg-green-600 text-white px-3 py-1 rounded text-sm flex items-center transition duration-150">
                                <i class="fas fa-play mr-1"></i> Simulate
                                <div class="tooltip ml-1">
                                    <i class="fas fa-info-circle text-white text-xs"></i>
                                    <span class="tooltip-text tooltip-bottom">
                                        <span class="tooltip-title">Simulate Scheduling</span>
                                        Visualize how the Kubernetes scheduler evaluates nodes and places pods based on resource requirements and constraints.
                                        
                                        <div class="tooltip-section">
                                            The simulation demonstrates the core scheduling principles:
                                            <ul class="tooltip-list">
                                                <li>Resource availability evaluation</li>
                                                <li>Node selection algorithm</li>
                                                <li>Pod placement decisions</li>
                                            </ul>
                                        </div>
                                    </span>
                                </div>
                            </button>
                            <button id="reset-btn" class="bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 px-3 py-1 rounded text-sm flex items-center transition duration-150">
                                <i class="fas fa-redo-alt mr-1"></i> Reset Cluster
                                <div class="tooltip ml-1">
                                    <i class="fas fa-info-circle text-gray-500 dark:text-gray-400 text-xs"></i>
                                    <span class="tooltip-text tooltip-bottom">
                                        <span class="tooltip-title">Reset Cluster</span>
                                        Clear all scheduled and pending pods from the cluster, resetting all node resources to their initial state.
                                        
                                        <div class="tooltip-section">
                                            This is equivalent to deleting all workloads while keeping the node infrastructure intact.
                                        </div>
                                    </span>
                                </div>
                            </button>
                        </div>
                    </div>
                    
                    <!-- Node Pool Management -->
                    <div class="mb-6">
                        <div class="flex justify-between items-center mb-2">
                            <h3 class="text-lg font-medium flex items-center">
                                <i class="fas fa-server text-primary mr-2"></i> Node Pool Management
                                <div class="tooltip ml-1">
                                    <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                    <span class="tooltip-text">
                                        <span class="tooltip-title">Node Pool Management</span>
                                        Configure groups of similar compute nodes (node pools) to create your Kubernetes cluster infrastructure.
                                        
                                        <div class="tooltip-section">
                                            <strong>Node pools allow you to:</strong>
                                            <ul class="tooltip-list">
                                                <li>Create heterogeneous clusters with different hardware types</li>
                                                <li>Separate workloads based on resource requirements</li>
                                                <li>Simulate real-world Kubernetes deployments</li>
                                            </ul>
                                        </div>
                                        
                                        <div class="tooltip-section">
                                            Each node pool defines a set of identical nodes with the same CPU, memory, GPU type, and count.
                                        </div>
                                    </span>
                                </div>
                            </h3>
                            <button id="add-nodepool-btn" class="bg-green-500 hover:bg-green-600 text-white px-3 py-1 rounded text-sm flex items-center transition duration-150">
                                <i class="fas fa-plus mr-1"></i> Add Node Pool
                                <div class="tooltip ml-1">
                                    <i class="fas fa-info-circle text-white text-xs"></i>
                                    <span class="tooltip-text tooltip-left">
                                        <span class="tooltip-title">Add Node Pool</span>
                                        Create a new group of compute nodes with custom specifications.
                                        
                                        <div class="tooltip-section">
                                            <strong>Common node pool types:</strong>
                                            <ul class="tooltip-list">
                                                <li>High-memory pools for memory-intensive workloads</li>
                                                <li>GPU pools with different GPU models</li>
                                                <li>CPU-only pools for smaller models or support services</li>
                                            </ul>
                                        </div>
                                    </span>
                                </div>
                            </button>
                        </div>
                        
                        <!-- Node Pools Container -->
                        <div id="node-pools-container">
                            <!-- Node Pool 1 with tooltips -->
                            <div class="node-pool bg-white dark:bg-gray-800 rounded-md border border-gray-300 dark:border-gray-600 p-3 mb-4" data-pool-id="1">
                                <div class="flex justify-between items-center mb-3">
                                    <div class="flex items-center">
                                        <div class="bg-blue-100 dark:bg-blue-900 p-2 rounded-md mr-2">
                                            <i class="fas fa-layer-group text-blue-500 dark:text-blue-400"></i>
                                        </div>
                                        <div>
                                            <h4 class="font-medium">Node Pool 1</h4>
                                            <p class="text-xs text-gray-500 dark:text-gray-400">Default compute node pool</p>
                                        </div>
                                    </div>
                                    <div class="flex items-center">
                                        <button class="text-gray-400 hover:text-red-500 dark:text-gray-500 dark:hover:text-red-400 ml-2 remove-nodepool-btn" data-pool-id="1" disabled="">
                                            <i class="fas fa-trash"></i>
                                            <div class="tooltip ml-1">
                                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                                <span class="tooltip-text tooltip-left">
                                                    The default node pool cannot be removed.
                                                </span>
                                            </div>
                                        </button>
                                        <button class="text-gray-500 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-200 ml-2 toggle-nodepool-btn" data-pool-id="1">
                                            <i class="fas fa-chevron-down"></i>
                                        </button>
                                    </div>
                                </div>
                                <div class="node-pool-content">
                                    <div class="grid grid-cols-1 md:grid-cols-3 gap-4">
                                        <div>
                                            <div class="label-with-tooltip">
                                                <label class="block text-sm font-medium">Number of Nodes</label>
                                                <div class="tooltip">
                                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                                <span class="tooltip-text tooltip-right">
                                                    <span class="tooltip-title">Number of Nodes</span>
                                                    Total count of identical nodes in this pool.
                                                    
                                                    <div class="tooltip-section">
                                                        Each node represents a physical or virtual machine with its own CPU, memory, and GPU resources. Higher node counts provide more total cluster capacity for running model deployments.
                                                    </div>
                                                </span>
                                                </div>
                                            </div>
                                            <div class="relative">
                                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                                    <i class="fas fa-server text-gray-500"></i>
                                                </div>
                                                <input type="number" class="node-count w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="3" min="1" max="10">
                                            </div>
                                        </div>
                                        <div>
                                            <div class="label-with-tooltip">
                                                <label class="block text-sm font-medium">GPUs per Node</label>
                                                <div class="tooltip">
                                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                                <span class="tooltip-text tooltip-right">
                                                    <span class="tooltip-title">GPUs per Node</span>
                                                    Number of GPU devices available on each node in this pool.
                                                    
                                                    <div class="tooltip-section">
                                                        <strong>Common configurations:</strong>
                                                        <ul class="tooltip-list">
                                                            <li>0: CPU-only nodes</li>
                                                            <li>1-2: Entry-level GPU nodes</li>
                                                            <li>4-8: High-performance computing nodes</li>
                                                        </ul>
                                                    </div>
                                                    
                                                    <div class="tooltip-section">
                                                        The scheduler will ensure models requiring N GPUs are placed on nodes with at least N available GPUs.
                                                    </div>
                                                </span>
                                                </div>
                                            </div>
                                            <div class="relative">
                                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                                    <i class="fas fa-microchip text-gray-500"></i>
                                                </div>
                                                <input type="number" class="node-gpu-count w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="2" min="0" max="8">
                                            </div>
                                        </div>
                                        <div>
                                            <div class="label-with-tooltip">
                                                <label class="block text-sm font-medium">GPU Device Type</label>
                                                <div class="tooltip">
                                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                                <span class="tooltip-text tooltip-right">
                                                    <span class="tooltip-title">GPU Device Type</span>
                                                    The specific GPU hardware model for nodes in this pool.
                                                    
                                                    <div class="tooltip-section">
                                                        <strong>Options:</strong>
                                                        <ul class="tooltip-list">
                                                            <li><strong>A100-80G:</strong> High performance, 80GB VRAM</li>
                                                            <li><strong>H100-80G:</strong> Latest generation, 80GB VRAM</li>
                                                            <li><strong>L40S-48G:</strong> Mid-tier, 48GB VRAM</li>
                                                            <li><strong>H100-NVL-94G:</strong> Enhanced H100 with 94GB VRAM</li>
                                                            <li><strong>CPU-Only:</strong> No GPUs attached</li>
                                                        </ul>
                                                    </div>
                                                    
                                                    <div class="tooltip-section">
                                                        The scheduler ensures models are only placed on nodes with compatible GPU types.
                                                    </div>
                                                </span>
                                                </div>
                                            </div>
                                            <div class="relative">
                                                <select class="node-gpu-type w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base appearance-none">
                                                    <option value="A100-80G">NVIDIA A100-80G</option>
                                                    <option value="H100-80G" selected="">NVIDIA H100-80G</option>
                                                    <option value="L40S-48G">NVIDIA L40S-48G</option>
                                                    <option value="H100-NVL-94G">NVIDIA H100 NVL-94G</option>
                                                    <option value="CPU-Only">CPU-Only Nodes</option>
                                                </select>
                                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                                    <i class="fas fa-layer-group text-green-500"></i>
                                                </div>
                                                <div class="absolute inset-y-0 right-0 pr-3 flex items-center pointer-events-none">
                                                    <i class="fas fa-chevron-down text-gray-400"></i>
                                                </div>
                                            </div>
                                        </div>
                                        <div>
                                            <div class="label-with-tooltip">
                                                <label class="block text-sm font-medium">CPU Cores per Node</label>
                                                <div class="tooltip">
                                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                                <span class="tooltip-text tooltip-right">
                                                    <span class="tooltip-title">CPU Cores per Node</span>
                                                    Number of CPU cores available on each node in this pool.
                                                    
                                                    <div class="tooltip-section">
                                                        <strong>Recommendations:</strong>
                                                        <ul class="tooltip-list">
                                                            <li>CPU-only nodes: 16-64 cores</li>
                                                            <li>GPU nodes: 32-128 cores</li>
                                                        </ul>
                                                    </div>
                                                    
                                                    <div class="tooltip-section">
                                                        LLM inference is often CPU-bound for token generation. Sufficient CPU cores are needed for preprocessing, postprocessing, and managing concurrent requests.
                                                    </div>
                                                </span>
                                                </div>
                                            </div>
                                            <div class="relative">
                                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                                    <i class="fas fa-memory text-gray-500"></i>
                                                </div>
                                                <input type="number" class="node-cpu w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="32" min="2" max="128">
                                            </div>
                                        </div>
                                        <div>
                                            <div class="label-with-tooltip">
                                                <label class="block text-sm font-medium">Memory per Node (GB)</label>
                                                <div class="tooltip">
                                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                                <span class="tooltip-text tooltip-right">
                                                    <span class="tooltip-title">Memory per Node</span>
                                                    Amount of RAM available on each node in this pool, measured in gigabytes.
                                                    
                                                    <div class="tooltip-section">
                                                        <strong>Recommendations:</strong>
                                                        <ul class="tooltip-list">
                                                            <li>CPU-only nodes: 32-256 GB</li>
                                                                <li>GPU nodes: 64-512 GB</li>
                                                        </ul>
                                                    </div>
                                                    
                                                    <div class="tooltip-section">
                                                            While GPU memory holds the model weights, system RAM is needed for input/output processing, batching, and the inference engine runtime.
                                                    </div>
                                                </span>
                                                </div>
                                            </div>
                                            <div class="relative">
                                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                                    <i class="fas fa-database text-gray-500"></i>
                                                </div>
                                                <input type="number" class="node-memory w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="128" min="8" max="512">
                                            </div>
                                        </div>
                                        <div>
                                            <div class="label-with-tooltip">
                                                <label class="block text-sm font-medium">Node Pool Label</label>
                                                <div class="tooltip">
                                                <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                                <span class="tooltip-text tooltip-right">
                                                    <span class="tooltip-title">Node Pool Label</span>
                                                        Optional label to identify this node pool for node selection.
                                                    
                                                    <div class="tooltip-section">
                                                            <strong>Common labels:</strong>
                                                        <ul class="tooltip-list">
                                                            <li><code>gpu-pool</code>: General GPU nodes</li>
                                                            <li><code>cpu-pool</code>: CPU-only nodes</li>
                                                            <li><code>high-memory</code>: Memory-optimized nodes</li>
                                                            <li><code>a100-pool</code>: For specific GPU type</li>
                                                        </ul>
                                                    </div>
                                                    
                                                    <div class="tooltip-section">
                                                            Labels can be used with node affinity/anti-affinity rules to control which workloads run on which nodes.
                                                    </div>
                                                </span>
                                                </div>
                                            </div>
                                            <div class="relative">
                                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                                    <i class="fas fa-tag text-gray-500"></i>
                                                </div>
                                                <input type="text" class="node-pool-label w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="default" placeholder="e.g., gpu-pool, cpu-pool">
                                            </div>
                                        </div>
                                    </div>
                                    <div class="mt-3 text-sm text-gray-500 dark:text-gray-400 flex items-center">
                                        <i class="fas fa-info-circle mr-2"></i> Total: <span class="node-pool-summary ml-1 font-medium">3 nodes, 6 GPUs, 96 CPU cores, 384 GB memory</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Update Cluster button with tooltip -->
                        <button id="update-nodes-btn" class="bg-primary hover:bg-primary-dark text-white font-semibold py-2 px-4 rounded transition-colors">
                            <i class="fas fa-sync-alt mr-1"></i> Update Cluster
                            <div class="tooltip ml-1">
                                <i class="fas fa-info-circle text-white text-xs"></i>
                                <span class="tooltip-text tooltip-top">
                                    <span class="tooltip-title">Update Cluster</span>
                                    Apply all node pool configuration changes to the cluster.
                                    
                                    <div class="tooltip-section">
                                        <strong>This will:</strong>
                                        <ul class="tooltip-list">
                                            <li>Create or remove nodes based on updated settings</li>
                                            <li>Preserve pod deployments where possible</li>
                                            <li>Attempt to reschedule pods if their nodes are removed</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="tooltip-section">
                                        Pods may become pending if the updated cluster doesn't have sufficient resources or compatible GPU types.
                                    </div>
                                </span>
                            </div>
                        </button>
                    </div>

                    <!-- Scheduler Animation Area -->
                    <div id="scheduler-animation" class="mb-4 hidden">
                        <div class="flex justify-between items-center mb-2">
                            <h3 class="font-medium flex items-center">
                                <i class="fas fa-magic text-primary mr-2"></i> Scheduler Animation
                            </h3>
                            <span class="text-xs text-gray-500">Watch the Kubernetes scheduler in action</span>
                        </div>
                        <div class="border border-gray-200 dark:border-gray-700 rounded-lg p-3 relative min-h-16 flex items-center justify-center">
                            <div id="animation-container" class="flex items-center justify-center">
                                <div id="pod-template" class="w-16 h-16 bg-meta text-white rounded-lg flex flex-col items-center justify-center mr-6 shadow-lg animate-float optimize-gpu">
                                    <i class="fab fa-facebook text-2xl"></i>
                                    <span class="text-xs mt-1">llama-3-1-70b</span>
                                </div>
                                <div class="text-2xl mx-4 text-primary animate-pulse">→</div>
                                <div class="relative flex space-x-6">
                                    <div class="node-box w-20 h-24 border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg flex flex-col items-center justify-center p-1 transition-all duration-300">
                                        <div class="text-xs text-gray-500 dark:text-gray-400 font-medium">Node 1</div>
                                        <i class="fas fa-microchip text-green-500 text-xl my-1"></i>
                                        <div class="w-full h-2 bg-gray-200 dark:bg-gray-700 rounded mt-1">
                                            <div class="h-full bg-green-500 rounded" style="width: 50%"></div>
                                        </div>
                                        <div class="mt-1 text-xs">1/2 GPU</div>
                                    </div>
                                    <div class="node-box w-20 h-24 border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg flex flex-col items-center justify-center p-1 transition-all duration-300">
                                        <div class="text-xs text-gray-500 dark:text-gray-400 font-medium">Node 2</div>
                                        <i class="fas fa-microchip text-green-500 text-xl my-1"></i>
                                        <div class="w-full h-2 bg-gray-200 dark:bg-gray-700 rounded mt-1">
                                            <div class="h-full bg-green-500 rounded" style="width: 50%"></div>
                                        </div>
                                        <div class="mt-1 text-xs">1/2 GPU</div>
                                    </div>
                                    <div class="node-box w-20 h-24 border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg flex flex-col items-center justify-center p-1 transition-all duration-300">
                                        <div class="text-xs text-gray-500 dark:text-gray-400 font-medium">Node 3</div>
                                        <i class="fas fa-microchip text-green-500 text-xl my-1"></i>
                                        <div class="w-full h-2 bg-gray-200 dark:bg-gray-700 rounded mt-1">
                                            <div class="h-full bg-green-500 rounded" style="width: 0%"></div>
                                        </div>
                                        <div class="mt-1 text-xs">0/2 GPU</div>
                                    </div>
                                </div>
                            </div>
                            <div id="scheduling-status" class="absolute bottom-1 right-2 text-xs font-medium text-primary"></div>
                        </div>
                    </div>

                    <!-- Cluster Visualization -->
                    <div id="cluster-visualization" class="border border-gray-300 dark:border-gray-600 rounded-lg p-4">
                        <!-- Nodes container with tooltip -->
                        <div id="nodes-container" class="space-y-4">
                            <!-- Nodes will be dynamically generated here -->
                            <div class="tooltip w-full flex justify-center mb-4">
                                <i class="fas fa-info-circle text-gray-400 text-sm"></i>
                                <span class="tooltip-text">
                                    <span class="tooltip-title">Cluster Visualization</span>
                                    This area shows all nodes in the cluster and their current resource usage.
                                    
                                    <div class="tooltip-section">
                                        <strong>Node components:</strong>
                                        <ul class="tooltip-list">
                                            <li>Node ID and hardware type</li>
                                            <li>Resource utilization bars (CPU, Memory, GPU)</li>
                                            <li>Deployed pods with provider and resource information</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="tooltip-section">
                                        <strong>Interactions:</strong>
                                        <ul class="tooltip-list">
                                            <li>Click on a pod's × button to delete it</li>
                                            <li>Deploy models using the configuration panel</li>
                                            <li>Reset the cluster to clear all pods</li>
                                        </ul>
                                    </div>
                                </span>
                            </div>
                        </div>
                        
                        <!-- Pending Pods Section with tooltip -->
                        <div id="pending-pods-container" class="mt-6 border-t border-gray-300 dark:border-gray-600 pt-4 hidden">
                            <h3 class="text-lg font-medium mb-2 flex items-center">
                                <i class="fas fa-hourglass-half mr-2 text-yellow-500"></i> Pending Pods
                                <div class="tooltip ml-1">
                                    <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                                    <span class="tooltip-text">
                                        <span class="tooltip-title">Pending Pods</span>
                                        Pods that couldn't be scheduled due to insufficient cluster resources.
                                        
                                        <div class="tooltip-section">
                                            <strong>Common reasons for pending status:</strong>
                                            <ul class="tooltip-list">
                                                <li>Not enough available GPUs on any node</li>
                                                <li>Incompatible GPU types across all nodes</li>
                                                <li>Insufficient CPU or memory resources</li>
                                                <li>Special hardware requirements not met</li>
                                            </ul>
                                        </div>
                                        
                                        <div class="tooltip-section">
                                            To resolve pending pods, you can:
                                            <ul class="tooltip-list">
                                                <li>Add more nodes to the cluster</li>
                                                <li>Increase resources on existing nodes</li>
                                                <li>Delete other pods to free up resources</li>
                                                <li>Modify the model configuration to use fewer resources</li>
                                            </ul>
                                        </div>
                                    </span>
                                </div>
                            </h3>
                            <div id="pending-pods" class="flex flex-wrap gap-2">
                                <!-- Pending pods will be dynamically generated here -->
                            </div>
                            <div id="pending-info" class="mt-2 text-xs text-yellow-600 dark:text-yellow-400 bg-yellow-50 dark:bg-yellow-900/30 p-2 rounded flex items-start">
                                <i class="fas fa-exclamation-triangle mr-2 mt-0.5"></i>
                                <span>These pods can't be scheduled due to insufficient GPU resources. Consider updating the node pool configuration or reducing GPU requirements.</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Console Output with tooltip -->
        <div class="mt-6 bg-gray-900 text-gray-100 p-4 rounded-lg shadow-md">
            <div class="flex justify-between items-center mb-2">
                <h3 class="font-mono text-lg flex items-center">
                    <i class="fas fa-terminal mr-2 text-green-400"></i> Console Output
                    <div class="tooltip ml-1">
                        <i class="fas fa-info-circle text-gray-400 text-xs"></i>
                        <span class="tooltip-text tooltip-bottom">
                            <span class="tooltip-title">Console Output</span>
                            Displays log messages and scheduling events from the simulator.
                            
                            <div class="tooltip-section">
                                <strong>Output modes:</strong>
                                <ul class="tooltip-list">
                                    <li><strong>Standard Mode:</strong> Chronological event logs with timestamps</li>
                                    <li><strong>Text UI Mode:</strong> Structured textual view of cluster state</li>
                                </ul>
                            </div>
                            
                            <div class="tooltip-section">
                                Use the console to track scheduling decisions, resource allocations, and error conditions.
                            </div>
                        </span>
                    </div>
                </h3>
                <div class="flex space-x-2">
                    <button id="toggle-console-mode" class="px-2 py-1 bg-blue-600 hover:bg-blue-700 text-white text-xs rounded transition-colors flex items-center">
                        <i class="fas fa-code mr-1"></i> Standard Mode
                    </button>
                    <button id="clear-console" class="px-2 py-1 bg-red-600 hover:bg-red-700 text-white text-xs rounded transition-colors flex items-center">
                        <i class="fas fa-trash-alt mr-1"></i> Clear
                    </button>
                </div>
            </div>
            <div id="console-output" class="text-sm bg-black p-3 rounded font-mono h-64 overflow-y-auto"></div>
        </div>
        
        <!-- Testing Examples Section -->
        <div class="mt-6">
            <div class="flex justify-between items-center mb-4">
                <h2 class="text-2xl font-semibold flex items-center">
                    <i class="fas fa-flask text-primary mr-2"></i> Testing Examples
                </h2>
                <div class="flex items-center">
                    <span class="text-sm text-gray-600 dark:text-gray-400 mr-2">Click a test to view its details or apply it</span>
                    <button id="collapse-all-tests" class="px-2 py-1 text-xs bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 rounded transition-colors flex items-center">
                        <i class="fas fa-compress-alt mr-1"></i> Collapse All
                    </button>
                </div>
            </div>
            
            <div class="grid grid-cols-1 lg:grid-cols-4 gap-4" id="testing-examples-container">
                <!-- Left side: Test Cards -->
                <div class="lg:col-span-1">
                    <div class="space-y-2">
                        <!-- Test 1: CPU-Only Model -->
                        <div id="cpu-only-test-card" class="test-select-card bg-white dark:bg-gray-800 rounded-lg shadow p-3 cursor-pointer border-l-4 border-blue-500 dark:border-blue-600 hover:bg-blue-50 dark:hover:bg-blue-900/20 transition duration-150" data-test-id="cpu-only-test">
                            <div class="flex items-center justify-between">
                                <h3 class="font-medium flex items-center">
                                    <i class="fas fa-microchip text-blue-500 mr-2"></i> CPU-Only Model
                                </h3>
                                <div class="flex items-center space-x-1">
                                    <button class="apply-test-btn px-2 py-1 bg-primary hover:bg-primary-dark text-white text-xs rounded transition-colors flex items-center" data-test-id="cpu-only-test">
                                        <i class="fas fa-cog mr-1"></i> Apply
                                    </button>
                                    <button class="run-simulation-btn px-2 py-1 bg-green-500 hover:bg-green-600 text-white text-xs rounded transition-colors flex items-center" data-test-id="cpu-only-test">
                                        <i class="fas fa-play mr-1"></i> Run
                                    </button>
                                </div>
                            </div>
                            <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Gemma 2B on CPU nodes</p>
                        </div>

                        <!-- Test 2: Large GPU Model -->
                        <div id="large-gpu-test-card" class="test-select-card bg-white dark:bg-gray-800 rounded-lg shadow p-3 cursor-pointer border-l-4 border-green-500 dark:border-green-600 hover:bg-green-50 dark:hover:bg-green-900/20 transition duration-150 selected" data-test-id="large-gpu-test">
                            <div class="flex items-center justify-between">
                                <h3 class="font-medium flex items-center">
                                    <i class="fas fa-microchip text-green-500 mr-2"></i> Large GPU Model
                                </h3>
                                <div class="flex items-center space-x-1">
                                    <button class="apply-test-btn px-2 py-1 bg-primary hover:bg-primary-dark text-white text-xs rounded transition-colors flex items-center" data-test-id="large-gpu-test">
                                        <i class="fas fa-cog mr-1"></i> Apply
                                    </button>
                                    <button class="run-simulation-btn px-2 py-1 bg-green-500 hover:bg-green-600 text-white text-xs rounded transition-colors flex items-center" data-test-id="large-gpu-test">
                                        <i class="fas fa-play mr-1"></i> Run
                                    </button>
                                </div>
                            </div>
                            <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Llama 70B on H100 GPUs</p>
                        </div>

                        <!-- Test 3: GPU Compatibility -->
                        <div id="gpu-compatibility-test-card" class="test-select-card bg-white dark:bg-gray-800 rounded-lg shadow p-3 cursor-pointer border-l-4 border-yellow-500 dark:border-yellow-600 hover:bg-yellow-50 dark:hover:bg-yellow-900/20 transition duration-150" data-test-id="gpu-compatibility-test">
                            <div class="flex items-center justify-between">
                                <h3 class="font-medium flex items-center">
                                    <i class="fas fa-exclamation-triangle text-yellow-500 mr-2"></i> GPU Compatibility
                                </h3>
                                <div class="flex items-center space-x-1">
                                    <button class="apply-test-btn px-2 py-1 bg-primary hover:bg-primary-dark text-white text-xs rounded transition-colors flex items-center" data-test-id="gpu-compatibility-test">
                                        <i class="fas fa-cog mr-1"></i> Apply
                                    </button>
                                    <button class="run-simulation-btn px-2 py-1 bg-green-500 hover:bg-green-600 text-white text-xs rounded transition-colors flex items-center" data-test-id="gpu-compatibility-test">
                                        <i class="fas fa-play mr-1"></i> Run
                                    </button>
                                </div>
                            </div>
                            <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Hardware compatibility testing</p>
                        </div>

                        <!-- Test 4: Advanced Settings (MoE Models) -->
                        <div id="moe-model-test-card" class="test-select-card bg-white dark:bg-gray-800 rounded-lg shadow p-3 cursor-pointer border-l-4 border-purple-500 dark:border-purple-600 hover:bg-purple-50 dark:hover:bg-purple-900/20 transition duration-150" data-test-id="moe-model-test">
                            <div class="flex items-center justify-between">
                                <h3 class="font-medium flex items-center">
                                    <i class="fas fa-sitemap text-purple-500 mr-2"></i> MoE Model
                                </h3>
                                <div class="flex items-center space-x-1">
                                    <button class="apply-test-btn px-2 py-1 bg-primary hover:bg-primary-dark text-white text-xs rounded transition-colors flex items-center" data-test-id="moe-model-test">
                                        <i class="fas fa-cog mr-1"></i> Apply
                                    </button>
                                    <button class="run-simulation-btn px-2 py-1 bg-green-500 hover:bg-green-600 text-white text-xs rounded transition-colors flex items-center" data-test-id="moe-model-test">
                                        <i class="fas fa-play mr-1"></i> Run
                                    </button>
                                </div>
                            </div>
                            <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Mixtral 8x7B with advanced settings</p>
                        </div>

                        <!-- Test 5: Mixed Workload -->
                        <div id="mixed-workload-test-card" class="test-select-card bg-white dark:bg-gray-800 rounded-lg shadow p-3 cursor-pointer border-l-4 border-red-500 dark:border-red-600 hover:bg-red-50 dark:hover:bg-red-900/20 transition duration-150" data-test-id="mixed-workload-test">
                            <div class="flex items-center justify-between">
                                <h3 class="font-medium flex items-center">
                                    <i class="fas fa-layer-group text-red-500 mr-2"></i> Mixed Workload
                                </h3>
                                <div class="flex items-center space-x-1">
                                    <button class="apply-test-btn px-2 py-1 bg-primary hover:bg-primary-dark text-white text-xs rounded transition-colors flex items-center" data-test-id="mixed-workload-test">
                                        <i class="fas fa-cog mr-1"></i> Apply
                                    </button>
                                    <button class="run-simulation-btn px-2 py-1 bg-green-500 hover:bg-green-600 text-white text-xs rounded transition-colors flex items-center" data-test-id="mixed-workload-test">
                                        <i class="fas fa-play mr-1"></i> Run
                                    </button>
                                </div>
                            </div>
                            <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Multiple model types and node pools</p>
                        </div>

                        <!-- Test 6: Resource Constraints -->
                        <div id="resource-constraints-test-card" class="test-select-card bg-white dark:bg-gray-800 rounded-lg shadow p-3 cursor-pointer border-l-4 border-orange-500 dark:border-orange-600 hover:bg-orange-50 dark:hover:bg-orange-900/20 transition duration-150" data-test-id="resource-constraints-test">
                            <div class="flex items-center justify-between">
                                <h3 class="font-medium flex items-center">
                                    <i class="fas fa-exclamation-circle text-orange-500 mr-2"></i> Resource Constraints
                                </h3>
                                <div class="flex items-center space-x-1">
                                    <button class="apply-test-btn px-2 py-1 bg-primary hover:bg-primary-dark text-white text-xs rounded transition-colors flex items-center" data-test-id="resource-constraints-test">
                                        <i class="fas fa-cog mr-1"></i> Apply
                                    </button>
                                    <button class="run-simulation-btn px-2 py-1 bg-green-500 hover:bg-green-600 text-white text-xs rounded transition-colors flex items-center" data-test-id="resource-constraints-test">
                                        <i class="fas fa-play mr-1"></i> Run
                                    </button>
                                </div>
                            </div>
                            <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Testing scheduler with limited resources</p>
                        </div>
                        
                        <!-- Test 7: NVIDIA NIM RAG Pipeline -->
                        <div id="nvidia-nim-rag-test-card" class="test-select-card bg-white dark:bg-gray-800 rounded-lg shadow p-3 cursor-pointer border-l-4 border-nvidia dark:border-nvidia hover:bg-green-50 dark:hover:bg-green-900/20 transition duration-150" data-test-id="nvidia-nim-rag-test">
                            <div class="flex items-center justify-between">
                                <h3 class="font-medium flex items-center">
                                    <i class="fas fa-database text-nvidia mr-2"></i> NVIDIA NIM RAG Pipeline
                                </h3>
                                <div class="flex items-center space-x-1">
                                    <button class="apply-test-btn px-2 py-1 bg-primary hover:bg-primary-dark text-white text-xs rounded transition-colors flex items-center" data-test-id="nvidia-nim-rag-test">
                                        <i class="fas fa-cog mr-1"></i> Apply
                                    </button>
                                    <button class="run-simulation-btn px-2 py-1 bg-green-500 hover:bg-green-600 text-white text-xs rounded transition-colors flex items-center" data-test-id="nvidia-nim-rag-test">
                                        <i class="fas fa-play mr-1"></i> Run
                                    </button>
                                </div>
                            </div>
                            <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Pre-validated NIM 70B RAG stack</p>
                        </div>
                    </div>
                </div>

                <!-- Right side: Test Details -->
                <div class="lg:col-span-3">
                    <div id="test-detail-container" class="bg-white dark:bg-gray-800 rounded-lg shadow-md border border-gray-200 dark:border-gray-700">
                        <!-- CPU-Only Model Test -->
                        <div id="cpu-only-test-detail" class="test-detail hidden">
                            <div class="p-4 border-b border-gray-200 dark:border-gray-700 bg-blue-50 dark:bg-blue-900/30 rounded-t-lg">
                                <div class="flex justify-between items-center">
                                    <h3 class="text-lg font-medium flex items-center">
                                        <i class="fas fa-microchip text-blue-500 mr-2"></i> CPU-Only Model (Gemma 2B)
                                    </h3>
                                    <div class="flex space-x-2">
                                        <button class="open-test-btn px-2 py-1 bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 text-xs rounded transition-colors flex items-center" data-test-id="cpu-only-test">
                                            <i class="fas fa-external-link-alt mr-1"></i> Open in New Window
                                        </button>
                                        <button class="apply-test-btn px-3 py-1 bg-primary hover:bg-primary-dark text-white text-sm rounded transition-colors flex items-center" data-test-id="cpu-only-test">
                                            <i class="fas fa-cog mr-1"></i> Apply Configuration
                                        </button>
                                        <button class="run-simulation-btn px-3 py-1 bg-green-500 hover:bg-green-600 text-white text-sm rounded transition-colors flex items-center" data-test-id="cpu-only-test">
                                            <i class="fas fa-play mr-1"></i> Run Simulation
                                        </button>
                                    </div>
                                </div>
                            </div>
                            <div class="p-5">
                                <p class="mb-4">
                                    Tests deployment of a small model (Google Gemma 2B) in CPU-only mode without requiring GPUs.
                                </p>
                                
                                <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-6">
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-cog text-blue-500 mr-2"></i> Configuration
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>Model: Google Gemma 2B (10GB)</li>
                                            <li>CPU-Only Mode: Enabled</li>
                                            <li>CPU Cores: 6</li>
                                            <li>Memory: 24 GB</li>
                                            <li>Replicas: 2</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-server text-blue-500 mr-2"></i> Recommended Node Pool
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>3 CPU-Only nodes</li>
                                            <li>8 CPU cores per node</li>
                                            <li>32 GB memory per node</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-clipboard-check text-blue-500 mr-2"></i> Expected Outcome
                                        </h4>
                                        <p class="text-sm text-gray-700 dark:text-gray-300">
                                            Each pod requires 6 CPU cores and 24 GB memory. With the recommended node pool, you should be able to schedule 1 pod per node.
                                        </p>
                                    </div>
                                </div>
                                
                                <div class="bg-blue-50 dark:bg-blue-900/20 p-4 rounded-lg">
                                    <h4 class="text-sm font-semibold mb-2 flex items-center">
                                        <i class="fas fa-lightbulb text-blue-500 mr-2"></i> Key Learning Points
                                    </h4>
                                    <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                        <li>Small models (&lt; 10B parameters) can run effectively on CPU-only deployments</li>
                                        <li>CPU-only deployments require more CPU cores and memory per pod</li>
                                        <li>No special GPU requirements means greater deployment flexibility</li>
                                        <li>Pods will be scheduled on any nodes with sufficient CPU and memory</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <!-- Large GPU Model Test -->
                        <div id="large-gpu-test-detail" class="test-detail">
                            <div class="p-4 border-b border-gray-200 dark:border-gray-700 bg-green-50 dark:bg-green-900/30 rounded-t-lg">
                                <div class="flex justify-between items-center">
                                    <h3 class="text-lg font-medium flex items-center">
                                        <i class="fas fa-microchip text-green-500 mr-2"></i> Large GPU Model (Llama 70B)
                                    </h3>
                                    <div class="flex space-x-2">
                                        <button class="open-test-btn px-2 py-1 bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 text-xs rounded transition-colors flex items-center" data-test-id="large-gpu-test">
                                            <i class="fas fa-external-link-alt mr-1"></i> Open in New Window
                                        </button>
                                        <button class="apply-test-btn px-3 py-1 bg-primary hover:bg-primary-dark text-white text-sm rounded transition-colors flex items-center" data-test-id="large-gpu-test">
                                            <i class="fas fa-cog mr-1"></i> Apply Configuration
                                        </button>
                                        <button class="run-simulation-btn px-3 py-1 bg-green-500 hover:bg-green-600 text-white text-sm rounded transition-colors flex items-center" data-test-id="large-gpu-test">
                                            <i class="fas fa-play mr-1"></i> Run Simulation
                                        </button>
                                    </div>
                                </div>
                            </div>
                            <div class="p-5">
                                <p class="mb-4">
                                    Tests deployment of a large model (Meta Llama 3.1 70B) requiring multiple H100 GPUs per pod.
                                </p>
                                
                                <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-6">
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-cog text-green-500 mr-2"></i> Configuration
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>Model: Meta Llama 3.1 70B (290GB)</li>
                                            <li>GPU Type: H100-80G</li>
                                            <li>Inference Engine: vLLM</li>
                                            <li>Replicas: 2</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-server text-green-500 mr-2"></i> Recommended Node Pool
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>2 nodes with H100-80G GPUs</li>
                                            <li>4 GPUs per node</li>
                                            <li>64 CPU cores per node</li>
                                            <li>256 GB memory per node</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-clipboard-check text-green-500 mr-2"></i> Expected Outcome
                                        </h4>
                                        <p class="text-sm text-gray-700 dark:text-gray-300">
                                            Each pod requires 2 H100 GPUs, 16 CPU cores, and 64 GB memory. With the recommended node pool, each node can run 2 pods, allowing all 2 replicas to be scheduled.
                                        </p>
                                    </div>
                                </div>
                                
                                <div class="bg-green-50 dark:bg-green-900/20 p-4 rounded-lg">
                                    <h4 class="text-sm font-semibold mb-2 flex items-center">
                                        <i class="fas fa-lightbulb text-green-500 mr-2"></i> Key Learning Points
                                    </h4>
                                    <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                        <li>Large models (&gt; 65B parameters) typically require multiple GPUs per pod</li>
                                        <li>High-end GPUs like H100s provide better performance for large models</li>
                                        <li>Pod resource requirements scale with model size</li>
                                        <li>Node capacity determines how many pods can be scheduled per node</li>
                                        <li>The vLLM inference engine optimizes memory usage and throughput</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <!-- GPU Compatibility Test -->
                        <div id="gpu-compatibility-test-detail" class="test-detail hidden">
                            <div class="p-4 border-b border-gray-200 dark:border-gray-700 bg-yellow-50 dark:bg-yellow-900/30 rounded-t-lg">
                                <div class="flex justify-between items-center">
                                    <h3 class="text-lg font-medium flex items-center">
                                        <i class="fas fa-exclamation-triangle text-yellow-500 mr-2"></i> GPU Compatibility Test
                                    </h3>
                                    <div class="flex space-x-2">
                                        <button class="open-test-btn px-2 py-1 bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 text-xs rounded transition-colors flex items-center" data-test-id="gpu-compatibility-test">
                                            <i class="fas fa-external-link-alt mr-1"></i> Open in New Window
                                        </button>
                                        <button class="apply-test-btn px-3 py-1 bg-primary hover:bg-primary-dark text-white text-sm rounded transition-colors flex items-center" data-test-id="gpu-compatibility-test">
                                            <i class="fas fa-cog mr-1"></i> Apply Configuration
                                        </button>
                                        <button class="run-simulation-btn px-3 py-1 bg-green-500 hover:bg-green-600 text-white text-sm rounded transition-colors flex items-center" data-test-id="gpu-compatibility-test">
                                            <i class="fas fa-play mr-1"></i> Run Simulation
                                        </button>
                                    </div>
                                </div>
                            </div>
                            <div class="p-5">
                                <p class="mb-4">
                                    Tests GPU compatibility handling with NVIDIA models that have specific hardware requirements.
                                </p>
                                
                                <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-6">
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-cog text-yellow-500 mr-2"></i> Configuration
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>Model: NVIDIA Llama 3.3 70B (160GB)</li>
                                            <li>Inference Engine: NVIDIA NIM (auto-selected)</li>
                                            <li>Hardware Requirement: H100 GPUs only</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-server text-yellow-500 mr-2"></i> Node Pool Setup
                                        </h4>
                                        <ol class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-decimal pl-5">
                                            <li>Create a node pool with A100-80G GPUs (incompatible)</li>
                                            <li>Create a node pool with H100-80G GPUs (compatible)</li>
                                            <li>Deploy the model and observe scheduling</li>
                                        </ol>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-clipboard-check text-yellow-500 mr-2"></i> Expected Outcome
                                        </h4>
                                        <p class="text-sm text-gray-700 dark:text-gray-300">
                                            The scheduler should recognize GPU type incompatibility, placing pods on H100 nodes while marking pods as pending with a GPU type incompatibility message if only A100 nodes are available.
                                        </p>
                                    </div>
                                </div>
                                
                                <div class="bg-yellow-50 dark:bg-yellow-900/20 p-4 rounded-lg">
                                    <h4 class="text-sm font-semibold mb-2 flex items-center">
                                        <i class="fas fa-lightbulb text-yellow-500 mr-2"></i> Key Learning Points
                                    </h4>
                                    <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                        <li>Some models have strict hardware compatibility requirements</li>
                                        <li>NVIDIA NGC models often require specific GPU architectures</li>
                                        <li>The scheduler checks GPU type compatibility before placing pods</li>
                                        <li>Incompatible GPU types lead to pods staying in pending state</li>
                                        <li>Hardware-specific optimizations in NVIDIA NIM require compatible GPUs</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <!-- MoE Model & Advanced Settings Test -->
                        <div id="moe-model-test-detail" class="test-detail hidden">
                            <div class="p-4 border-b border-gray-200 dark:border-gray-700 bg-purple-50 dark:bg-purple-900/30 rounded-t-lg">
                                <div class="flex justify-between items-center">
                                    <h3 class="text-lg font-medium flex items-center">
                                        <i class="fas fa-sitemap text-purple-500 mr-2"></i> MoE Model &amp; Advanced Settings
                                    </h3>
                                    <div class="flex space-x-2">
                                        <button class="open-test-btn px-2 py-1 bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 text-xs rounded transition-colors flex items-center" data-test-id="moe-model-test">
                                            <i class="fas fa-external-link-alt mr-1"></i> Open in New Window
                                        </button>
                                        <button class="apply-test-btn px-3 py-1 bg-primary hover:bg-primary-dark text-white text-sm rounded transition-colors flex items-center" data-test-id="moe-model-test">
                                            <i class="fas fa-cog mr-1"></i> Apply Configuration
                                        </button>
                                        <button class="run-simulation-btn px-3 py-1 bg-green-500 hover:bg-green-600 text-white text-sm rounded transition-colors flex items-center" data-test-id="moe-model-test">
                                            <i class="fas fa-play mr-1"></i> Run Simulation
                                        </button>
                                    </div>
                                </div>
                            </div>
                            <div class="p-5">
                                <p class="mb-4">
                                    Tests Mixture of Experts models with advanced resource settings for fine-tuned deployments.
                                </p>
                                
                                <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-6">
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-cog text-purple-500 mr-2"></i> Configuration
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>Model: Mistral AI Mixtral 8x7B (200GB)</li>
                                            <li>GPU Type: A100-80G</li>
                                            <li>Enable Advanced Settings with GPU Override set to 4</li>
                                            <li>vLLM CPU Multiplier: 1.5</li>
                                            <li>vLLM Memory Multiplier: 1.8</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-server text-purple-500 mr-2"></i> Recommended Node Pool
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>1 node with A100-80G GPUs</li>
                                            <li>8 GPUs per node</li>
                                            <li>96 CPU cores per node</li>
                                            <li>384 GB memory per node</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-clipboard-check text-purple-500 mr-2"></i> Expected Outcome
                                        </h4>
                                        <p class="text-sm text-gray-700 dark:text-gray-300">
                                            Each pod requires 4 GPUs with increased CPU and memory due to the multipliers. The pod should schedule on a node with sufficient resources.
                                        </p>
                                    </div>
                                </div>
                                
                                <div class="bg-purple-50 dark:bg-purple-900/20 p-4 rounded-lg">
                                    <h4 class="text-sm font-semibold mb-2 flex items-center">
                                        <i class="fas fa-lightbulb text-purple-500 mr-2"></i> Key Learning Points
                                    </h4>
                                    <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                        <li>MoE models activate only a subset of their parameters for each input, making them more efficient</li>
                                        <li>Advanced resource settings allow fine-tuning of deployment parameters</li>
                                        <li>Resource multipliers adjust CPU and memory allocation based on the inference engine</li>
                                        <li>GPU count overrides allow specifying exact GPU requirements</li>
                                        <li>High-capacity nodes are needed for resource-intensive MoE models</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <!-- Mixed Workload Test -->
                        <div id="mixed-workload-test-detail" class="test-detail hidden">
                            <div class="p-4 border-b border-gray-200 dark:border-gray-700 bg-red-50 dark:bg-red-900/30 rounded-t-lg">
                                <div class="flex justify-between items-center">
                                    <h3 class="text-lg font-medium flex items-center">
                                        <i class="fas fa-layer-group text-red-500 mr-2"></i> Mixed Workload Testing
                                    </h3>
                                    <div class="flex space-x-2">
                                        <button class="open-test-btn px-2 py-1 bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 text-xs rounded transition-colors flex items-center" data-test-id="mixed-workload-test">
                                            <i class="fas fa-external-link-alt mr-1"></i> Open in New Window
                                        </button>
                                        <button class="apply-test-btn px-3 py-1 bg-primary hover:bg-primary-dark text-white text-sm rounded transition-colors flex items-center" data-test-id="mixed-workload-test">
                                            <i class="fas fa-cog mr-1"></i> Apply Configuration
                                        </button>
                                        <button class="run-simulation-btn px-3 py-1 bg-green-500 hover:bg-green-600 text-white text-sm rounded transition-colors flex items-center" data-test-id="mixed-workload-test">
                                            <i class="fas fa-play mr-1"></i> Run Simulation
                                        </button>
                                    </div>
                                </div>
                            </div>
                            <div class="p-5">
                                <p class="mb-4">
                                    Tests a heterogeneous cluster with multiple node pools and diverse workloads.
                                </p>
                                
                                <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-server text-red-500 mr-2"></i> Node Pool Setup
                                        </h4>
                                        <ol class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-decimal pl-5">
                                            <li>H100 pool: 2 nodes, 2 GPUs each, 64 CPU, 256 GB memory</li>
                                            <li>L40S pool: 3 nodes, 4 GPUs each, 48 CPU, 192 GB memory</li>
                                            <li>CPU pool: 4 nodes, 0 GPUs, 32 CPU, 128 GB memory</li>
                                        </ol>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-cog text-red-500 mr-2"></i> Workload Deployment
                                        </h4>
                                        <ol class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-decimal pl-5">
                                            <li>Deploy Llama 3.1 70B on H100 pool</li>
                                            <li>Deploy Mixtral 8x7B on L40S pool</li>
                                            <li>Deploy Gemma 2B in CPU-only mode</li>
                                            <li>Create resource contention by deploying additional pods</li>
                                        </ol>
                                    </div>
                                </div>
                                
                                <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg mb-6">
                                    <h4 class="text-sm font-semibold mb-2 flex items-center">
                                        <i class="fas fa-clipboard-check text-red-500 mr-2"></i> Expected Outcome
                                    </h4>
                                    <p class="text-sm text-gray-700 dark:text-gray-300">
                                        Pods should be scheduled on their compatible node pools. Once resources are exhausted, pods should go to pending state with proper error messages.
                                    </p>
                                </div>
                                
                                <div class="bg-red-50 dark:bg-red-900/20 p-4 rounded-lg">
                                    <h4 class="text-sm font-semibold mb-2 flex items-center">
                                        <i class="fas fa-lightbulb text-red-500 mr-2"></i> Key Learning Points
                                    </h4>
                                    <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                        <li>Heterogeneous clusters can efficiently support diverse workloads</li>
                                        <li>Different node pools can be optimized for specific model types</li>
                                        <li>Node pool labels help with workload targeting</li>
                                        <li>CPU-only workloads can coexist with GPU workloads</li>
                                        <li>The scheduler intelligently places pods based on resource requirements and compatibility</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <!-- Resource Constraints Test -->
                        <div id="resource-constraints-test-detail" class="test-detail hidden">
                            <div class="p-4 border-b border-gray-200 dark:border-gray-700 bg-orange-50 dark:bg-orange-900/30 rounded-t-lg">
                                <div class="flex justify-between items-center">
                                    <h3 class="text-lg font-medium flex items-center">
                                        <i class="fas fa-exclamation-circle text-orange-500 mr-2"></i> Resource Constraints
                                    </h3>
                                    <div class="flex space-x-2">
                                        <button class="open-test-btn px-2 py-1 bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 text-xs rounded transition-colors flex items-center" data-test-id="resource-constraints-test">
                                            <i class="fas fa-external-link-alt mr-1"></i> Open in New Window
                                        </button>
                                        <button class="apply-test-btn px-3 py-1 bg-primary hover:bg-primary-dark text-white text-sm rounded transition-colors flex items-center" data-test-id="resource-constraints-test">
                                            <i class="fas fa-cog mr-1"></i> Apply Configuration
                                        </button>
                                        <button class="run-simulation-btn px-3 py-1 bg-green-500 hover:bg-green-600 text-white text-sm rounded transition-colors flex items-center" data-test-id="resource-constraints-test">
                                            <i class="fas fa-play mr-1"></i> Run Simulation
                                        </button>
                                    </div>
                                </div>
                            </div>
                            <div class="p-5">
                                <p class="mb-4">
                                    Tests how the scheduler handles resource constraints and pending pods.
                                </p>
                                
                                <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-6">
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-server text-orange-500 mr-2"></i> Node Pool Setup
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>Single node pool with 2 nodes</li>
                                            <li>4 GPUs per node (H100-80G)</li>
                                            <li>64 CPU cores per node</li>
                                            <li>256 GB memory per node</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-cog text-orange-500 mr-2"></i> Test Steps
                                        </h4>
                                        <ol class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-decimal pl-5">
                                            <li>Deploy Mixtral 8x7B requiring 2 GPUs each (2 replicas)</li>
                                            <li>Deploy Meta Llama 3.1 70B requiring 2 GPUs each (2 replicas)</li>
                                            <li>Try to deploy one more replica of Mixtral</li>
                                            <li>Delete one pod and observe rescheduling</li>
                                        </ol>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-clipboard-check text-orange-500 mr-2"></i> Expected Outcome
                                        </h4>
                                        <p class="text-sm text-gray-700 dark:text-gray-300">
                                            Initial 4 pods will fill the cluster (2 GPUs × 4 pods = 8 GPUs total). The 5th pod should be pending due to insufficient resources. When a pod is deleted, the pending pod should automatically schedule.
                                        </p>
                                    </div>
                                </div>
                                
                                <div class="bg-orange-50 dark:bg-orange-900/20 p-4 rounded-lg">
                                    <h4 class="text-sm font-semibold mb-2 flex items-center">
                                        <i class="fas fa-lightbulb text-orange-500 mr-2"></i> Key Learning Points
                                    </h4>
                                    <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                        <li>Kubernetes tracks pending pods and attempts to schedule them when resources become available</li>
                                        <li>Pods go to pending state when there are insufficient cluster resources</li>
                                        <li>When resources are freed (by deleting pods), the scheduler automatically tries to place pending pods</li>
                                        <li>Capacity planning is important to avoid resource contention</li>
                                        <li>Resource constraints can be diagnosed through pod status and events</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                        
                        <!-- NVIDIA NIM RAG Pipeline Test -->
                        <div id="nvidia-nim-rag-test-detail" class="test-detail hidden">
                            <div class="p-4 border-b border-gray-200 dark:border-gray-700 bg-green-50 dark:bg-green-900/30 rounded-t-lg">
                                <div class="flex justify-between items-center">
                                    <h3 class="text-lg font-medium flex items-center">
                                        <i class="fas fa-database text-nvidia mr-2"></i> NVIDIA NIM RAG Pipeline
                                    </h3>
                                    <div class="flex space-x-2">
                                        <button class="open-test-btn px-2 py-1 bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 text-xs rounded transition-colors flex items-center" data-test-id="nvidia-nim-rag-test">
                                            <i class="fas fa-external-link-alt mr-1"></i> Open in New Window
                                        </button>
                                        <button class="apply-test-btn px-3 py-1 bg-primary hover:bg-primary-dark text-white text-sm rounded transition-colors flex items-center" data-test-id="nvidia-nim-rag-test">
                                            <i class="fas fa-cog mr-1"></i> Apply Configuration
                                        </button>
                                        <button class="run-simulation-btn px-3 py-1 bg-green-500 hover:bg-green-600 text-white text-sm rounded transition-colors flex items-center" data-test-id="nvidia-nim-rag-test">
                                            <i class="fas fa-play mr-1"></i> Run Simulation
                                        </button>
                                    </div>
                                </div>
                            </div>
                            <div class="p-5">
                                <p class="mb-4">
                                    Tests deployment of a complete NVIDIA NIM RAG pipeline with pre-validated components for enterprise production deployments.
                                </p>
                                
                                <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
                                    <div class="col-span-1 md:col-span-2 bg-nvidia bg-opacity-10 dark:bg-opacity-20 border border-nvidia border-opacity-20 rounded-lg p-4">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center text-nvidia">
                                            <i class="fas fa-info-circle mr-2"></i> About NVIDIA NIM RAG Pipeline
                                        </h4>
                                        <p class="text-sm text-gray-700 dark:text-gray-300 mb-2">
                                            This integrated stack deploys a production-ready Retrieval Augmented Generation (RAG) pipeline using NVIDIA's 
                                            pre-validated NIM (NVIDIA Inference Microservices) components. All microservices are optimized for NVIDIA hardware 
                                            and include built-in security and monitoring capabilities.
                                        </p>
                                        <div class="grid grid-cols-1 md:grid-cols-4 gap-4 mt-4">
                                            <div class="bg-white dark:bg-gray-800 p-3 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700">
                                                <div class="flex items-center mb-2">
                                                    <div class="w-8 h-8 bg-nvidia rounded-full flex items-center justify-center mr-2">
                                                        <i class="fas fa-brain text-white"></i>
                                                    </div>
                                                    <h5 class="font-medium">LLM Inference</h5>
                                                </div>
                                                <p class="text-xs text-gray-600 dark:text-gray-400">NVIDIA NIM LLM 70B model with TensorRT-LLM acceleration</p>
                                            </div>
                                            <div class="bg-white dark:bg-gray-800 p-3 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700">
                                                <div class="flex items-center mb-2">
                                                    <div class="w-8 h-8 bg-nvidia rounded-full flex items-center justify-center mr-2">
                                                        <i class="fas fa-vector-square text-white"></i>
                                                    </div>
                                                    <h5 class="font-medium">Embedding</h5>
                                                </div>
                                                <p class="text-xs text-gray-600 dark:text-gray-400">E5-large-v2 embedding model optimized with FasterTransformer</p>
                                            </div>
                                            <div class="bg-white dark:bg-gray-800 p-3 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700">
                                                <div class="flex items-center mb-2">
                                                    <div class="w-8 h-8 bg-nvidia rounded-full flex items-center justify-center mr-2">
                                                        <i class="fas fa-sort-amount-up text-white"></i>
                                                    </div>
                                                    <h5 class="font-medium">Reranker</h5>
                                                </div>
                                                <p class="text-xs text-gray-600 dark:text-gray-400">BGE reranker model with quantization optimizations</p>
                                            </div>
                                            <div class="bg-white dark:bg-gray-800 p-3 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700">
                                                <div class="flex items-center mb-2">
                                                    <div class="w-8 h-8 bg-nvidia rounded-full flex items-center justify-center mr-2">
                                                        <i class="fas fa-shield-alt text-white"></i>
                                                    </div>
                                                    <h5 class="font-medium">Guardrails</h5>
                                                </div>
                                                <p class="text-xs text-gray-600 dark:text-gray-400">NeMo Guardrails for content safety and compliance</p>
                                            </div>
                                        </div>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-server text-nvidia mr-2"></i> Node Pool Setup
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>High-performance node pool with 2 nodes</li>
                                            <li>8 GPUs per node (H100-80G)</li>
                                            <li>128 CPU cores per node</li>
                                            <li>512 GB memory per node</li>
                                            <li>NVMe storage for vector database</li>
                                        </ul>
                                        <div class="mt-3 bg-white dark:bg-gray-800 p-3 rounded-lg border border-gray-200 dark:border-gray-700">
                                            <h5 class="text-xs font-semibold mb-1 text-nvidia">Resource Distribution</h5>
                                            <ul class="text-xs text-gray-700 dark:text-gray-300 list-none pl-0 space-y-1">
                                                <li>• LLM Inference: 6 GPUs, 96 CPU cores, 384 GB RAM</li>
                                                <li>• Embedding: 1 GPU, 16 CPU cores, 64 GB RAM</li>
                                                <li>• Reranker: 1 GPU, 8 CPU cores, 32 GB RAM</li>
                                                <li>• Guardrails: Shares LLM container resources</li>
                                            </ul>
                                        </div>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-clipboard-check text-nvidia mr-2"></i> Expected Outcome
                                        </h4>
                                        <p class="text-sm text-gray-700 dark:text-gray-300 mb-2">
                                            The simulation will deploy a complete RAG pipeline with four interlinked components across the cluster.
                                            Components will be scheduled with anti-affinity rules to ensure high availability.
                                        </p>
                                        <div class="mt-3 bg-white dark:bg-gray-800 p-3 rounded border border-gray-200 dark:border-gray-700">
                                            <h5 class="text-xs font-semibold mb-1 flex items-center">
                                                <i class="fas fa-tachometer-alt text-green-500 mr-1"></i> Performance Metrics
                                            </h5>
                                            <ul class="text-xs text-gray-700 dark:text-gray-300 list-none pl-0 space-y-1">
                                                <li>• Query throughput: 100 QPS</li>
                                                <li>• End-to-end latency: &lt; 300ms</li>
                                                <li>• Resource efficiency: 2× better than non-NIM deployments</li>
                                                <li>• Auto-scaling with traffic patterns</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-cogs text-nvidia mr-2"></i> Optimization Features
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>TensorRT-LLM inference optimization with FP8 quantization</li>
                                            <li>Multi-GPU tensor parallelism for the 70B model</li>
                                            <li>NVFuser operator fusion for embedding models</li>
                                            <li>Rayon parallel scheduling for reranking operations</li>
                                            <li>GPU-accelerated vector search with FAISS</li>
                                            <li>Continuous batching with PagedAttention KV cache</li>
                                        </ul>
                                    </div>
                                    
                                    <div class="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
                                        <h4 class="text-sm font-semibold mb-2 flex items-center">
                                            <i class="fas fa-shield-alt text-nvidia mr-2"></i> Production Features
                                        </h4>
                                        <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                            <li>Built-in Triton metrics export for Prometheus</li>
                                            <li>Automatic fault tolerance with pod anti-affinity</li>
                                            <li>NeMo Guardrails for content safety and compliance</li>
                                            <li>Input/output validation with JSON Schema</li>
                                            <li>Rate limiting and quota management</li>
                                            <li>GPU failure monitoring and auto-recovery</li>
                                        </ul>
                                    </div>
                                </div>
                                
                                <div class="bg-green-50 dark:bg-green-900/20 p-4 rounded-lg border-l-4 border-nvidia">
                                    <h4 class="text-sm font-semibold mb-2 flex items-center">
                                        <i class="fas fa-lightbulb text-nvidia mr-2"></i> Key Learning Points
                                    </h4>
                                    <ul class="text-sm space-y-1 text-gray-700 dark:text-gray-300 list-disc pl-5">
                                        <li>Complete RAG pipelines require coordinated deployment of multiple model types with different resource profiles</li>
                                        <li>Pre-validated components reduce deployment complexity and ensure compatibility</li>
                                        <li>High-capacity nodes with multiple GPUs are ideal for large-scale inference workloads</li>
                                        <li>Production features like monitoring, guardrails, and fault tolerance are critical for enterprise deployments</li>
                                        <li>Optimized containers from trusted sources (like NVIDIA) provide significant performance advantages over custom builds</li>
                                        <li>Kubernetes pod affinity and anti-affinity rules can be used to optimize placement for both performance and availability</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Model resource requirements based on GPU compatibility data
        const modelRequirements = {
            // AI21 Labs
            "ai21labs-jamba": { 
                "L40S-48G": { cpu: 12, memory: 48, gpu: 4, storage: 110, supportedCounts: [4, 8] },
                "A100-80G": { cpu: 12, memory: 48, gpu: 2, storage: 110, supportedCounts: [2, 4, 8] },
                "H100-80G": { cpu: 12, memory: 48, gpu: 2, storage: 110, supportedCounts: [2, 4, 8] },
                "H100-NVL-94G": { cpu: 12, memory: 48, gpu: 2, storage: 110, supportedCounts: [2, 4, 8] }
            },
            // Google models with updated GPU compatibility
            "google-gemma-2-2b": { 
                "L40S-48G": { cpu: 4, memory: 12, gpu: 1, storage: 10, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 4, memory: 12, gpu: 1, storage: 10, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 4, memory: 12, gpu: 1, storage: 10, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 4, memory: 12, gpu: 1, storage: 10, supportedCounts: [1, 2, 4, 8] },
                "CPU-Only": { cpu: 4, memory: 16, gpu: 0, storage: 10 }
            },
            "google-gemma-2-9b": { 
                "L40S-48G": { cpu: 8, memory: 16, gpu: 1, storage: 20, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 8, memory: 16, gpu: 1, storage: 20, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 8, memory: 16, gpu: 1, storage: 20, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 8, memory: 16, gpu: 1, storage: 20, supportedCounts: [1, 2, 4, 8] },
                "CPU-Only": { cpu: 8, memory: 32, gpu: 0, storage: 20 }
            },
            // Meta models with updated GPU compatibility
            "meta-llama-2-13b": { 
                "L40S-48G": { cpu: 8, memory: 24, gpu: 1, storage: 60, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 60, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 60, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 8, memory: 24, gpu: 1, storage: 60, supportedCounts: [1, 2, 4, 8] }
            },
            "meta-llama-3-2-1b": { 
                "L40S-48G": { cpu: 4, memory: 12, gpu: 1, storage: 20, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 4, memory: 12, gpu: 1, storage: 20, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 4, memory: 12, gpu: 1, storage: 20, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 4, memory: 12, gpu: 1, storage: 20, supportedCounts: [1, 2, 4, 8] },
                "CPU-Only": { cpu: 4, memory: 12, gpu: 0, storage: 20 }
            },
            "meta-llama-3-2-3b": { 
                "L40S-48G": { cpu: 4, memory: 12, gpu: 1, storage: 10, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 4, memory: 12, gpu: 1, storage: 10, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 4, memory: 12, gpu: 1, storage: 10, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 4, memory: 12, gpu: 1, storage: 10, supportedCounts: [1, 2, 4, 8] },
                "CPU-Only": { cpu: 6, memory: 16, gpu: 0, storage: 10 }
            },
            "meta-llama-3-1-8b": { 
                "L40S-48G": { cpu: 8, memory: 16, gpu: 1, storage: 40, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 8, memory: 16, gpu: 1, storage: 40, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 8, memory: 16, gpu: 1, storage: 40, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 8, memory: 16, gpu: 1, storage: 40, supportedCounts: [1, 2, 4, 8] },
                "CPU-Only": { cpu: 12, memory: 32, gpu: 0, storage: 40 }
            },
            "meta-llama-3-1-70b": { 
                "L40S-48G": { cpu: 16, memory: 64, gpu: 4, storage: 290, supportedCounts: [4, 8] },
                "A100-80G": { cpu: 16, memory: 64, gpu: 2, storage: 290, supportedCounts: [2, 4, 8] },
                "H100-80G": { cpu: 16, memory: 64, gpu: 2, storage: 290, supportedCounts: [2, 4, 8] },
                "H100-NVL-94G": { cpu: 16, memory: 64, gpu: 2, storage: 290, supportedCounts: [2, 4, 8] }
            },
            "meta-llama-3-3-70b": { 
                "L40S-48G": { cpu: 16, memory: 64, gpu: 4, storage: 290, supportedCounts: [4, 8] },
                "A100-80G": { cpu: 16, memory: 64, gpu: 2, storage: 290, supportedCounts: [2, 4, 8] },
                "H100-80G": { cpu: 16, memory: 64, gpu: 2, storage: 290, supportedCounts: [2, 4, 8] },
                "H100-NVL-94G": { cpu: 16, memory: 64, gpu: 2, storage: 290, supportedCounts: [2, 4, 8] }
            },
            "meta-codellama-7b": { 
                "L40S-48G": { cpu: 8, memory: 16, gpu: 1, storage: 30, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 8, memory: 16, gpu: 1, storage: 30, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 8, memory: 16, gpu: 1, storage: 30, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 8, memory: 16, gpu: 1, storage: 30, supportedCounts: [1, 2, 4, 8] },
                "CPU-Only": { cpu: 12, memory: 32, gpu: 0, storage: 30 }
            },
            "meta-codellama-13b": { 
                "L40S-48G": { cpu: 8, memory: 24, gpu: 1, storage: 60, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 60, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 60, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 8, memory: 24, gpu: 1, storage: 60, supportedCounts: [1, 2, 4, 8] }
            },
            "meta-codellama-34b": { 
                "L40S-48G": { cpu: 12, memory: 32, gpu: 2, storage: 140, supportedCounts: [2, 4, 8] },
                "A100-80G": { cpu: 12, memory: 32, gpu: 1, storage: 140, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 12, memory: 32, gpu: 1, storage: 140, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 12, memory: 32, gpu: 1, storage: 140, supportedCounts: [1, 2, 4, 8] }
            },
            "meta-codellama-70b": { 
                "L40S-48G": { cpu: 16, memory: 64, gpu: 4, storage: 280, supportedCounts: [4, 8] },
                "A100-80G": { cpu: 16, memory: 64, gpu: 2, storage: 280, supportedCounts: [2, 4, 8] },
                "H100-80G": { cpu: 16, memory: 64, gpu: 2, storage: 280, supportedCounts: [2, 4, 8] },
                "H100-NVL-94G": { cpu: 16, memory: 64, gpu: 2, storage: 280, supportedCounts: [2, 4, 8] }
            },
            // Mistral AI models with updated GPU compatibility
            "mistralai-mistral-7b": { 
                "L40S-48G": { cpu: 8, memory: 16, gpu: 1, storage: 30, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 8, memory: 16, gpu: 1, storage: 30, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 8, memory: 16, gpu: 1, storage: 30, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 8, memory: 16, gpu: 1, storage: 30, supportedCounts: [1, 2, 4, 8] },
                "CPU-Only": { cpu: 12, memory: 32, gpu: 0, storage: 30 }
            },
            "mistralai-mixtral-8x7b": { 
                "L40S-48G": { cpu: 16, memory: 64, gpu: 4, storage: 200, supportedCounts: [4, 8] },
                "A100-80G": { cpu: 16, memory: 64, gpu: 2, storage: 200, supportedCounts: [2, 4, 8] },
                "H100-80G": { cpu: 16, memory: 64, gpu: 2, storage: 200, supportedCounts: [2, 4, 8] },
                "H100-NVL-94G": { cpu: 16, memory: 64, gpu: 2, storage: 200, supportedCounts: [2, 4, 8] }
            },
            "mistralai-mixtral-8x22b": { 
                "L40S-48G": { cpu: 32, memory: 128, gpu: 8, storage: 290, supportedCounts: [8] },
                "A100-80G": { cpu: 32, memory: 128, gpu: 4, storage: 290, supportedCounts: [4, 8] },
                "H100-80G": { cpu: 32, memory: 128, gpu: 4, storage: 290, supportedCounts: [4, 8] },
                "H100-NVL-94G": { cpu: 32, memory: 128, gpu: 4, storage: 290, supportedCounts: [4, 8] }
            },
            "mistralai-nemo-instruct-2407": {
                "L40S-48G": { cpu: 8, memory: 24, gpu: 1, storage: 50, supportedCounts: [1, 2, 4, 8] },
                "A100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50, supportedCounts: [1, 2, 4, 8] },
                "H100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50, supportedCounts: [1, 2, 4, 8] },
                "H100-NVL-94G": { cpu: 8, memory: 24, gpu: 1, storage: 50, supportedCounts: [1, 2, 4, 8] }
            },
            // NVIDIA models
            "nvidia-llama-3-3-70b": { 
                "L40S-48G": { cpu: 16, memory: 64, gpu: 4, storage: 160 },
                "A100-80G": { cpu: 16, memory: 64, gpu: 0, storage: 160 }, // Not supported
                "H100-80G": { cpu: 16, memory: 64, gpu: 4, storage: 160 },
                "H100-NVL-94G": { cpu: 16, memory: 64, gpu: 4, storage: 160 }
            },
            "nvidia-llama-3-1-70b": {
                "L40S-48G": { cpu: 16, memory: 64, gpu: 4, storage: 160 },
                "A100-80G": { cpu: 16, memory: 64, gpu: 4, storage: 160 },
                "H100-80G": { cpu: 16, memory: 64, gpu: 4, storage: 160 },
                "H100-NVL-94G": { cpu: 16, memory: 64, gpu: 4, storage: 160 }
            },
            "nvidia-llama-3-1-70b-pb24b2": {
                "L40S-48G": { cpu: 16, memory: 48, gpu: 4, storage: 160 },
                "A100-80G": { cpu: 16, memory: 48, gpu: 4, storage: 160 },
                "H100-80G": { cpu: 16, memory: 48, gpu: 4, storage: 160 },
                "H100-NVL-94G": { cpu: 16, memory: 48, gpu: 4, storage: 160 }
            },
            "nvidia-llama-3-1-8b": {
                "L40S-48G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "A100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-NVL-94G": { cpu: 8, memory: 24, gpu: 1, storage: 50 }
            },
            "nvidia-llama3-8b": {
                "L40S-48G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "A100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-NVL-94G": { cpu: 8, memory: 24, gpu: 1, storage: 50 }
            },
            "nvidia-llama-3-1-swallow-8b": {
                "L40S-48G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "A100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-NVL-94G": { cpu: 8, memory: 24, gpu: 1, storage: 50 }
            },
            "nvidia-llama-3-1-nemoguard-8b-safety": {
                "L40S-48G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "A100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-NVL-94G": { cpu: 8, memory: 24, gpu: 1, storage: 50 }
            },
            "nvidia-llama-3-1-nemoguard-8b-topic": {
                "L40S-48G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "A100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-NVL-94G": { cpu: 8, memory: 24, gpu: 1, storage: 50 }
            },
            "nvidia-llama-3-1-nemoguard-8b-slimora": {
                "L40S-48G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "A100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-80G": { cpu: 8, memory: 24, gpu: 1, storage: 50 },
                "H100-NVL-94G": { cpu: 8, memory: 24, gpu: 1, storage: 50 }
            },
            "nvidia-llama-3-2-nv-embed": {
                "L40S-48G": { cpu: 2, memory: 8, gpu: 1, storage: 5 },
                "A100-80G": { cpu: 2, memory: 8, gpu: 1, storage: 5 },
                "H100-80G": { cpu: 2, memory: 8, gpu: 1, storage: 5 },
                "H100-NVL-94G": { cpu: 2, memory: 8, gpu: 1, storage: 5 }
            },
            "nvidia-llama-3-2-nv-reranker": {
                "L40S-48G": { cpu: 2, memory: 8, gpu: 1, storage: 5 },
                "A100-80G": { cpu: 2, memory: 8, gpu: 1, storage: 5 },
                "H100-80G": { cpu: 2, memory: 8, gpu: 1, storage: 5 },
                "H100-NVL-94G": { cpu: 2, memory: 8, gpu: 1, storage: 5 }
            },
            "nvidia-llama-3-1-nemotron": {
                "L40S-48G": { cpu: 16, memory: 64, gpu: 4, storage: 160 },
                "A100-80G": { cpu: 16, memory: 64, gpu: 4, storage: 160 },
                "H100-80G": { cpu: 16, memory: 64, gpu: 4, storage: 160 },
                "H100-NVL-94G": { cpu: 16, memory: 64, gpu: 4, storage: 160 }
            },
            "nvidia-mistral-nemo-12b": {
                "L40S-48G": { cpu: 8, memory: 32, gpu: 2, storage: 80 },
                "A100-80G": { cpu: 8, memory: 32, gpu: 1, storage: 80 },
                "H100-80G": { cpu: 8, memory: 32, gpu: 1, storage: 80 },
                "H100-NVL-94G": { cpu: 8, memory: 32, gpu: 1, storage: 80 }
            },
            "nvidia-mixtral-8x7b": {
                "L40S-48G": { cpu: 16, memory: 48, gpu: 4, storage: 110 },
                "A100-80G": { cpu: 16, memory: 48, gpu: 2, storage: 110 },
                "H100-80G": { cpu: 16, memory: 48, gpu: 2, storage: 110 },
                "H100-NVL-94G": { cpu: 16, memory: 48, gpu: 2, storage: 110 }
            },
            "nvidia-arctic-embed": {
                "L40S-48G": { cpu: 4, memory: 16, gpu: 1, storage: 20 },
                "A100-80G": { cpu: 4, memory: 16, gpu: 1, storage: 20 },
                "H100-80G": { cpu: 4, memory: 16, gpu: 1, storage: 20 },
                "H100-NVL-94G": { cpu: 4, memory: 16, gpu: 1, storage: 20 }
            },
            "nvidia-nv-embedqa": {
                "L40S-48G": { cpu: 2, memory: 8, gpu: 1, storage: 5 },
                "A100-80G": { cpu: 2, memory: 8, gpu: 1, storage: 5 },
                "H100-80G": { cpu: 2, memory: 8, gpu: 1, storage: 5 },
                "H100-NVL-94G": { cpu: 2, memory: 8, gpu: 1, storage: 5 }
            }
        };

        // Context length data for models
        const contextLengthData = {
            // HuggingFace Models
            "meta-llama-3-3-70b": {
                "A100-80G": {"2": 128000, "4": 256000, "8": 256000},
                "H100-80G": {"2": 128000, "4": 256000, "8": 256000},
                "H100-NVL-94G": {"2": 128000, "4": 256000, "8": 256000},
                "L40S-48G": {"4": 128000, "8": 256000}
            },
            "meta-llama-3-1-70b": {
                "A100-80G": {"2": 128000, "4": 128000, "8": 128000},
                "H100-80G": {"2": 128000, "4": 128000, "8": 128000},
                "H100-NVL-94G": {"2": 128000, "4": 128000, "8": 128000},
                "L40S-48G": {"4": 128000, "8": 128000}
            },
            "meta-llama-3-1-8b": {
                "A100-80G": {"1": 128000, "2": 128000, "4": 128000, "8": 128000},
                "H100-80G": {"1": 128000, "2": 128000, "4": 128000, "8": 128000},
                "H100-NVL-94G": {"1": 128000, "2": 128000, "4": 128000, "8": 128000},
                "L40S-48G": {"1": 128000, "2": 128000, "4": 128000, "8": 128000}
            },
            "mistralai-mixtral-8x7b": {
                "A100-80G": {"2": 32768, "4": 32768, "8": 32768},
                "H100-80G": {"2": 32768, "4": 32768, "8": 32768},
                "H100-NVL-94G": {"2": 32768, "4": 32768, "8": 32768},
                "L40S-48G": {"4": 32768, "8": 32768}
            },
            "mistralai-mixtral-8x22b": {
                "A100-80G": {"4": 32768, "8": 32768},
                "H100-80G": {"4": 32768, "8": 32768},
                "H100-NVL-94G": {"4": 32768, "8": 32768},
                "L40S-48G": {"8": 32768}
            },
            // NVIDIA models - Updated with new context lengths
            "nvidia-llama-3-3-70b": {
                "H100-80G": {"4": 131072},
                "H100-NVL-94G": {"4": 131072},
                "L40S-48G": {"4": 131072}
            },
            "nvidia-llama-3-1-70b": {
                "H100-NVL-94G": {"2": 131072},
                "L40S-48G": {"4": 131072}
            },
            "nvidia-llama-3-1-8b": {
                "H100-NVL-94G": {"1": 131072},
                "L40S-48G": {"1": 131072, "2": 131072}
            },
            "nvidia-mixtral-8x7b": {
                "H100-NVL-94G": {"2": 32768},
                "L40S-48G": {"4": 32768}
            },
            "nvidia-llama-3-1-nemoguard-8b-safety": {
                "H100-80G": {"1": 131072},
                "H100-NVL-94G": {"1": 131072},
                "L40S-48G": {"1": 131072}
            },
            "nvidia-llama-3-1-nemoguard-8b-topic": {
                "H100-80G": {"1": 131072},
                "H100-NVL-94G": {"1": 131072},
                "L40S-48G": {"1": 131072}
            },
            "nvidia-llama-3-2-nv-embed": {
                "H100-80G": {"1": 8192},
                "H100-NVL-94G": {"1": 8192},
                "L40S-48G": {"1": 8192}
            },
            "nvidia-llama-3-2-nv-reranker": {
                "H100-80G": {"1": 8192},
                "H100-NVL-94G": {"1": 8192},
                "L40S-48G": {"1": 8192}
            }
        };

        // Model runtime tags mapping
        const modelRuntimeTags = {
            // HuggingFace models
            "meta-llama-2-13b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "meta-llama-3-1-8b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text", "tool-calling"]
            },
            "meta-llama-3-1-70b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text", "tool-calling"]
            },
            "meta-llama-3-3-70b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text", "tool-calling"]
            },
            "meta-llama-3-2-1b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text", "tool-calling"]
            },
            "meta-llama-3-2-3b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text", "tool-calling"]
            },
            "meta-codellama-7b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "meta-codellama-13b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "meta-codellama-34b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "meta-codellama-70b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "mistralai-mistral-7b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "mistralai-nemo-instruct-2407": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "mistralai-mixtral-8x7b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "mistralai-mixtral-8x22b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "google-gemma-2-9b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "google-gemma-2-2b": {
                "vllm": ["text-to-text"],
                "tgi": ["text-to-text"]
            },
            "ai21labs-jamba": {
                "vllm": ["text-to-text"]
            },
            // NVIDIA models
            "nvidia-llama-3-1-8b": {
                "nvidia-nim": ["text-to-text", "tool-calling"]
            },
            "nvidia-mixtral-8x7b": {
                "nvidia-nim": ["text-to-text"]
            },
            "nvidia-llama-3-1-70b": {
                "nvidia-nim": ["text-to-text", "tool-calling"]
            },
            "nvidia-llama-3-3-70b": {
                "nvidia-nim": ["text-to-text", "tool-calling"]
            },
            "nvidia-llama-3-1-nemoguard-8b-safety": {
                "nvidia-nim": ["content-safety"]
            },
            "nvidia-llama-3-2-nv-reranker": {
                "nvidia-nim": ["reranker"]
            },
            "nvidia-llama-3-2-nv-embed": {
                "nvidia-nim": ["embedding"]
            },
            "nvidia-llama-3-1-nemoguard-8b-topic": {
                "nvidia-nim": ["content-safety"]
            },
            "nvidia-llama-3-1-nemotron": {
                "nvidia-nim": ["text-to-text"]
            },
            "nvidia-nv-embedqa": {
                "nvidia-nim": ["embedding"]
            },
            "nvidia-arctic-embed": {
                "nvidia-nim": ["embedding"]
            },
            "nvidia-llama-3-1-swallow-8b": {
                "nvidia-nim": ["text-to-text"]
            },
            "nvidia-llama3-8b": {
                "nvidia-nim": ["text-to-text"]
            },
            "nvidia-llama-3-1-70b-pb24b2": {
                "nvidia-nim": ["text-to-text", "tool-calling"]
            }
        };

        // Application state
        let nodes = [];
        let pods = [];
        let pendingPods = [];
        let nextPodId = 1;
        let nextNodePoolId = 2;
        let nodePools = [];
        
        // State tracking to prevent redraws
        window.lastModelValue = '';
        window.lastNvidiaModelState = false;
        window.isUpdatingRequirements = false;
        window.isUpdatingGPUOptions = false;
        window.isUpdatingEngineOptions = false;
        window.isCPUOnlyModeActive = false;

        // Console mode - standard only
        let consoleMode = 'standard';

        // Cache for DOM elements to avoid repeated lookups
        const domCache = new Map();
        
        // Get DOM element with caching
        function getElement(id) {
            if (!domCache.has(id)) {
                domCache.set(id, document.getElementById(id));
            }
            return domCache.get(id);
        }

        // DOM Elements - use cached lookups for frequently accessed elements
        const modelSelect = getElement('model');
        const modelCard = getElement('model-card');
        const inferenceEngineSelect = getElement('inference-engine');
        const gpuTypeSelect = getElement('gpu-type');
        const replicasInput = getElement('replicas');
        const deployBtn = getElement('deploy-btn');
        const resetBtn = getElement('reset-btn');
        const updateNodesBtn = getElement('update-nodes-btn');
        const simulateBtn = getElement('simulate-btn');
        const nodesContainer = getElement('nodes-container');
        const pendingPodsContainer = getElement('pending-pods-container');
        const pendingPodsDiv = getElement('pending-pods');
        const consoleOutput = getElement('console-output');
        const clearConsoleBtn = getElement('clear-console');
        const toggleConsoleBtn = getElement('toggle-console-mode');
        
        // Model filter toggles
        const showHfToggle = getElement('show-hf');
        const showNvidiaToggle = getElement('show-nvidia');
        const showValidatedOnlyToggle = getElement('show-validated-only');
        
        // CPU-only elements
        const cpuOnlySection = getElement('cpu-only-section');
        const cpuOnlyToggle = getElement('cpu-only-toggle');
        const cpuResourceSection = getElement('cpu-resource-section');
        const inferenceEngineSection = getElement('inference-engine-section');
        const gpuTypeSection = getElement('gpu-type-section');
        const advancedSettingsSection = getElement('advanced-settings-section');
        const cpuCountInput = getElement('cpu-count');
        const memorySizeInput = getElement('memory-size');
        const gpuRequirement = getElement('gpu-requirement');
        const cpuOnlyIndicator = getElement('cpu-only-indicator');
        
        // Advanced settings elements
        const advancedToggle = getElement('advanced-toggle');
        const advancedIcon = getElement('advanced-icon');
        const advancedContent = getElement('advanced-content');
        const gpuOverrideToggle = getElement('gpu-override-toggle');
        const overrideGpuSelect = getElement('override-gpu-select');
        
        // Engine resource multipliers
        const tgiCpuInput = getElement('tgi-cpu');
        const tgiMemoryInput = getElement('tgi-memory');
        const vllmCpuInput = getElement('vllm-cpu');
        const vllmMemoryInput = getElement('vllm-memory');
        const nimCpuInput = getElement('nim-cpu');
        const nimMemoryInput = getElement('nim-memory');

        // Debounce function for expensive event handlers
        function debounce(func, wait) {
            let timeout;
            return function(...args) {
                const context = this;
                clearTimeout(timeout);
                timeout = setTimeout(() => func.apply(context, args), wait);
            };
        }

        // Debounced versions of expensive handlers
        const debouncedUpdateModelRequirements = debounce(updateModelRequirements, 150);
        const debouncedUpdateModelCard = debounce(updateModelCard, 150);

        // Custom console logger
        const originalConsoleLog = console.log;
        
        console.log = function(...args) {
            // Send to the browser console
            originalConsoleLog.apply(console, args);
            
            // Don't show regular logs in text-ui mode unless they have the TEXT UI marker
            if (consoleMode === 'text-ui' && args[0] !== '-----TEXT UI-----') {
                return;
            }
            
            // Format the output - create a new div for each log entry
            const logDiv = document.createElement('div');
            
            if (args[0] === '-----TEXT UI-----') {
                // Remove the marker for text UI logs and don't include timestamp
                logDiv.innerHTML = args.slice(1).join(' ');
            } else {
                // Format regular logs with timestamp
                const timestamp = new Date().toISOString().substr(11, 8);
                const message = args.map(arg => {
                    if (typeof arg === 'object') {
                        try {
                            return JSON.stringify(arg, null, 2);
                        } catch (e) {
                            return '[Object]';
                        }
                    } else {
                        return String(arg);
                    }
                }).join(' ');
                
                logDiv.innerHTML = `<span class="text-gray-500">[${timestamp}]</span> ${message}`;
            }
            
            // Add to console output directly
            consoleOutput.appendChild(logDiv);
            
            // Scroll to the bottom
            consoleOutput.scrollTop = consoleOutput.scrollHeight;
        };

        // Clear console button
        clearConsoleBtn.addEventListener('click', () => {
            consoleOutput.innerHTML = '';
        });
        
        // Toggle console mode
        toggleConsoleBtn.addEventListener('click', () => {
            consoleMode = consoleMode === 'standard' ? 'text-ui' : 'standard';
            toggleConsoleBtn.innerHTML = consoleMode === 'standard' ? 
                '<i class="fas fa-code mr-1"></i> Standard Mode' : 
                '<i class="fas fa-code mr-1"></i> Text UI Mode';
            
            // Clear console when switching modes
            consoleOutput.innerHTML = '';
            
            if (consoleMode === 'text-ui') {
                logTextUI();
            } else {
                console.log('Switched to standard console mode');
            }
        });

        // CPU-only mode toggle
        cpuOnlyToggle.addEventListener('change', function() {
            toggleCPUOnlyMode(this.checked);
            debouncedUpdateModelRequirements();
        });
        
        // CPU and Memory inputs for CPU-only mode
        cpuCountInput.addEventListener('input', debouncedUpdateModelRequirements);
        memorySizeInput.addEventListener('input', debouncedUpdateModelRequirements);
        
        // Event listeners - use debounced functions for UI handlers
        modelSelect.addEventListener('change', function() {
            debouncedUpdateModelCard();
            checkCPUOnlyEligibility();
            debouncedUpdateModelRequirements();
        });

        gpuTypeSelect.addEventListener('change', debouncedUpdateModelRequirements);
        inferenceEngineSelect.addEventListener('change', debouncedUpdateModelRequirements);
        
        // Advanced settings event listeners
        advancedToggle.addEventListener('click', toggleAdvancedSettings);
        
        // GPU override toggle event listener
        gpuOverrideToggle.addEventListener('change', function() {
            overrideGpuSelect.disabled = !this.checked;
            debouncedUpdateModelRequirements();
        });
        
        // Update GPU override dropdown change event
        overrideGpuSelect.addEventListener('change', debouncedUpdateModelRequirements);
        
        // Engine multiplier inputs - use debounce
        tgiCpuInput.addEventListener('input', debouncedUpdateModelRequirements);
        tgiMemoryInput.addEventListener('input', debouncedUpdateModelRequirements);
        vllmCpuInput.addEventListener('input', debouncedUpdateModelRequirements);
        vllmMemoryInput.addEventListener('input', debouncedUpdateModelRequirements);
        nimCpuInput.addEventListener('input', debouncedUpdateModelRequirements);
        nimMemoryInput.addEventListener('input', debouncedUpdateModelRequirements);

        // Main action buttons
        deployBtn.addEventListener('click', deployPod);
        resetBtn.addEventListener('click', resetCluster);
        updateNodesBtn.addEventListener('click', updateNodePoolsFromUI);
        simulateBtn.addEventListener('click', function() {
            getElement('scheduler-animation').classList.remove('hidden');
            simulateScheduling();
        });

        // Model filtering
        showHfToggle.addEventListener('change', filterModels);
        showNvidiaToggle.addEventListener('change', filterModels);
        showValidatedOnlyToggle.addEventListener('change', filterModels);
        
        // Node pool management
        document.getElementById('add-nodepool-btn').addEventListener('click', addNodePool);

        // Add event listeners to node pool inputs and selects
        document.querySelectorAll('.node-pool input, .node-pool select').forEach(input => {
            input.addEventListener('change', updateNodePoolsFromUI);
        });

        // function updateNodePoolsFromUI() {
        //     pods = [];
        //     pendingPods = [];
        //     initNodesFromPools();
        //     renderPendingPods();
        //     console.log(`Updated cluster with ${nodes.length} nodes`);
        // }

        // Read node pool configurations
        function readNodePoolConfigurations() {
            const nodePools = [];
            const nodePoolDivs = document.querySelectorAll('.node-pool');

            nodePoolDivs.forEach(poolDiv => {
                const poolId = parseInt(poolDiv.getAttribute('data-pool-id'));
                const nodeCount = parseInt(poolDiv.querySelector('.node-count').value) || 0;
                const gpuCount = parseInt(poolDiv.querySelector('.node-gpu-count').value) || 0;
                const cpuCores = parseInt(poolDiv.querySelector('.node-cpu').value) || 0;
                const memory = parseInt(poolDiv.querySelector('.node-memory').value) || 0;
                const gpuType = poolDiv.querySelector('.node-gpu-type').value || 'CPU-Only';
                const label = poolDiv.querySelector('.node-pool-label').value || `Pool ${poolId}`;

                nodePools.push({
                    id: poolId,
                    nodeCount,
                    gpuCount,
                    cpuCores,
                    memory,
                    gpuType,
                    label
                });
            });

            return nodePools;
        }
        
        // Event delegation for node pool and pod operations
        document.addEventListener('click', function(e) {
            // Pod deletion
            if (e.target.classList.contains('delete-pod-btn')) {
                const podId = parseInt(e.target.getAttribute('data-pod-id'));
                deletePod(podId);
            }
            if (e.target.classList.contains('delete-pending-pod-btn')) {
                const podId = parseInt(e.target.getAttribute('data-pod-id'));
                deletePendingPod(podId);
            }
            
            // Node pool toggle
            if (e.target.classList.contains('toggle-nodepool-btn') || 
                e.target.parentElement.classList.contains('toggle-nodepool-btn')) {
                const btn = e.target.classList.contains('toggle-nodepool-btn') ? 
                            e.target : e.target.parentElement;
                const poolId = btn.getAttribute('data-pool-id');
                toggleNodePoolContent(poolId);
            }
            
            // Node pool removal
            if (e.target.classList.contains('remove-nodepool-btn') || 
                e.target.parentElement.classList.contains('remove-nodepool-btn')) {
                const btn = e.target.classList.contains('remove-nodepool-btn') ? 
                            e.target : e.target.parentElement;
                const poolId = btn.getAttribute('data-pool-id');
                if (poolId !== '1') { // Don't allow removing the first node pool
                    removeNodePool(poolId);
                }
            }
        });
        
        // Toggle CPU-only mode sections visibility
        function toggleCPUOnlyMode(enableCPUOnly) {
            window.isCPUOnlyModeActive = enableCPUOnly;
            
            if (enableCPUOnly) {
                // Hide GPU-related sections
                inferenceEngineSection.classList.add('hidden');
                gpuTypeSection.classList.add('hidden');
                advancedSettingsSection.classList.add('hidden');
                
                // Show CPU-specific controls
                cpuResourceSection.classList.remove('hidden');
                
                // Update requirements display
                gpuRequirement.classList.add('hidden');
                cpuOnlyIndicator.classList.remove('hidden');
                
                console.log('CPU-only mode enabled');
            } else {
                // Show GPU-related sections
                inferenceEngineSection.classList.remove('hidden');
                gpuTypeSection.classList.remove('hidden');
                advancedSettingsSection.classList.remove('hidden');
                
                // Hide CPU-specific controls
                cpuResourceSection.classList.add('hidden');
                
                // Update requirements display
                gpuRequirement.classList.remove('hidden');
                cpuOnlyIndicator.classList.add('hidden');
                
                console.log('CPU-only mode disabled');
            }
        }
        
        // Check if a model is eligible for CPU-only mode
        function checkCPUOnlyEligibility() {
            const selectedOption = modelSelect.options[modelSelect.selectedIndex];
            const provider = selectedOption.getAttribute('data-provider');
            const modelSize = parseInt(selectedOption.getAttribute('data-size') || '100');
            const model = modelSelect.value;
            
            // Only enable CPU-only option for HuggingFace models with <10B parameters
            const isEligible = provider !== 'nvidia' && modelSize < 10 && 
                              modelRequirements[model] && modelRequirements[model]['CPU-Only'];
            
            if (isEligible) {
                cpuOnlySection.classList.remove('hidden');
                return true;
            } else {
                cpuOnlySection.classList.add('hidden');
                
                // Make sure CPU-only mode is turned off if not eligible
                if (window.isCPUOnlyModeActive) {
                    cpuOnlyToggle.checked = false;
                    toggleCPUOnlyMode(false);
                }
                
                return false;
            }
        }

        // Function to filter models based on source and validation status
        function filterModels() {
            const showHf = showHfToggle.checked;
            const showNvidia = showNvidiaToggle.checked;
            const showValidatedOnly = showValidatedOnlyToggle.checked;
            
            const options = modelSelect.querySelectorAll('option');
            let atLeastOneVisible = false;
            
            // First hide all optgroups 
            const optgroups = modelSelect.querySelectorAll('optgroup');
            optgroups.forEach(group => {
                group.style.display = 'none';
            });
            
            options.forEach(option => {
                const source = option.getAttribute('data-source');
                const isValidated = option.getAttribute('data-validated') === 'true';
                
                // Determine if option should be shown
                const showOption = (
                    (source === 'hf' && showHf || source === 'nvidia' && showNvidia) && 
                    (!showValidatedOnly || (showValidatedOnly && isValidated))
                );
                
                // Set display style of option
                option.style.display = showOption ? '' : 'none';
                
                // Show the optgroup if any of its options are visible
                if (showOption) {
                    option.parentNode.style.display = ''; // Show the parent optgroup
                    atLeastOneVisible = true;
                }
            });
            
            // Check if we need to select a different option
            const selectedOption = modelSelect.options[modelSelect.selectedIndex];
            if (selectedOption.style.display === 'none') {
                // Find the first visible option and select it
                const firstVisibleOption = Array.from(options).find(opt => opt.style.display !== 'none');
                if (firstVisibleOption) {
                    firstVisibleOption.selected = true;
                    updateModelCard();
                    checkCPUOnlyEligibility();
                    updateModelRequirements();
                }
            }
            
            // Log the filtering action
            console.log(`Model filtering: HF=${showHf}, NVIDIA=${showNvidia}, Validated only=${showValidatedOnly}`);
        }

        // Helper function to format categories into readable form
        function formatCategories(categoriesStr) {
            if (!categoriesStr) return "";
            
            return categoriesStr.split(',').map(c => {
                // Convert kebab-case to Title Case with spaces
                return c.split('-')
                    .map(word => word.charAt(0).toUpperCase() + word.slice(1))
                    .join(' ');
            }).join(', ');
        }

        // Function to generate text representation of the UI
        function logTextUI() {
            // Header
            console.log('-----TEXT UI-----', '<span class="text-yellow-300 font-bold">KUBERNETES LLM POD SCHEDULING SIMULATOR - TEXT UI VIEW</span>');
            console.log('-----TEXT UI-----', '<span class="text-gray-400">============================================</span>');
            
            // Cluster summary
            console.log('-----TEXT UI-----', '<span class="text-blue-300 font-bold">CLUSTER SUMMARY:</span>');
            
            let totalCpuCapacity = 0;
            let totalMemoryCapacity = 0;
            let totalGpuCapacity = 0;
            let totalCpuUsed = 0;
            let totalMemoryUsed = 0;
            let totalGpuUsed = 0;
            
            for (let i = 0; i < nodes.length; i++) {
                const node = nodes[i];
                totalCpuCapacity += node.totalCpu;
                totalMemoryCapacity += node.totalMemory;
                totalGpuCapacity += node.totalGpu;
                totalCpuUsed += node.usedCpu;
                totalMemoryUsed += node.usedMemory;
                totalGpuUsed += node.usedGpu;
            }
            
            const cpuUtilization = totalCpuCapacity > 0 ? (totalCpuUsed / totalCpuCapacity * 100).toFixed(1) : 0;
            const memoryUtilization = totalMemoryCapacity > 0 ? (totalMemoryUsed / totalMemoryCapacity * 100).toFixed(1) : 0;
            const gpuUtilization = totalGpuCapacity > 0 ? (totalGpuUsed / totalGpuCapacity * 100).toFixed(1) : 0;
            
            console.log('-----TEXT UI-----', `<span class="text-gray-400">Nodes:</span> <span class="text-white">${nodes.length}</span>  <span class="text-gray-400">Scheduled Pods:</span> <span class="text-white">${pods.length}</span>  <span class="text-gray-400">Pending Pods:</span> <span class="text-white">${pendingPods.length}</span>`);
            console.log('-----TEXT UI-----', `<span class="text-gray-400">CPU:</span> <span class="text-white">${totalCpuUsed}/${totalCpuCapacity}</span> cores <span class="text-blue-300">(${cpuUtilization}%)</span>`);
            console.log('-----TEXT UI-----', `<span class="text-gray-400">Memory:</span> <span class="text-white">${totalMemoryUsed}/${totalMemoryCapacity}</span> GB <span class="text-green-300">(${memoryUtilization}%)</span>`);
            console.log('-----TEXT UI-----', `<span class="text-gray-400">GPU:</span> <span class="text-white">${totalGpuUsed}/${totalGpuCapacity}</span> <span class="text-purple-300">(${gpuUtilization}%)</span>`);
            
            console.log('-----TEXT UI-----', '<span class="text-gray-400">============================================</span>');
            
            // Nodes
            console.log('-----TEXT UI-----', '<span class="text-blue-300 font-bold">NODES:</span>');
            
            if (nodes.length === 0) {
                console.log('-----TEXT UI-----', '<span class="text-gray-400">No nodes available</span>');
            } else {
                for (let i = 0; i < nodes.length; i++) {
                    const node = nodes[i];
                    const cpuPercentage = (node.usedCpu / node.totalCpu * 100).toFixed(1);
                    const memoryPercentage = (node.usedMemory / node.totalMemory * 100).toFixed(1);
                    const gpuPercentage = (node.usedGpu / node.totalGpu * 100).toFixed(1);
                    
                    console.log('-----TEXT UI-----', `<span class="text-yellow-300">Node ${node.id}</span> <span class="text-gray-400">(${node.gpuType})</span>`);
                    console.log('-----TEXT UI-----', `  <span class="text-gray-400">CPU:</span> <span class="text-white">${node.usedCpu}/${node.totalCpu}</span> cores <span class="text-blue-300">(${cpuPercentage}%)</span>`);
                    console.log('-----TEXT UI-----', `  <span class="text-gray-400">Memory:</span> <span class="text-white">${node.usedMemory}/${node.totalMemory}</span> GB <span class="text-green-300">(${memoryPercentage}%)</span>`);
                    console.log('-----TEXT UI-----', `  <span class="text-gray-400">GPU:</span> <span class="text-white">${node.usedGpu}/${node.totalGpu}</span> <span class="text-purple-300">(${gpuPercentage}%)</span>`);
                    
                    if (node.pods.length > 0) {
                        console.log('-----TEXT UI-----', `  <span class="text-gray-400">Pods (${node.pods.length}):</span>`);
                        for (let j = 0; j < node.pods.length; j++) {
                            const pod = node.pods[j];
                            if (pod.cpuOnly) {
                                console.log('-----TEXT UI-----', `    <span class="text-blue-300">${pod.displayName} #${pod.id}</span> <span class="text-gray-400">(CPU-only, CPU: ${pod.cpu}, Mem: ${pod.memory}GB)</span>`);
                            } else {
                                console.log('-----TEXT UI-----', `    <span class="text-green-300">${pod.displayName} #${pod.id}</span> <span class="text-gray-400">(${pod.gpu}×${pod.gpuType}, CPU: ${pod.cpu}, Mem: ${pod.memory}GB)</span>`);
                            }
                        }
                    } else {
                        console.log('-----TEXT UI-----', `  <span class="text-gray-400">Pods: None</span>`);
                    }
                    console.log('-----TEXT UI-----', '');
                }
            }
            
            // Pending Pods
            if (pendingPods.length > 0) {
                console.log('-----TEXT UI-----', '<span class="text-red-300 font-bold">PENDING PODS:</span>');
                for (let i = 0; i < pendingPods.length; i++) {
                    const pod = pendingPods[i];
                    if (pod.cpuOnly) {
                        console.log('-----TEXT UI-----', `  <span class="text-blue-300">${pod.displayName} #${pod.id}</span> <span class="text-gray-400">(CPU-only, CPU: ${pod.cpu}, Mem: ${pod.memory}GB)</span>`);
                    } else {
                        console.log('-----TEXT UI-----', `  <span class="text-yellow-300">${pod.displayName} #${pod.id}</span> <span class="text-gray-400">(${pod.gpu}×${pod.gpuType}, CPU: ${pod.cpu}, Mem: ${pod.memory}GB)</span>`);
                    }
                }
            }
            
            console.log('-----TEXT UI-----', '<span class="text-gray-400">============================================</span>');
            
            // Current Settings
            console.log('-----TEXT UI-----', '<span class="text-blue-300 font-bold">CURRENT SETTINGS:</span>');
            
            const selectedOption = modelSelect.options[modelSelect.selectedIndex];
            const modelName = selectedOption.text;
            const contextLength = selectedOption.getAttribute('data-context');
            const categories = formatCategories(selectedOption.getAttribute('data-categories'));
            const gpuType = window.isCPUOnlyModeActive ? "N/A" : gpuTypeSelect.value;
            const inferenceEngine = window.isCPUOnlyModeActive ? "N/A" : inferenceEngineSelect.value;
            const replicas = replicasInput.value;
            const validated = selectedOption.getAttribute('data-validated') === 'true' ? '✓ Yes' : '❌ No';
            const source = selectedOption.getAttribute('data-source') === 'hf' ? 'HuggingFace' : 'NVIDIA NGC';
            
            console.log('-----TEXT UI-----', `<span class="text-gray-400">Selected Model:</span> <span class="text-white">${modelName}</span> <span class="text-green-300">${validated}</span>`);
            console.log('-----TEXT UI-----', `<span class="text-gray-400">Source:</span> <span class="text-white">${source}</span>`);
            console.log('-----TEXT UI-----', `<span class="text-gray-400">Context Length:</span> <span class="text-white">${contextLength}</span>`);
            console.log('-----TEXT UI-----', `<span class="text-gray-400">Use Cases:</span> <span class="text-white">${categories}</span>`);
            
            if (window.isCPUOnlyModeActive) {
                console.log('-----TEXT UI-----', `<span class="text-gray-400">Deployment:</span> <span class="text-blue-300">CPU-Only Mode</span>`);
                console.log('-----TEXT UI-----', `<span class="text-gray-400">CPU Cores:</span> <span class="text-white">${cpuCountInput.value}</span>`);
                console.log('-----TEXT UI-----', `<span class="text-gray-400">Memory Size:</span> <span class="text-white">${memorySizeInput.value} GB</span>`);
            } else {
                console.log('-----TEXT UI-----', `<span class="text-gray-400">Inference Engine:</span> <span class="text-white">${inferenceEngine}</span>`);
                console.log('-----TEXT UI-----', `<span class="text-gray-400">GPU Type:</span> <span class="text-white">${gpuType}</span>`);
                
                if (gpuOverrideToggle.checked) {
                    console.log('-----TEXT UI-----', `<span class="text-gray-400">GPU Override:</span> <span class="text-yellow-300">Enabled (${overrideGpuSelect.value})</span>`);
                }
            }
            
            console.log('-----TEXT UI-----', `<span class="text-gray-400">Replicas:</span> <span class="text-white">${replicas}</span>`);
            
            // Resource requirements
            const reqCpu = getElement('req-cpu');
            const reqMemory = getElement('req-memory');
            const reqGpu = getElement('req-gpu');
            const reqGpuType = getElement('req-gpu-type');
            const reqStorage = getElement('req-storage');
            
            if (window.isCPUOnlyModeActive) {
                console.log('-----TEXT UI-----', `<span class="text-gray-400">Resource Requirements:</span> <span class="text-white">CPU: ${reqCpu.textContent}, Memory: ${reqMemory.textContent}GB, Storage: ${reqStorage.textContent}GB (CPU-Only)</span>`);
            } else {
                console.log('-----TEXT UI-----', `<span class="text-gray-400">Resource Requirements:</span> <span class="text-white">CPU: ${reqCpu.textContent}, Memory: ${reqMemory.textContent}GB, GPU: ${reqGpu.textContent}×${reqGpuType.textContent}, Storage: ${reqStorage.textContent}GB</span>`);
            }
            
            console.log('-----TEXT UI-----', '<span class="text-gray-400">============================================</span>');
        }

        // Format model category tags for display
        function formatCategoryTags(categoriesStr) {
            if (!categoriesStr) return '';
            
            const categories = categoriesStr.split(',');
            const primaryCategories = categories.slice(0, 2); // Show only first 2 categories max
            
            // Convert kebab-case to Title Case for display, and abbreviate long categories
            return primaryCategories.map(category => {
                let displayText = '';
                
                // Special abbreviations for common categories
                if (category === 'text-generation') {
                    displayText = 'Text Gen';
                } else if (category === 'instruction-following') {
                    displayText = 'Instruct';
                } else if (category === 'code-generation') {
                    displayText = 'Code Gen';
                } else if (category === 'code-completion') {
                    displayText = 'Code Compl.';
                } else {
                    // Title-case the category
                    displayText = category.split('-')
                        .map(word => word.charAt(0).toUpperCase() + word.slice(1))
                        .join(' ');
                }
                
                return `<span class="inline-block px-1.5 py-0.5 bg-gray-100 dark:bg-gray-700 rounded text-xxs mr-1">${displayText}</span>`;
            }).join('');
        }
        
        // Format model tags based on the model and engine
        function formatModelTags(modelKey, engine) {
            if (!modelRuntimeTags[modelKey] || !modelRuntimeTags[modelKey][engine]) {
                return '';
            }
            
            const tags = modelRuntimeTags[modelKey][engine];
            
            // Format each tag with a different color based on type
            return tags.map(tag => {
                let bgColor, textColor, icon, displayText;
                
                switch(tag) {
                    case 'text-to-text':
                        bgColor = 'bg-blue-100 dark:bg-blue-900/30';
                        textColor = 'text-blue-800 dark:text-blue-300';
                        icon = 'fas fa-comment';
                        displayText = 'Text Generation';
                        break;
                    case 'tool-calling':
                        bgColor = 'bg-purple-100 dark:bg-purple-900/30';
                        textColor = 'text-purple-800 dark:text-purple-300';
                        icon = 'fas fa-tools';
                        displayText = 'Tool Calling';
                        break;
                    case 'content-safety':
                        bgColor = 'bg-red-100 dark:bg-red-900/30';
                        textColor = 'text-red-800 dark:text-red-300';
                        icon = 'fas fa-shield-alt';
                        displayText = 'Content Safety';
                        break;
                    case 'embedding':
                        bgColor = 'bg-green-100 dark:bg-green-900/30';
                        textColor = 'text-green-800 dark:text-green-300';
                        icon = 'fas fa-vector-square';
                        displayText = 'Embedding';
                        break;
                    case 'reranker':
                        bgColor = 'bg-yellow-100 dark:bg-yellow-900/30';
                        textColor = 'text-yellow-800 dark:text-yellow-300';
                        icon = 'fas fa-sort-amount-up';
                        displayText = 'Reranker';
                        break;
                    default:
                        bgColor = 'bg-gray-100 dark:bg-gray-800';
                        textColor = 'text-gray-800 dark:text-gray-300';
                        icon = 'fas fa-tag';
                        displayText = tag.split('-')
                            .map(word => word.charAt(0).toUpperCase() + word.slice(1))
                            .join(' ');
                }
                
                return `<span class="inline-flex items-center px-2 py-1 rounded text-xs font-medium mr-1 mb-1 ${bgColor} ${textColor}">
                    <i class="${icon} mr-1 text-xs"></i> ${displayText}
                </span>`;
            }).join('');
        }

        // Function to update the model card with the selected model's details
        function updateModelCard() {
            const selectedOption = modelSelect.options[modelSelect.selectedIndex];
            const provider = selectedOption.getAttribute('data-provider');
            const modelName = selectedOption.text.split('/')[1].trim();
            const modelDescription = selectedOption.getAttribute('data-desc');
            const modelContext = selectedOption.getAttribute('data-context');
            const modelCategories = selectedOption.getAttribute('data-categories');
            const modelCardUrl = selectedOption.getAttribute('data-url');
            const modelSource = selectedOption.getAttribute('data-source');
            const isValidated = selectedOption.getAttribute('data-validated') === 'true';
            
            // Get size information from model name
            let paramSize = '';
            if (modelName.includes('70B')) {
                paramSize = '70B';
            } else if (modelName.includes('34B')) {
                paramSize = '34B';
            } else if (modelName.includes('22B')) {
                paramSize = '22B';
            } else if (modelName.includes('13B')) {
                paramSize = '13B';
            } else if (modelName.includes('9B')) {
                paramSize = '9B';
            } else if (modelName.includes('8x7B')) {
                paramSize = '8x7B MoE';
            } else if (modelName.includes('7B')) {
                paramSize = '7B';
            } else if (modelName.includes('3B')) {
                paramSize = '3B';
            } else if (modelName.includes('2B')) {
                paramSize = '2B';
            } else if (modelName.includes('1B')) {
                paramSize = '1B';
            }
            
            // Extract storage from model name
            const storageMatch = selectedOption.text.match(/\((\d+)GB\)/);
            const storage = storageMatch ? storageMatch[1] : '?';
            
            // Provider-specific styling
            let iconClass = 'fas fa-robot';
            let bgColor = 'bg-primary';
            let textColor = 'text-primary';
            
            switch(provider) {
                case 'meta':
                    iconClass = 'fab fa-facebook';
                    bgColor = 'bg-meta';
                    textColor = 'text-meta';
                    break;
                case 'google':
                    iconClass = 'fab fa-google';
                    bgColor = 'bg-google';
                    textColor = 'text-google';
                    break;
                case 'nvidia':
                    iconClass = 'fas fa-microchip';
                    bgColor = 'bg-nvidia';
                    textColor = 'text-nvidia';
                    break;
                case 'mistral':
                    iconClass = 'fas fa-wind';
                    bgColor = 'bg-mistral';
                    textColor = 'text-mistral';
                    break;
                case 'ai21':
                    iconClass = 'fas fa-brain';
                    bgColor = 'bg-ai21';
                    textColor = 'text-ai21';
                    break;
            }
            
            // Source badge
            const sourceBadge = modelSource === 'hf' ? 
                `<span class="source-badge source-hf ml-1.5 flex-shrink-0">
                    <i class="fab fa-hubspot mr-1"></i>HF
                </span>` : 
                `<span class="source-badge source-nvidia ml-1.5 flex-shrink-0">
                    <i class="fas fa-microchip mr-1"></i>NGC
                </span>`;
            
            // Validation mark
            const validatedMark = isValidated ? 
                `<div class="validated-mark ml-1 flex-shrink-0">
                    <i class="fas fa-check text-xs"></i>
                </div>` : '';
            
            // Update the model card with enhanced information
            modelCard.innerHTML = `
                <div class="flex items-start mb-2">
                    <div class="p-2 rounded-full ${bgColor} bg-opacity-10 mr-3 flex-shrink-0">
                        <i class="${iconClass} text-3xl ${textColor}"></i>
                    </div>
                    <div class="flex-grow min-w-0">
                        <div class="flex items-center">
                            <h3 class="text-sm font-semibold text-gray-800 dark:text-gray-200 mb-1 truncate">${selectedOption.text.split('/')[0]}/${modelName}</h3>
                            ${validatedMark}
                            ${sourceBadge}
                        </div>
                        <div class="flex flex-wrap gap-2 mb-1">
                            <span class="inline-flex items-center px-2 py-1 rounded-full text-xs font-medium bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200">
                                <i class="fas fa-tag mr-1"></i> ${paramSize} parameters
                            </span>
                            <span class="inline-flex items-center px-2 py-1 rounded-full text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200">
                                <i class="fas fa-memory mr-1"></i> ${storage}GB storage
                            </span>
                            <span class="inline-flex items-center px-2 py-1 rounded-full text-xs font-medium bg-purple-100 text-purple-800 dark:bg-purple-900 dark:text-purple-200">
                                <i class="fas fa-microchip mr-1"></i> ${selectedOption.getAttribute('data-quantization') || 'float16'}
                            </span>
                        </div>
                        <p class="text-xs text-gray-600 dark:text-gray-400 line-clamp-2">${modelDescription}</p>
                    </div>
                </div>
                <div class="grid grid-cols-2 gap-2 mt-1">
                    <div class="col-span-1">
                        <div class="flex items-center text-xs text-gray-700 dark:text-gray-300">
                            <i class="fas fa-align-left mr-1 text-purple-500"></i> Context: <span class="ml-1 font-medium">${modelContext} tokens</span>
                        </div>
                    </div>
                    <div class="col-span-1">
                        <div class="flex items-center text-xs text-gray-700 dark:text-gray-300">
                            <i class="fas fa-tasks mr-1 text-blue-500"></i> Use cases: 
                            <div class="truncate ml-1">
                                ${formatCategoryTags(modelCategories)}
                            </div>
                        </div>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="flex flex-wrap gap-1" id="model-tags">
                        ${formatModelTags(modelSelect.value, window.isCPUOnlyModeActive ? 'cpu' : inferenceEngineSelect.value)}
                    </div>
                </div>
                <div class="mt-2 flex justify-end">
                    <a href="${modelCardUrl}" target="_blank" class="text-xs ${textColor} hover:underline transition-colors flex items-center">
                        <i class="fas fa-external-link-alt mr-1"></i> View Model Card
                    </a>
                </div>
            `;
            
            // Update provider icon
            const modelIcon = getElement('model-icon');
            modelIcon.innerHTML = `<i class="${iconClass}"></i>`;
        }
        
        // Toggle advanced settings panel
        function toggleAdvancedSettings() {
            advancedContent.classList.toggle('expanded');
            if (advancedContent.classList.contains('expanded')) {
                advancedIcon.className = 'fas fa-chevron-up';
            } else {
                advancedIcon.className = 'fas fa-chevron-down';
            }
        }

        // Function to update GPU override dropdown options based on selected GPU Type
        function updateGpuOverrideOptions(gpuType) {
            if (window.isUpdatingGPUOptions) return;
            window.isUpdatingGPUOptions = true;
            
            try {
                const model = modelSelect.value;
                const isNvidiaModel = model.startsWith('nvidia-');
                
                // Get the base GPU count for this model and GPU type
                let defaultGpuCount = 2; // fallback default
                let supportedCounts = [1, 2, 4, 8]; // fallback supported counts
                
                if (modelRequirements[model] && modelRequirements[model][gpuType]) {
                    const modelReq = modelRequirements[model][gpuType];
                    defaultGpuCount = modelReq.gpu;
                    
                    // Check if the model has specific supported GPU counts
                    if (modelReq.supportedCounts) {
                        supportedCounts = modelReq.supportedCounts;
                    } 
                    // Special handling for NVIDIA models without explicit supportedCounts
                    else if (isNvidiaModel) {
                        // For NVIDIA models, restrict to exactly the default GPU count
                        // unless we have specific supportedCounts defined
                        supportedCounts = [defaultGpuCount];
                    }
                }
                
                // Check if the current GPU type is even supported
                const isGpuTypeSupported = modelRequirements[model] && 
                                          modelRequirements[model][gpuType] &&
                                          modelRequirements[model][gpuType].gpu > 0;
                
                // If GPU type not supported, disable the override toggle and return
                if (!isGpuTypeSupported) {
                    overrideGpuSelect.innerHTML = '<option value="0">N/A</option>';
                    overrideGpuSelect.disabled = true;
                    gpuOverrideToggle.checked = false;
                    gpuOverrideToggle.disabled = true;
                    return;
                } else {
                    gpuOverrideToggle.disabled = false;
                }
                
                // Save current value if possible
                const currentValue = overrideGpuSelect.value;
                
                // Create minimal HTML string instead of DOM operations
                let optionsHtml = '';
                
                // Only show supported GPU counts for this model and GPU type
                for (let i = 0; i < supportedCounts.length; i++) {
                    const count = supportedCounts[i];
                    const selected = count === defaultGpuCount ? ' selected' : '';
                    optionsHtml += `<option value="${count}"${selected}>${count === 1 ? `${count} GPU` : `${count} GPUs`}</option>`;
                }
                
                // Use a single innerHTML update
                overrideGpuSelect.innerHTML = optionsHtml;
                
                // Add information about fixed GPU requirements for NVIDIA models
                if (isNvidiaModel && supportedCounts.length === 1) {
                    // Add a note to the first option to indicate it's fixed
                    const singleOption = overrideGpuSelect.querySelector('option');
                    if (singleOption) {
                        singleOption.textContent += " (fixed)";
                    }
                    
                    // Show a message about fixed GPU counts
                    console.log(`NVIDIA model ${model} requires exactly ${defaultGpuCount} GPUs on ${gpuType} hardware`);
                }
                
                // Try to restore previous selection if it exists
                if (currentValue && supportedCounts.includes(parseInt(currentValue))) {
                    const option = overrideGpuSelect.querySelector(`option[value="${currentValue}"]`);
                    if (option) {
                        option.selected = true;
                    }
                }
                
                // If no options were added (which shouldn't happen), add a default
                if (!optionsHtml) {
                    overrideGpuSelect.innerHTML = `<option value="${defaultGpuCount}">${defaultGpuCount === 1 ? '1 GPU' : `${defaultGpuCount} GPUs`}</option>`;
                }
            } finally {
                // Always release the flag
                setTimeout(() => {
                    window.isUpdatingGPUOptions = false;
                }, 10);
            }
        }

        // Get current inference engine multipliers
        function getInferenceEngineMultipliers() {
            return {
                "tgi": { 
                    cpu: parseFloat(tgiCpuInput.value) || 1.0, 
                    memory: parseFloat(tgiMemoryInput.value) || 1.0 
                },
                "vllm": { 
                    cpu: parseFloat(vllmCpuInput.value) || 1.2, 
                    memory: parseFloat(vllmMemoryInput.value) || 1.5 
                },
                "nvidia-nim": { 
                    cpu: parseFloat(nimCpuInput.value) || 0.8, 
                    memory: parseFloat(nimMemoryInput.value) || 0.8 
                }
            };
        }

        // Update available inference engine options based on model provider
        function updateInferenceEngineOptions(isNvidiaModel) {
            // Prevent recursive updates
            if (window.isUpdatingEngineOptions) return;
            window.isUpdatingEngineOptions = true;
            
            try {
                // NVIDIA models only support NVIDIA NIM
                if (isNvidiaModel) {
                    // Simple string-based update instead of DOM manipulation
                    inferenceEngineSelect.innerHTML = `<option value="nvidia-nim" selected>NVIDIA NIM</option>`;
                    
                    // Update engine icon asynchronously
                    setTimeout(() => {
                        const engineIcon = getElement('engine-icon');
                        engineIcon.innerHTML = `<i class="fas fa-microchip text-nvidia"></i>`;
                    }, 0);
                    
                    // Enable NVIDIA NIM settings in advanced panel
                    const nimSettingsDiv = document.querySelector('div:has(> #nim-cpu)');
                    if (nimSettingsDiv && nimSettingsDiv.closest('.bg-white')) {
                        nimCpuInput.disabled = false;
                        nimMemoryInput.disabled = false;
                        nimSettingsDiv.closest('.bg-white').classList.remove('opacity-50');
                    }
                    
                    console.log('NVIDIA model detected - using NVIDIA NIM inference engine');
                    return;
                }
                
                // For non-NVIDIA models, build a simple HTML string
                const htmlString = `
                    <option value="tgi">Text Generation Inference (TGI)</option>
                    <option value="vllm" selected>vLLM</option>
                `;
                
                // Update with a single DOM operation
                inferenceEngineSelect.innerHTML = htmlString;
                
                // Update the icon asynchronously
                setTimeout(() => {
                    const engineIcon = getElement('engine-icon');
                    engineIcon.innerHTML = `<i class="fas fa-bolt text-yellow-500"></i>`;
                }, 0);
                
                // Disable NVIDIA NIM settings asynchronously
                setTimeout(() => {
                    nimCpuInput.disabled = true;
                    nimMemoryInput.disabled = true;
                    const nimSettingsDiv = document.querySelector('div:has(> #nim-cpu)');
                    if (nimSettingsDiv && nimSettingsDiv.closest('.bg-white')) {
                        nimSettingsDiv.closest('.bg-white').classList.add('opacity-50');
                    }
                }, 0);
            } finally {
                // Always release the flag, with a small delay
                setTimeout(() => {
                    window.isUpdatingEngineOptions = false;
                }, 10);
            }
        }
        
        // Update available GPU types based on model compatibility
        function updateGpuTypeOptions(model) {
            // Save current selection if possible
            const currentGpu = gpuTypeSelect.value;
            
            // Define all GPU options based on Nutanix Enterprise AI document
            if (!window.originalGpuOptions) {
                window.originalGpuOptions = [
                    { value: "A100-80G", text: "NVIDIA A100-80G" },
                    { value: "H100-80G", text: "NVIDIA H100-80G" },
                    { value: "L40S-48G", text: "NVIDIA L40S-48G" },
                    { value: "H100-NVL-94G", text: "NVIDIA H100 NVL-94G" }
                ];
            }
            
            // Get compatible GPUs for this model
            const compatibleGpus = [];
            if (modelRequirements[model]) {
                for (const gpu in modelRequirements[model]) {
                    if (gpu !== 'CPU-Only' && modelRequirements[model][gpu].gpu > 0) {
                        compatibleGpus.push(gpu);
                    }
                }
            }
            
            // Build HTML string instead of DOM operations
            let optionsHtml = '';
            
            // Add compatible GPU options
            window.originalGpuOptions.forEach(gpu => {
                if (compatibleGpus.includes(gpu.value)) {
                    optionsHtml += `<option value="${gpu.value}">${gpu.text}</option>`;
                }
            });
            
            // If no options were added, add at least the compatible options
            if (!optionsHtml) {
                compatibleGpus.forEach(gpuValue => {
                    optionsHtml += `<option value="${gpuValue}">NVIDIA ${gpuValue}</option>`;
                });
            }
            
            // Use a single DOM update
            gpuTypeSelect.innerHTML = optionsHtml;
            
            // Try to restore previous selection if it's still valid
            let selection = gpuTypeSelect.querySelector(`option[value="${currentGpu}"]`);
            if (selection) {
                selection.selected = true;
            }
            
            // Update the GPU icon based on selected GPU (async to avoid layout thrashing)
            setTimeout(() => {
                const gpuIcon = getElement('gpu-icon');
                
                let iconClass = '';
                switch(gpuTypeSelect.value) {
                    case 'A100-80G':
                        iconClass = 'fas fa-microchip text-blue-500';
                        break;
                    case 'H100-80G':
                    case 'H100-NVL-94G':
                        iconClass = 'fas fa-microchip text-green-500';
                        break;
                    case 'L40S-48G':
                        iconClass = 'fas fa-microchip text-purple-500';
                        break;
                    default:
                        iconClass = 'fas fa-microchip text-gray-400';
                }
                
                gpuIcon.innerHTML = `<i class="${iconClass}"></i>`;
            }, 0);
            
            // Update GPU override options based on the new GPU type (async)
            setTimeout(() => updateGpuOverrideOptions(gpuTypeSelect.value), 0);
        }
        
        // Function to get context length based on model, GPU type, and count
        function getContextLength(model, gpuType, gpuCount) {
            // Convert count to string for lookup
            const gpuCountStr = String(gpuCount);
            
            // Check if model exists in the data
            if (!contextLengthData[model]) {
                // Try to get context from model attribute
                const selectedOption = modelSelect.options[modelSelect.selectedIndex];
                const contextAttr = selectedOption.getAttribute('data-context');
                if (contextAttr) {
                    // Parse context like "128K" into number (128000)
                    if (contextAttr.endsWith('K')) {
                        return parseInt(contextAttr.slice(0, -1)) * 1000;
                    }
                    return parseInt(contextAttr);
                }
                return null;
            }
            
            // Get GPU type data
            if (!contextLengthData[model][gpuType]) {
                return null;
            }
            
            // Get context length for specific GPU count
            const contextLength = contextLengthData[model][gpuType][gpuCountStr];
            if (contextLength) {
                return contextLength;
            }
            
            // If exact count not found, find the highest available count that's <= requested count
            const availableCounts = Object.keys(contextLengthData[model][gpuType])
                .map(Number)
                .filter(count => count <= gpuCount)
                .sort((a, b) => b - a);
            
            if (availableCounts.length > 0) {
                return contextLengthData[model][gpuType][String(availableCounts[0])];
            }
            
            // Try to get context from model attribute as fallback
            const selectedOption = modelSelect.options[modelSelect.selectedIndex];
            const contextAttr = selectedOption.getAttribute('data-context');
            if (contextAttr) {
                // Parse context like "128K" into number (128000)
                if (contextAttr.endsWith('K')) {
                    return parseInt(contextAttr.slice(0, -1)) * 1000;
                }
                return parseInt(contextAttr);
            }
            
            return null;
        }

        // Update model requirements display and available inference engines
        function updateModelRequirements() {
            // Use a flag to prevent recursive calls during updates
            if (window.isUpdatingRequirements) return;
            window.isUpdatingRequirements = true;
            
            try {
                const model = modelSelect.value;
                const selectedOption = modelSelect.options[modelSelect.selectedIndex];
                const provider = selectedOption.getAttribute('data-provider');
                
                // Check if this is an NVIDIA model
                const isNvidiaModel = provider === 'nvidia';
                
                // Only update engine options if the provider changed and not in CPU-only mode
                if (!window.isCPUOnlyModeActive && isNvidiaModel !== window.lastNvidiaModelState) {
                    updateInferenceEngineOptions(isNvidiaModel);
                    window.lastNvidiaModelState = isNvidiaModel;
                }
                
                // Only update GPU types if the model changed and not in CPU-only mode
                if (!window.isCPUOnlyModeActive && model !== window.lastModelValue) {
                    updateGpuTypeOptions(model);
                    window.lastModelValue = model;
                    
                    // Since GPU options changed, update the override options
                    const gpuType = gpuTypeSelect.value;
                    setTimeout(() => updateGpuOverrideOptions(gpuType), 0);
                }
                
                // Calculate requirements
                let requirements;
                
                if (window.isCPUOnlyModeActive) {
                    // For CPU-only mode, use manual CPU and memory inputs
                    requirements = {
                        cpu: parseInt(cpuCountInput.value) || 4,
                        memory: parseInt(memorySizeInput.value) || 16,
                        gpu: 0,
                        storage: modelRequirements[model] && modelRequirements[model]['CPU-Only'] ? 
                                modelRequirements[model]['CPU-Only'].storage : 10
                    };
                } else {
                    const gpuType = gpuTypeSelect.value;
                    const inferenceEngine = inferenceEngineSelect.value;
                    
                    // Get inference engine multipliers
                    const engineMultipliers = getInferenceEngineMultipliers();
                    
                    // Check if the model is supported with the selected GPU
                    if (modelRequirements[model] && modelRequirements[model][gpuType] && modelRequirements[model][gpuType].gpu > 0) {
                        let baseReq = {...modelRequirements[model][gpuType]};
                        let multiplier = engineMultipliers[inferenceEngine];
                        
                        // Apply inference engine multiplier
                        requirements = {
                            cpu: Math.ceil(baseReq.cpu * multiplier.cpu),
                            memory: Math.ceil(baseReq.memory * multiplier.memory),
                            gpu: gpuOverrideToggle.checked ? parseInt(overrideGpuSelect.value) : baseReq.gpu,
                            storage: baseReq.storage
                        };
                    } else {
                        // Model not supported with selected GPU
                        requirements = {
                            cpu: "N/A",
                            memory: "N/A",
                            gpu: "N/A",
                            storage: "N/A"
                        };
                        
                        // Make the deploy button non-clickable
                        deployBtn.disabled = true;
                        deployBtn.classList.add('opacity-50', 'cursor-not-allowed');
                        deployBtn.classList.remove('hover:bg-primary-dark');
                        
                        // Update the UI with calculated requirements
                        requestAnimationFrame(() => {
                            const reqCpuSpan = getElement('req-cpu');
                            const reqMemorySpan = getElement('req-memory');
                            const reqGpuSpan = getElement('req-gpu');
                            const reqGpuTypeSpan = getElement('req-gpu-type');
                            const reqStorageSpan = getElement('req-storage');
                            
                            reqCpuSpan.textContent = requirements.cpu;
                            reqMemorySpan.textContent = requirements.memory;
                            reqGpuSpan.textContent = requirements.gpu;
                            reqGpuTypeSpan.textContent = gpuType;
                            reqStorageSpan.textContent = requirements.storage;
                            
                            // Update model tags display
                            const modelTagsDiv = document.getElementById('model-tags');
                            if (modelTagsDiv) {
                                modelTagsDiv.innerHTML = formatModelTags(model, inferenceEngine);
                            }
                        });
                        
                        return;
                    }
                }
                
                // Batch UI updates for better performance
                // Calculate context length based on model, GPU type, and count
                let contextLength = null;
                if (!window.isCPUOnlyModeActive) {
                    const gpuType = gpuTypeSelect.value;
                    const gpuCount = gpuOverrideToggle.checked ? parseInt(overrideGpuSelect.value) : requirements.gpu;
                    
                    contextLength = getContextLength(model, gpuType, gpuCount);
                }
                
                requestAnimationFrame(() => {
                    // Get requirements display elements
                    const reqCpuSpan = getElement('req-cpu');
                    const reqMemorySpan = getElement('req-memory');
                    const reqGpuSpan = getElement('req-gpu');
                    const reqGpuTypeSpan = getElement('req-gpu-type');
                    const reqStorageSpan = getElement('req-storage');
                    
                    // Make sure resource requirements are formatted properly as strings
                    reqCpuSpan.textContent = String(requirements.cpu);
                    reqMemorySpan.textContent = String(requirements.memory);
                    if (!window.isCPUOnlyModeActive) {
                        reqGpuSpan.textContent = String(requirements.gpu);
                        reqGpuTypeSpan.textContent = gpuTypeSelect.value;
                    }
                    reqStorageSpan.textContent = String(requirements.storage);
                    
                    // Update inference engine display
                    const reqEngineSpan = getElement('req-engine');
                    const inferenceEngineDisplay = getElement('inference-engine-display');
                    
                    if (reqEngineSpan) {
                        if (!window.isCPUOnlyModeActive) {
                            // Display the selected inference engine
                            let engineDisplayName = inferenceEngineSelect.value;
                            
                            // Format the engine name for nicer display
                            if (engineDisplayName === 'tgi') engineDisplayName = 'TGI';
                            else if (engineDisplayName === 'vllm') engineDisplayName = 'vLLM';
                            else if (engineDisplayName === 'nvidia-nim') engineDisplayName = 'NVIDIA NIM';
                            
                            reqEngineSpan.textContent = engineDisplayName;
                        } else {
                            // For CPU-only mode, show "CPU" as the engine
                            reqEngineSpan.textContent = "CPU";
                        }
                    }
                    
                    if (inferenceEngineDisplay) {
                        inferenceEngineDisplay.classList.remove('hidden');
                    }
                    
                    // Get context display elements
                    const reqContextSpan = getElement('req-context');
                    const contextLengthDisplay = getElement('context-length-display');
                    
                    if (!window.isCPUOnlyModeActive && contextLength) {
                        // Format context length (e.g., 32768 -> 32K, 131072 -> 128K)
                        let formattedLength;
                        
                        if (contextLength >= 1000) {
                            formattedLength = `${Math.round(contextLength/1024)}K`;
                        } else {
                            formattedLength = contextLength.toString();
                        }
                        
                        if (reqContextSpan) {
                            reqContextSpan.textContent = formattedLength;
                        }
                        if (contextLengthDisplay) {
                            contextLengthDisplay.classList.remove('hidden');
                        }
                    } else {
                        if (reqContextSpan) {
                            reqContextSpan.textContent = "N/A";
                        }
                        if (contextLengthDisplay) {
                            if (window.isCPUOnlyModeActive) {
                                contextLengthDisplay.classList.add('hidden');
                            } else {
                                contextLengthDisplay.classList.remove('hidden');
                            }
                        }
                    }
                    
                    // Update model tags display
                    const modelTagsDiv = document.getElementById('model-tags');
                    if (modelTagsDiv) {
                        const engine = window.isCPUOnlyModeActive ? 'cpu' : inferenceEngineSelect.value;
                        modelTagsDiv.innerHTML = formatModelTags(model, engine);
                    }
                    
                    // Re-enable deploy button
                    deployBtn.disabled = false;
                    deployBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    deployBtn.classList.add('hover:bg-primary-dark');
                });
            } finally {
                // Release the lock after a short delay to ensure we don't process too many events at once
                setTimeout(() => {
                    window.isUpdatingRequirements = false;
                }, 50);
            }
        }

        // Initialize node pool
        function init() {
            console.log("Initializing Kubernetes LLM Pod Scheduling Simulator");

            // Apply initial model filtering
            filterModels();

            // Update the model card
            updateModelCard();

            // Check CPU-only eligibility
            checkCPUOnlyEligibility();

            // Add the default node pool to the tracking array if empty
            if (nodePools.length === 0) {
                const defaultNodeCount = parseInt(document.querySelector('.node-count')?.value) || 1; // Dynamically fetch node count
                const defaultGpuCount = parseInt(document.querySelector('.node-gpu-count')?.value) || 0; // Dynamically fetch GPU count
                const defaultCpuCores = parseInt(document.querySelector('.node-cpu')?.value) || 16; // Dynamically fetch CPU cores
                const defaultMemory = parseInt(document.querySelector('.node-memory')?.value) || 64; // Dynamically fetch memory
                const defaultGpuType = document.querySelector('.node-gpu-type')?.value || 'CPU-Only'; // Dynamically fetch GPU type

                nodePools.push({
                    id: 1,
                    label: 'default',
                    nodeCount: defaultNodeCount,
                    gpuCount: defaultGpuCount,
                    gpuType: defaultGpuType,
                    cpuCores: defaultCpuCores,
                    memory: defaultMemory
                });
            }

            // Update the model requirements display (after a brief delay to avoid race conditions)
            setTimeout(() => {
                updateModelRequirements();

                // Initialize the node pool (after model requirements are set)
                initNodesFromPools();

                console.log("Application initialized successfully");
            }, 100);

            // Add input change listeners for all node pool inputs
            document.querySelectorAll('.node-pool').forEach(nodePool => {
                const inputs = nodePool.querySelectorAll('input, select');
                inputs.forEach(input => {
                    input.addEventListener('change', () => {
                        updateNodePoolSummary(nodePool);
                    });
                    input.addEventListener('input', () => {
                        updateNodePoolSummary(nodePool);
                    });
                });
            });
        }

        function initNodes() {
            const nodeCount = parseInt(document.querySelector('.node-count').value) || 3;
            const gpuCount = parseInt(document.querySelector('.node-gpu-count').value) || 2;
            const cpuCores = parseInt(document.querySelector('.node-cpu').value) || 32;
            const memory = parseInt(document.querySelector('.node-memory').value) || 128;
            const gpuType = document.querySelector('.node-gpu-type').value;
            
            nodes = [];
            
            // Pre-allocate array with correct size for performance
            nodes = new Array(nodeCount);
            
            for (let i = 0; i < nodeCount; i++) {
                nodes[i] = {
                    id: i + 1,
                    totalCpu: cpuCores,
                    totalMemory: memory,
                    totalGpu: gpuCount,
                    gpuType: gpuType,
                    usedCpu: 0,
                    usedMemory: 0,
                    usedGpu: 0,
                    usedStorage: 0,
                    pods: []
                };
            }
            
            renderNodes();
        }

        // Generate a consistent color for a node pool ID
        function getNodePoolColor(poolId, poolLabel) {
            // Define a set of colors for the node pools with both light and dark mode variants
            const poolColors = [
                { light: 'bg-blue-100 text-blue-800 border-blue-200', dark: 'dark:bg-blue-900/30 dark:text-blue-300 dark:border-blue-800' },
                { light: 'bg-green-100 text-green-800 border-green-200', dark: 'dark:bg-green-900/30 dark:text-green-300 dark:border-green-800' },
                { light: 'bg-purple-100 text-purple-800 border-purple-200', dark: 'dark:bg-purple-900/30 dark:text-purple-300 dark:border-purple-800' },
                { light: 'bg-red-100 text-red-800 border-red-200', dark: 'dark:bg-red-900/30 dark:text-red-300 dark:border-red-800' },
                { light: 'bg-yellow-100 text-yellow-800 border-yellow-200', dark: 'dark:bg-yellow-900/30 dark:text-yellow-300 dark:border-yellow-800' },
                { light: 'bg-pink-100 text-pink-800 border-pink-200', dark: 'dark:bg-pink-900/30 dark:text-pink-300 dark:border-pink-800' },
                { light: 'bg-indigo-100 text-indigo-800 border-indigo-200', dark: 'dark:bg-indigo-900/30 dark:text-indigo-300 dark:border-indigo-800' },
                { light: 'bg-orange-100 text-orange-800 border-orange-200', dark: 'dark:bg-orange-900/30 dark:text-orange-300 dark:border-orange-800' }
            ];
            
            // Use consistent color based on pool ID or fallback to a hash of the label
            const colorIndex = (poolId ? (poolId - 1) : Math.abs(poolLabel.split('').reduce((a, b) => {
                a = ((a << 5) - a) + b.charCodeAt(0);
                return a & a;
            }, 0))) % poolColors.length;
            
            return `${poolColors[colorIndex].light} ${poolColors[colorIndex].dark}`;
        }
        
        // Render nodes and their pods - optimized with DocumentFragment
        function initNodesFromPools() {
            // Clear existing nodes
            nodes = [];

            // Read current node pool configurations
            const pools = readNodePoolConfigurations();

            // Create nodes for each pool
            let nodeIndex = 1;
            pools.forEach(pool => {
                for (let i = 0; i < pool.nodeCount; i++) {
                    nodes.push({
                        id: nodeIndex++,
                        totalCpu: pool.cpuCores,
                        totalMemory: pool.memory,
                        totalGpu: pool.gpuCount,
                        gpuType: pool.gpuType,
                        usedCpu: 0,
                        usedMemory: 0,
                        usedGpu: 0,
                        usedStorage: 0,
                        pods: [],
                        poolId: pool.id,
                        poolLabel: pool.label
                    });
                }
            });

            renderNodes();
            console.log(`Initialized cluster with ${nodes.length} nodes from ${pools.length} node pools`);
        }

        function renderNodes() {
            // Use DocumentFragment for batch DOM operations
            const fragment = document.createDocumentFragment();
            
            for (let i = 0; i < nodes.length; i++) {
                const node = nodes[i];
                const nodeDiv = document.createElement('div');
                
                // Add a subtle border color based on the node pool
                const poolColorClasses = getNodePoolColor(node.poolId, node.poolLabel || 'default');
                nodeDiv.className = `node bg-gray-100 dark:bg-gray-700 rounded-lg p-3 mb-4 hover:shadow-md transition-shadow border-l-4 ${poolColorClasses.replace(/bg-|text-/g, 'border-l-')}`;
                
                // Use template strings for better performance on HTML construction
                // Extract the text color from the pool color classes for icons
                const iconColorMatch = poolColorClasses.match(/text-([a-z]+-[0-9]+)/);
                const iconColor = iconColorMatch ? iconColorMatch[0] : 'text-gray-500';
                
                nodeDiv.innerHTML = `
                    <div class="flex justify-between items-center mb-2">
                        <h3 class="font-medium flex items-center flex-wrap">
                            <i class="fas fa-server mr-2 ${iconColor}"></i>
                            <span>Node ${node.id}</span> 
                            <span class="text-xs font-normal ml-1 px-2 py-0.5 bg-green-100 dark:bg-green-900 text-green-800 dark:text-green-200 rounded">${node.gpuType}</span>
                            
                            <!-- Node Pool Label Badge -->
                            <span class="text-xs ml-1 px-2 py-0.5 ${poolColorClasses} rounded-full border flex items-center">
                                <i class="fas fa-layer-group mr-1 text-xs"></i>
                                ${node.poolLabel || 'default'}
                            </span>
                        </h3>
                        <span class="text-sm px-2 py-0.5 bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 rounded flex items-center">
                            <i class="fas fa-cube mr-1"></i> ${node.pods.length} pod(s)
                        </span>
                    </div>
                    
                    <div class="grid grid-cols-4 gap-2 mb-3">
                        <!-- CPU usage bar -->
                        <div class="resource">
                            <div class="flex justify-between text-xs mb-1">
                                <span>CPU:</span>
                                <span class="font-medium">${node.usedCpu}/${node.totalCpu} cores</span>
                            </div>
                            <div class="h-2 bg-gray-300 dark:bg-gray-600 rounded-full overflow-hidden">
                                <div class="h-full bg-blue-500 resource-bar" style="width: ${(node.usedCpu / node.totalCpu) * 100}%"></div>
                            </div>
                        </div>
                        
                        <!-- Memory usage bar -->
                        <div class="resource">
                            <div class="flex justify-between text-xs mb-1">
                                <span>Memory:</span>
                                <span class="font-medium">${node.usedMemory}/${node.totalMemory} GB</span>
                            </div>
                            <div class="h-2 bg-gray-300 dark:bg-gray-600 rounded-full overflow-hidden">
                                <div class="h-full bg-green-500 resource-bar" style="width: ${(node.usedMemory / node.totalMemory) * 100}%"></div>
                            </div>
                        </div>
                        
                        <!-- GPU usage bar -->
                        <div class="resource">
                            <div class="flex justify-between text-xs mb-1">
                                <span>GPU:</span>
                                <span class="font-medium">${node.usedGpu}/${node.totalGpu}</span>
                            </div>
                            <div class="h-2 bg-gray-300 dark:bg-gray-600 rounded-full overflow-hidden">
                                <div class="h-full bg-purple-500 resource-bar" style="width: ${(node.usedGpu / node.totalGpu) * 100}%"></div>
                            </div>
                        </div>
                        
                        <!-- Storage display -->
                        <div class="resource">
                            <div class="flex justify-between text-xs mb-1">
                                <span>Storage:</span>
                                <span class="font-medium">${node.usedStorage} GB</span>
                            </div>
                            <div class="h-2 bg-gray-300 dark:bg-gray-600 rounded-full overflow-hidden">
                                <div class="h-full bg-yellow-500 resource-bar" style="width: ${Math.min(node.usedStorage / 500 * 100, 100)}%"></div>
                            </div>
                        </div>
                    </div>
                    
                    <div id="node${node.id}-pods" class="flex flex-wrap gap-2 min-h-8"></div>
                    
                    ${node.pods.length === 0 ? 
                        `<div class="text-center py-3 text-sm text-gray-500 dark:text-gray-400 bg-gray-50 dark:bg-gray-800 rounded border border-dashed border-gray-300 dark:border-gray-600">
                            <i class="fas fa-inbox mr-1"></i> No pods scheduled on this node
                        </div>` : ''
                    }
                `;
                
                // Add pods to the node if there are any
                if (node.pods.length > 0) {
                    const podsContainer = nodeDiv.querySelector(`#node${node.id}-pods`);
                    // Create a pod fragment to append all pods at once
                    const podsFragment = document.createDocumentFragment();
                    
                    for (let j = 0; j < node.pods.length; j++) {
                        const podDiv = createPodElement(node.pods[j]);
                        podsFragment.appendChild(podDiv);
                    }
                    
                    podsContainer.appendChild(podsFragment);
                }
                
                fragment.appendChild(nodeDiv);
            }
            
            // Clear and append in a single operation
            nodesContainer.innerHTML = '';
            nodesContainer.appendChild(fragment);
        }

        // Create a pod element
        function createPodElement(pod) {
            const podDiv = document.createElement('div');
            
            // Base pod class
            let baseClass = 'pod px-2 py-1 text-white text-xs rounded flex items-center space-x-1 hover:bg-opacity-90 transition-colors duration-200 shadow-sm pod-scheduling animate-fadeIn optimize-gpu';
            
            // Set provider-specific styling or CPU-only styling
            let iconClass = 'fas fa-robot';
            
            if (pod.cpuOnly) {
                // CPU-only pod styling
                podDiv.className = `${baseClass} bg-indigo-600 cpu-pod`;
                iconClass = 'fas fa-microchip';
            } else {
                // GPU pod styling
                podDiv.className = `${baseClass} bg-primary`;
                
                switch(pod.provider) {
                    case 'meta':
                        iconClass = 'fab fa-facebook';
                        podDiv.classList.add('bg-meta');
                        podDiv.classList.remove('bg-primary');
                        break;
                    case 'google':
                        iconClass = 'fab fa-google';
                        podDiv.classList.add('bg-google');
                        podDiv.classList.remove('bg-primary');
                        break;
                    case 'nvidia':
                        iconClass = 'fas fa-microchip';
                        podDiv.classList.add('bg-nvidia');
                        podDiv.classList.remove('bg-primary');
                        break;
                    case 'mistral':
                        iconClass = 'fas fa-wind';
                        podDiv.classList.add('bg-mistral');
                        podDiv.classList.remove('bg-primary');
                        break;
                    case 'ai21':
                        iconClass = 'fas fa-brain';
                        podDiv.classList.add('bg-ai21');
                        podDiv.classList.remove('bg-primary');
                        break;
                }
            }
            
            // Pod content
            if (pod.cpuOnly) {
                podDiv.innerHTML = `
                    <i class="${iconClass} text-blue-300 mr-1"></i>
                    <span>${pod.displayName}</span>
                    <span class="ml-1 text-xs opacity-75">(CPU)</span>
                    <button class="delete-pod-btn ml-2 text-white hover:text-red-200 bg-red-500 hover:bg-red-600 rounded-full w-4 h-4 flex items-center justify-center transition-colors" data-pod-id="${pod.id}">×</button>
                `;
            } else {
                podDiv.innerHTML = `
                    <i class="${iconClass} text-blue-300 mr-1"></i>
                    <span>${pod.displayName}</span>
                    <span class="ml-1 text-xs opacity-75">(${pod.gpu}×${pod.gpuType})</span>
                    <button class="delete-pod-btn ml-2 text-white hover:text-red-200 bg-red-500 hover:bg-red-600 rounded-full w-4 h-4 flex items-center justify-center transition-colors" data-pod-id="${pod.id}">×</button>
                `;
            }
            
            return podDiv;
        }

        // Render pending pods
        function renderPendingPods() {
            if (pendingPods.length > 0) {
                pendingPodsContainer.classList.remove('hidden');
                
                // Update pending info text for CPU-only pods if needed
                const pendingInfo = getElement('pending-info');
                const hasCPUOnlyPods = pendingPods.some(pod => pod.cpuOnly);
                const hasGPUTypeIncompatibility = pendingPods.some(pod => !pod.cpuOnly && !nodes.some(node => node.gpuType === pod.gpuType));
                
                if (hasCPUOnlyPods && hasGPUTypeIncompatibility) {
                    pendingInfo.innerHTML = `
                        <i class="fas fa-exclamation-triangle mr-2 mt-0.5"></i>
                        <span>These pods can't be scheduled due to insufficient resources and GPU type incompatibility. Consider updating the node pool configuration.</span>
                    `;
                } else if (hasCPUOnlyPods) {
                    pendingInfo.innerHTML = `
                        <i class="fas fa-exclamation-triangle mr-2 mt-0.5"></i>
                        <span>These pods can't be scheduled due to insufficient CPU/memory resources. Consider updating the node pool configuration or reducing resource requirements.</span>
                    `;
                } else if (hasGPUTypeIncompatibility) {
                    pendingInfo.innerHTML = `
                        <i class="fas fa-exclamation-triangle mr-2 mt-0.5"></i>
                        <span>These pods can't be scheduled due to GPU type incompatibility. Add nodes with compatible GPU types (${pendingPods.map(p => p.gpuType).filter((v, i, a) => a.indexOf(v) === i).join(', ')}).</span>
                    `;
                } else {
                    pendingInfo.innerHTML = `
                        <i class="fas fa-exclamation-triangle mr-2 mt-0.5"></i>
                        <span>These pods can't be scheduled due to insufficient GPU resources. Consider updating the node pool configuration or reducing GPU requirements.</span>
                    `;
                }
                
                // Use DocumentFragment for batch DOM operations
                const fragment = document.createDocumentFragment();
                
                for (let i = 0; i < pendingPods.length; i++) {
                    const pod = pendingPods[i];
                    const podDiv = document.createElement('div');
                    
                    if (pod.cpuOnly) {
                        podDiv.className = 'pending-pod px-2 py-1 bg-blue-500 text-white text-xs rounded flex items-center hover:bg-blue-600 transition-colors duration-200 shadow-sm optimize-gpu';
                        podDiv.innerHTML = `
                            <i class="fas fa-microchip text-blue-300 mr-1"></i>
                            <span>${pod.displayName} #${pod.id}</span>
                            <span class="ml-1 text-xs opacity-75">(CPU)</span>
                            <button class="delete-pending-pod-btn ml-2 text-white hover:text-red-200 bg-red-500 hover:bg-red-600 rounded-full w-4 h-4 flex items-center justify-center transition-colors" data-pod-id="${pod.id}">×</button>
                        `;
                    } else {
                        // Check if there's a node with compatible GPU type
                        const hasCompatibleNode = nodes.some(node => node.gpuType === pod.gpuType);
                        // Use red background for GPU type incompatibility
                        const bgClass = hasCompatibleNode ? 'bg-yellow-500 hover:bg-yellow-600' : 'bg-red-500 hover:bg-red-600';
                        
                        podDiv.className = `pending-pod px-2 py-1 ${bgClass} text-white text-xs rounded flex items-center transition-colors duration-200 shadow-sm optimize-gpu`;
                        
                        // Set provider-specific icon
                        let iconClass = 'fas fa-robot';
                        switch(pod.provider) {
                            case 'meta': iconClass = 'fab fa-facebook'; break;
                            case 'google': iconClass = 'fab fa-google'; break;
                            case 'nvidia': iconClass = 'fas fa-microchip'; break;
                            case 'mistral': iconClass = 'fas fa-wind'; break;
                            case 'ai21': iconClass = 'fas fa-brain'; break;
                        }
                        
                        podDiv.innerHTML = `
                            <i class="${iconClass} text-yellow-300 mr-1"></i>
                            <span>${pod.displayName} #${pod.id}</span>
                            <span class="ml-1 text-xs opacity-75">(${pod.gpu}×${pod.gpuType})</span>
                            <button class="delete-pending-pod-btn ml-2 text-white hover:text-red-200 bg-red-500 hover:bg-red-600 rounded-full w-4 h-4 flex items-center justify-center transition-colors" data-pod-id="${pod.id}">×</button>
                        `;
                    }
                    
                    fragment.appendChild(podDiv);
                }
                
                // Clear and append in a single operation
                pendingPodsDiv.innerHTML = '';
                pendingPodsDiv.appendChild(fragment);
            } else {
                pendingPodsContainer.classList.add('hidden');
            }
        }

        // Schedule a pod to a node if resources are available
        function schedulePod(pod) {
            // Sort nodes by least allocated resources first (cache this calculation)
            const sortedNodes = nodes.map((node, index) => {
                // Calculate resource utilization percentage for each node
                const utilization = (node.usedCpu / node.totalCpu + 
                                     node.usedMemory / node.totalMemory + 
                                     (pod.cpuOnly ? 0 : node.usedGpu / node.totalGpu)) / (pod.cpuOnly ? 2 : 3);
                return { node, index, utilization };
            }).sort((a, b) => a.utilization - b.utilization)
              .map(item => item.node);
            
            // Try to find a node with enough resources and compatible GPU type
            for (let i = 0; i < sortedNodes.length; i++) {
                const node = sortedNodes[i];
                
                // Check if the node has compatible GPU type and sufficient resources
                const gpuCompatible = pod.cpuOnly || !pod.gpuType || !node.gpuType || node.gpuType === pod.gpuType;
                const cpuAvailable = node.usedCpu + pod.cpu <= node.totalCpu;
                const memoryAvailable = node.usedMemory + pod.memory <= node.totalMemory;
                const gpuAvailable = pod.cpuOnly || node.usedGpu + pod.gpu <= node.totalGpu;
                
                if (gpuCompatible && cpuAvailable && memoryAvailable && gpuAvailable) {
                    // Assign pod to this node
                    node.usedCpu += pod.cpu;
                    node.usedMemory += pod.memory;
                    if (!pod.cpuOnly) {
                        node.usedGpu += pod.gpu;
                    }
                    node.usedStorage += pod.storage;
                    
                    // Update pod's GPU type to match the node it's scheduled on (if not CPU-only)
                    let updatedPod;
                    if (pod.cpuOnly) {
                        updatedPod = {...pod};
                    } else {
                        updatedPod = {...pod, gpuType: node.gpuType};
                    }
                    
                    node.pods.push(updatedPod);
                    pods.push(updatedPod);
                    
                    if (pod.cpuOnly) {
                        console.log(`Scheduled CPU-only pod ${pod.id} (${pod.displayName}) on node ${node.id}`);
                    } else {
                        console.log(`Scheduled pod ${pod.id} (${pod.displayName}) on node ${node.id}`);
                    }
                    return true;
                }
            }
            
            // If no node has enough resources or compatible GPU type, add to pending pods
            pendingPods.push(pod);
            if (pod.cpuOnly) {
                console.log(`CPU-only pod ${pod.id} (${pod.displayName}) added to pending queue due to insufficient resources`);
            } else {
                console.log(`Pod ${pod.id} (${pod.displayName}) added to pending queue due to insufficient resources`);
            }
            return false;
        }

        // Deploy a pod based on current settings
        function deployPod() {
            // Get UI elements
            const deployBtn = getElement('deploy-btn');
            const deployText = getElement('deploy-text');
            const deployProgress = getElement('deploy-progress');
            const deployStatus = getElement('deploy-status');
            
            // Show loading state
            deployBtn.disabled = true;
            deployBtn.classList.add('opacity-80');
            deployText.textContent = 'Deploying...';
            deployProgress.classList.remove('hidden');
            
            // Get model options and provider
            const model = modelSelect.value;
            const displayName = modelSelect.options[modelSelect.selectedIndex].text.split('/')[1].trim();
            const provider = modelSelect.options[modelSelect.selectedIndex].getAttribute('data-provider');
            const gpuType = window.isCPUOnlyModeActive ? 'CPU-Only' : gpuTypeSelect.value;
            const inferenceEngine = window.isCPUOnlyModeActive ? 'cpu' : inferenceEngineSelect.value;
            const replicas = parseInt(replicasInput.value) || 1;
            
            if (window.isCPUOnlyModeActive) {
                console.log(`Deploying ${replicas}× ${displayName} in CPU-only mode`);
            } else {
                console.log(`Deploying ${replicas}× ${displayName} with ${inferenceEngine} on ${gpuType}`);
            }
            
            // Use requestAnimationFrame for smoother UI updates
            requestAnimationFrame(() => {
                deployStatus.textContent = 'Creating pod resources...';
                
                // Use setTimeout with promise for better control and chaining
                new Promise(resolve => setTimeout(resolve, 400))
                .then(() => {
                    deployStatus.textContent = 'Scheduling pods...';
                    return new Promise(resolve => setTimeout(resolve, 400));
                })
                .then(() => {
                    let requirements;
                    
                    if (window.isCPUOnlyModeActive) {
                        // For CPU-only deployments
                        requirements = {
                            cpu: parseInt(cpuCountInput.value) || 4,
                            memory: parseInt(memorySizeInput.value) || 16,
                            gpu: 0,
                            storage: modelRequirements[model]['CPU-Only'] ? modelRequirements[model]['CPU-Only'].storage : 10
                        };
                        
                        // Create pods and try to schedule them
                        for (let i = 0; i < replicas; i++) {
                            const pod = {
                                id: nextPodId++,
                                model: model,
                                displayName: displayName,
                                provider: provider,
                                inferenceEngine: 'cpu',
                                cpuOnly: true,
                                gpu: 0,
                                cpu: requirements.cpu,
                                memory: requirements.memory,
                                storage: requirements.storage
                            };
                            
                            schedulePod(pod);
                        }
                    } else {
                        // For GPU deployments
                        // Get inference engine multipliers
                        const engineMultipliers = getInferenceEngineMultipliers();
                        
                        // Check if the model is supported with the selected GPU
                        if (modelRequirements[model] && modelRequirements[model][gpuType] && modelRequirements[model][gpuType].gpu > 0) {
                            let baseReq = {...modelRequirements[model][gpuType]};
                            let multiplier = engineMultipliers[inferenceEngine];
                            
                            // Apply inference engine multiplier and any overrides
                            requirements = {
                                cpu: Math.ceil(baseReq.cpu * multiplier.cpu),
                                memory: Math.ceil(baseReq.memory * multiplier.memory),
                                gpu: gpuOverrideToggle.checked ? parseInt(overrideGpuSelect.value) : baseReq.gpu,
                                storage: baseReq.storage
                            };
                            
                            // Create pods and try to schedule them
                            for (let i = 0; i < replicas; i++) {
                                const pod = {
                                    id: nextPodId++,
                                    model: model,
                                    displayName: displayName,
                                    provider: provider,
                                    inferenceEngine: inferenceEngine,
                                    gpuType: gpuType,
                                    cpu: requirements.cpu,
                                    memory: requirements.memory,
                                    gpu: requirements.gpu,
                                    storage: requirements.storage,
                                    cpuOnly: false
                                };
                                
                                schedulePod(pod);
                            }
                        }
                    }
                    
                    renderNodes();
                    renderPendingPods();
                    
                    // Log the text UI after deployment
                    if (consoleMode === 'text-ui') {
                        logTextUI();
                    }
                    
                    return new Promise(resolve => setTimeout(resolve, 400));
                })
                .then(() => {
                    // Reset button state
                    deployBtn.disabled = false;
                    deployBtn.classList.remove('opacity-80');
                    deployText.textContent = 'Deploy Model';
                    deployProgress.classList.add('hidden');
                });
            });
        }

        // Delete a scheduled pod
        function deletePod(podId) {
            for (let i = 0; i < nodes.length; i++) {
                const node = nodes[i];
                const podIndex = node.pods.findIndex(p => p.id === podId);
                
                if (podIndex !== -1) {
                    const pod = node.pods[podIndex];
                    
                    // Release resources
                    node.usedCpu -= pod.cpu;
                    node.usedMemory -= pod.memory;
                    if (!pod.cpuOnly) {
                        node.usedGpu -= pod.gpu;
                    }
                    node.usedStorage -= pod.storage;
                    
                    // Remove pod from node
                    node.pods.splice(podIndex, 1);
                    
                    // Remove pod from global pods array
                    const globalPodIndex = pods.findIndex(p => p.id === podId);
                    if (globalPodIndex !== -1) {
                        pods.splice(globalPodIndex, 1);
                    }
                    
                    console.log(`Deleted pod ${podId} from node ${node.id}, resources released`);
                    
                    // Try to schedule pending pods
                    checkPendingPods();
                    
                    renderNodes();
                    renderPendingPods();
                    
                    // Log the text UI after deleting a pod
                    if (consoleMode === 'text-ui') {
                        logTextUI();
                    }
                    
                    return;
                }
            }
        }

        // Delete a pending pod
        function deletePendingPod(podId) {
            const podIndex = pendingPods.findIndex(p => p.id === podId);
            if (podIndex !== -1) {
                const pod = pendingPods[podIndex];
                pendingPods.splice(podIndex, 1);
                console.log(`Deleted pending pod ${podId} (${pod.displayName})`);
                renderPendingPods();
                
                // Log the text UI after deleting a pending pod
                if (consoleMode === 'text-ui') {
                    logTextUI();
                }
            }
        }

        // Try to schedule pending pods when resources become available
        function checkPendingPods() {
            if (pendingPods.length === 0) return;
            
            const podsToSchedule = [...pendingPods];
            pendingPods = [];
            
            let scheduledCount = 0;
            
            for (let i = 0; i < podsToSchedule.length; i++) {
                const scheduled = schedulePod(podsToSchedule[i]);
                if (scheduled) {
                    scheduledCount++;
                }
            }
            
            console.log(`Pending pods check: ${scheduledCount} scheduled, ${pendingPods.length} still pending`);
        }

        // Reset the cluster state
        function resetCluster() {
            console.log("Resetting cluster state");
            
            pods = [];
            pendingPods = [];
            nextPodId = 1;
            
            initNodesFromPools();
            renderPendingPods();
            
            // Log the text UI after reset
            if (consoleMode === 'text-ui') {
                logTextUI();
            }
        }

        // Simulate the scheduling process in the animation area
        function simulateScheduling() {
            const animationContainer = getElement('animation-container');
            const schedulingStatus = getElement('scheduling-status');
            const podTemplate = getElement('pod-template');
            const nodeBoxes = document.querySelectorAll('.node-box');
            
            // Reset animation state
            nodeBoxes.forEach(box => {
                box.classList.remove('border-primary', 'border-solid', 'scale-110');
                box.classList.add('border-dashed', 'border-gray-300', 'dark:border-gray-600');
            });
            
            console.log("Starting scheduler animation");
            
            // Adjust pod template based on CPU-only mode
            if (window.isCPUOnlyModeActive) {
                podTemplate.classList.add('bg-indigo-600');
                podTemplate.classList.remove('bg-meta');
                podTemplate.innerHTML = `
                    <i class="fas fa-microchip text-blue-300 text-2xl"></i>
                    <span class="text-xs mt-1">${modelSelect.options[modelSelect.selectedIndex].text.split('/')[1].split(' ')[0]}</span>
                `;
            } else {
                podTemplate.classList.remove('bg-indigo-600');
                // Set pod template based on provider
                const provider = modelSelect.options[modelSelect.selectedIndex].getAttribute('data-provider');
                switch(provider) {
                    case 'meta':
                        podTemplate.className = 'w-16 h-16 bg-meta text-white rounded-lg flex flex-col items-center justify-center mr-6 shadow-lg animate-float optimize-gpu';
                        podTemplate.innerHTML = `
                            <i class="fab fa-facebook text-2xl"></i>
                            <span class="text-xs mt-1">${modelSelect.options[modelSelect.selectedIndex].text.split('/')[1].split(' ')[0]}</span>
                        `;
                        break;
                    case 'google':
                        podTemplate.className = 'w-16 h-16 bg-google text-white rounded-lg flex flex-col items-center justify-center mr-6 shadow-lg animate-float optimize-gpu';
                        podTemplate.innerHTML = `
                            <i class="fab fa-google text-2xl"></i>
                            <span class="text-xs mt-1">${modelSelect.options[modelSelect.selectedIndex].text.split('/')[1].split(' ')[0]}</span>
                        `;
                        break;
                    case 'nvidia':
                        podTemplate.className = 'w-16 h-16 bg-nvidia text-white rounded-lg flex flex-col items-center justify-center mr-6 shadow-lg animate-float optimize-gpu';
                        podTemplate.innerHTML = `
                            <i class="fas fa-microchip text-2xl"></i>
                            <span class="text-xs mt-1">${modelSelect.options[modelSelect.selectedIndex].text.split('/')[1].split(' ')[0]}</span>
                        `;
                        break;
                    case 'mistral':
                        podTemplate.className = 'w-16 h-16 bg-mistral text-white rounded-lg flex flex-col items-center justify-center mr-6 shadow-lg animate-float optimize-gpu';
                        podTemplate.innerHTML = `
                            <i class="fas fa-wind text-2xl"></i>
                            <span class="text-xs mt-1">${modelSelect.options[modelSelect.selectedIndex].text.split('/')[1].split(' ')[0]}</span>
                        `;
                        break;
                    case 'ai21':
                        podTemplate.className = 'w-16 h-16 bg-ai21 text-white rounded-lg flex flex-col items-center justify-center mr-6 shadow-lg animate-float optimize-gpu';
                        podTemplate.innerHTML = `
                            <i class="fas fa-brain text-2xl"></i>
                            <span class="text-xs mt-1">${modelSelect.options[modelSelect.selectedIndex].text.split('/')[1].split(' ')[0]}</span>
                        `;
                        break;
                }
            }
            
            // Use RAF and promises for better animation timing
            schedulingStatus.textContent = 'Initializing scheduler...';
            
            // Chain animations with promises for better control and performance
            const waitTime = (ms) => new Promise(resolve => setTimeout(resolve, ms));
            
            Promise.resolve()
                .then(() => waitTime(400))
                .then(() => {
                    schedulingStatus.textContent = 'Finding optimal node placement...';
                    return waitTime(400);
                })
                .then(async () => {
                    for (let i = 0; i < nodeBoxes.length; i++) {
                        // Highlight the current node being evaluated
                        nodeBoxes[i].classList.add('border-blue-500', 'border-solid');
                        nodeBoxes[i].classList.remove('border-dashed', 'border-gray-300', 'dark:border-gray-600');
                        schedulingStatus.textContent = `Checking Node ${i + 1} resources...`;
                        await waitTime(400);
            
                        // Simulate resource check
                        const hasSufficientResources = i === nodeBoxes.length - 1; // Assume the last node has sufficient resources
                        schedulingStatus.textContent = hasSufficientResources
                            ? `Node ${i + 1} has sufficient resources ✓`
                            : `Node ${i + 1} has insufficient resources...`;
            
                        // Update node styles based on the result
                        if (hasSufficientResources) {
                            nodeBoxes[i].classList.add('border-primary', 'border-solid', 'scale-110');
                            nodeBoxes[i].classList.remove('border-blue-500', 'border-dashed', 'border-gray-300', 'dark:border-gray-600');
                            break;
                        } else {
                            nodeBoxes[i].classList.remove('border-blue-500', 'border-solid');
                            nodeBoxes[i].classList.add('border-dashed', 'border-gray-300', 'dark:border-gray-600');
                        }
            
                        await waitTime(400);
                    }
                })
                .then(() => {
                    // Animate pod moving to the selected node
                    podTemplate.classList.add('translate-x-32', 'scale-75');
                    podTemplate.style.transition = 'all 0.8s cubic-bezier(0.68, -0.55, 0.27, 1.55)';
                    return waitTime(800);
                })
                .then(() => {
                    // Update resource usage in the selected node
                    const selectedNodeIndex = nodeBoxes.length - 1; // Assume the last node is selected
                    if (!window.isCPUOnlyModeActive) {
                        const gpuBar = nodeBoxes[selectedNodeIndex].querySelector('.bg-green-500');
                        gpuBar.style.width = '100%';
                        nodeBoxes[selectedNodeIndex].querySelector('.text-xs:last-child').textContent = '2/2 GPU';
                    }
                    schedulingStatus.textContent = 'Pod scheduled successfully ✓';
                    console.log("Scheduling animation: pod scheduled successfully");
                    return waitTime(1000);
                })
                .then(() => {
                    // Hide animation area
                    getElement('scheduler-animation').classList.add('hidden');
            
                    // Reset pod position for next time
                    podTemplate.classList.remove('translate-x-32', 'scale-75');
            
                    // Create a new pod in the node
                    createNewPodInNode(nodeBoxes.length - 1); // Pass the selected node index
                });
        }
        
        // Create a new pod in the specified node (for simulation)
        function createNewPodInNode(nodeIndex) {
            // Get node from the nodes array
            const node = nodes[nodeIndex];
            if (!node) return;
            
            // Get model options and provider
            const model = modelSelect.value;
            const displayName = modelSelect.options[modelSelect.selectedIndex].text.split('/')[1].trim();
            const provider = modelSelect.options[modelSelect.selectedIndex].getAttribute('data-provider');
            
            let pod;
            
            if (window.isCPUOnlyModeActive) {
                // CPU-only simulation
                const cpu = parseInt(cpuCountInput.value) || 4;
                const memory = parseInt(memorySizeInput.value) || 16;
                const storage = modelRequirements[model]['CPU-Only'] ? modelRequirements[model]['CPU-Only'].storage : 10;
                
                // Check if node has enough CPU and memory
                if (node.usedCpu + cpu > node.totalCpu || node.usedMemory + memory > node.totalMemory) {
                    console.log(`Cannot create simulated CPU-only pod: Node ${node.id} has insufficient resources`);
                    return;
                }
                
                // Create CPU-only pod
                pod = {
                    id: nextPodId++,
                    model: model,
                    displayName: displayName,
                    provider: provider,
                    inferenceEngine: 'cpu',
                    cpuOnly: true,
                    gpu: 0,
                    cpu: cpu,
                    memory: memory,
                    storage: storage
                };
                
                // Update node resources
                node.usedCpu += pod.cpu;
                node.usedMemory += pod.memory;
                node.usedStorage += pod.storage;
                
                console.log(`Created simulated CPU-only pod ${pod.id} (${pod.displayName}) on node ${node.id}`);
            } else {
                // GPU simulation
                const gpuType = gpuTypeSelect.value;
                const inferenceEngine = inferenceEngineSelect.value;
                
                // Get inference engine multipliers
                const engineMultipliers = getInferenceEngineMultipliers();
                
                // Check if the model is supported with the selected GPU
                if (modelRequirements[model] && modelRequirements[model][gpuType] && modelRequirements[model][gpuType].gpu > 0) {
                    let baseReq = {...modelRequirements[model][gpuType]};
                    let multiplier = engineMultipliers[inferenceEngine];
                    
                    // Get requested GPUs
                    const requestedGpus = gpuOverrideToggle.checked ? 
                        parseInt(overrideGpuSelect.value) : 
                        baseReq.gpu;
                    
                    // Check if node has enough GPUs for the pod
                    if (node.usedGpu + requestedGpus > node.totalGpu) {
                        console.log(`Cannot create simulated pod: Node ${node.id} has insufficient GPU resources`);
                        return;
                    }
                    
                    // Apply inference engine multiplier
                    const requirements = {
                        cpu: Math.ceil(baseReq.cpu * multiplier.cpu),
                        memory: Math.ceil(baseReq.memory * multiplier.memory),
                        gpu: requestedGpus,
                        storage: baseReq.storage
                    };
                    
                    // Create pod
                    pod = {
                        id: nextPodId++,
                        model: model,
                        displayName: displayName,
                        provider: provider,
                        inferenceEngine: inferenceEngine,
                        gpuType: node.gpuType, // Use the node's GPU type
                        cpu: requirements.cpu,
                        memory: requirements.memory,
                        gpu: requirements.gpu,
                        storage: requirements.storage,
                        cpuOnly: false
                    };
                    
                    // Update node resources
                    node.usedCpu += pod.cpu;
                    node.usedMemory += pod.memory;
                    node.usedGpu += pod.gpu;
                    node.usedStorage += pod.storage;
                    
                    console.log(`Created simulated pod ${pod.id} (${pod.displayName}) on node ${node.id}`);
                }
            }
            
            // Add pod to node and global pods array
            if (pod) {
                node.pods.push(pod);
                pods.push(pod);
                
                // Re-render the nodes to show the new pod
                renderNodes();
                
                // Log the text UI after creating a new pod
                if (consoleMode === 'text-ui') {
                    logTextUI();
                }
            }
        }
        
        // Node Pool Management Functions
        
        // Add a new node pool with default settings
        function addNodePool() {
            const nodePoolsContainer = document.getElementById('node-pools-container');
            const nodePoolId = nextNodePoolId++;
            
            // Create new node pool element
            const nodePoolDiv = document.createElement('div');
            nodePoolDiv.className = 'node-pool bg-white dark:bg-gray-800 rounded-md border border-gray-300 dark:border-gray-600 p-3 mb-4';
            nodePoolDiv.setAttribute('data-pool-id', nodePoolId.toString());
            
            // Determine icon color based on pool ID
            const poolColors = [
                { bg: 'bg-blue-100 dark:bg-blue-900', icon: 'text-blue-500 dark:text-blue-400' },
                { bg: 'bg-green-100 dark:bg-green-900', icon: 'text-green-500 dark:text-green-400' },
                { bg: 'bg-purple-100 dark:bg-purple-900', icon: 'text-purple-500 dark:text-purple-400' },
                { bg: 'bg-red-100 dark:bg-red-900', icon: 'text-red-500 dark:text-red-400' },
                { bg: 'bg-yellow-100 dark:bg-yellow-900', icon: 'text-yellow-500 dark:text-yellow-400' }
            ];
            
            const colorIndex = (nodePoolId - 1) % poolColors.length;
            const { bg, icon } = poolColors[colorIndex];
            
            nodePoolDiv.innerHTML = `
                <div class="flex justify-between items-center mb-3">
                    <div class="flex items-center">
                        <div class="${bg} p-2 rounded-md mr-2">
                            <i class="fas fa-layer-group ${icon}"></i>
                        </div>
                        <div>
                            <h4 class="font-medium">Node Pool ${nodePoolId}</h4>
                            <p class="text-xs text-gray-500 dark:text-gray-400">${nodePoolId === 1 ? 'Default compute node pool' : 'Secondary node pool'}</p>
                        </div>
                    </div>
                    <div class="flex items-center">
                        <button class="text-gray-400 hover:text-red-500 dark:text-gray-500 dark:hover:text-red-400 ml-2 remove-nodepool-btn" data-pool-id="${nodePoolId}">
                            <i class="fas fa-trash"></i>
                        </button>
                        <button class="text-gray-500 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-200 ml-2 toggle-nodepool-btn" data-pool-id="${nodePoolId}">
                            <i class="fas fa-chevron-down"></i>
                        </button>
                    </div>
                </div>
                <div class="node-pool-content">
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-4">
                        <div>
                            <label class="block text-sm font-medium mb-1">Number of Nodes</label>
                            <div class="relative">
                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                    <i class="fas fa-server text-gray-500"></i>
                                </div>
                                <input type="number" class="node-count w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="2" min="1" max="10">
                            </div>
                        </div>
                        <div>
                            <label class="block text-sm font-medium mb-1">GPUs per Node</label>
                            <div class="relative">
                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                    <i class="fas fa-microchip text-gray-500"></i>
                                </div>
                                <input type="number" class="node-gpu-count w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="4" min="0" max="8">
                            </div>
                        </div>
                        <div>
                            <label class="block text-sm font-medium mb-1">GPU Device Type</label>
                            <div class="relative">
                                <select class="node-gpu-type w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base appearance-none">
                                    <option value="A100-80G" selected>NVIDIA A100-80G</option>
                                    <option value="H100-80G">NVIDIA H100-80G</option>
                                    <option value="L40S-48G">NVIDIA L40S-48G</option>
                                    <option value="H100-NVL-94G">NVIDIA H100 NVL-94G</option>
                                    <option value="CPU-Only">CPU-Only Nodes</option>
                                </select>
                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                    <i class="fas fa-layer-group text-green-500"></i>
                                </div>
                                <div class="absolute inset-y-0 right-0 pr-3 flex items-center pointer-events-none">
                                    <i class="fas fa-chevron-down text-gray-400"></i>
                                </div>
                            </div>
                        </div>
                        <div>
                            <label class="block text-sm font-medium mb-1">CPU Cores per Node</label>
                            <div class="relative">
                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                    <i class="fas fa-memory text-gray-500"></i>
                                </div>
                                <input type="number" class="node-cpu w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="48" min="2" max="128">
                            </div>
                        </div>
                        <div>
                            <label class="block text-sm font-medium mb-1">Memory per Node (GB)</label>
                            <div class="relative">
                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                    <i class="fas fa-database text-gray-500"></i>
                                </div>
                                <input type="number" class="node-memory w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="256" min="4" max="512">
                            </div>
                        </div>
                        <div>
                            <label class="block text-sm font-medium mb-1">Node Pool Label</label>
                            <div class="relative">
                                <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                                    <i class="fas fa-tag text-gray-500"></i>
                                </div>
                                <input type="text" class="node-pool-label w-full pl-10 pr-3 py-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-md text-base" value="gpu-pool-${nodePoolId - 1}" placeholder="e.g., gpu-pool, cpu-pool">
                            </div>
                        </div>
                    </div>
                    <div class="mt-3 text-sm text-gray-500 dark:text-gray-400 flex items-center">
                        <i class="fas fa-info-circle mr-2"></i> Total: <span class="node-pool-summary ml-1 font-medium">2 nodes, 8 GPUs, 96 CPU cores, 512 GB memory</span>
                    </div>
                </div>
            `;
            
            // Add to DOM
            nodePoolsContainer.appendChild(nodePoolDiv);
            
            // Update node pool summary
            updateNodePoolSummary(nodePoolDiv);
            
            // Add to nodePools array
            nodePools.push({
                id: nodePoolId,
                label: `gpu-pool-${nodePoolId - 1}`,
                nodeCount: 2,
                gpuCount: 4,
                gpuType: 'A100-80G',
                cpuCores: 48,
                memory: 256
            });
            
            console.log(`Added new node pool #${nodePoolId}`);
            
            // Add event listeners to the inputs in the new node pool
            const inputs = nodePoolDiv.querySelectorAll('input, select');
            inputs.forEach(input => {
                input.addEventListener('change', () => {
                    updateNodePoolSummary(nodePoolDiv);
                });
                input.addEventListener('input', () => {
                    updateNodePoolSummary(nodePoolDiv);
                });
            });
        }
        
        // Remove a node pool
        function removeNodePool(poolId) {
            const nodePoolDiv = document.querySelector(`.node-pool[data-pool-id="${poolId}"]`);
            if (nodePoolDiv) {
                nodePoolDiv.remove();
                
                // Remove from nodePools array
                nodePools = nodePools.filter(pool => pool.id !== parseInt(poolId));
                
                console.log(`Removed node pool #${poolId}`);
            }
        }
        
        // Toggle node pool content visibility
        function toggleNodePoolContent(poolId) {
            const nodePoolDiv = document.querySelector(`.node-pool[data-pool-id="${poolId}"]`);
            if (!nodePoolDiv) {
                console.error(`Node pool with id ${poolId} not found`);
                return;
            }
            
            const contentDiv = nodePoolDiv.querySelector('.node-pool-content');
            const toggleIcon = nodePoolDiv.querySelector('.toggle-nodepool-btn i');
            
            // Get computed style to check actual display value
            const computedStyle = window.getComputedStyle(contentDiv);
            
            if (computedStyle.display === 'none') {
                contentDiv.style.display = 'block';
                toggleIcon.className = 'fas fa-chevron-down';
            } else {
                contentDiv.style.display = 'none';
                toggleIcon.className = 'fas fa-chevron-right';
            }
        }
        
        // Update node pool summary
        function updateNodePoolSummary(nodePoolDiv) {
            const nodeCount = parseInt(nodePoolDiv.querySelector('.node-count').value);
            const gpuCount = parseInt(nodePoolDiv.querySelector('.node-gpu-count').value);
            const cpuCores = parseInt(nodePoolDiv.querySelector('.node-cpu').value);
            const memory = parseInt(nodePoolDiv.querySelector('.node-memory').value);
            const gpuType = nodePoolDiv.querySelector('.node-gpu-type').value;
            
            // Calculate totals
            const totalGPUs = gpuType === 'CPU-Only' ? 0 : nodeCount * gpuCount;
            const totalCPUs = nodeCount * cpuCores;
            const totalMemory = nodeCount * memory;
            
            // Update summary text
            const summaryElement = nodePoolDiv.querySelector('.node-pool-summary');
            if (gpuType === 'CPU-Only') {
                summaryElement.textContent = `${nodeCount} nodes, ${totalCPUs} CPU cores, ${totalMemory} GB memory (CPU-Only)`;
            } else {
                summaryElement.textContent = `${nodeCount} nodes, ${totalGPUs} GPUs, ${totalCPUs} CPU cores, ${totalMemory} GB memory`;
            }
            
            // Update pool in the nodePools array
            const poolId = parseInt(nodePoolDiv.getAttribute('data-pool-id'));
            const poolIndex = nodePools.findIndex(pool => pool.id === poolId);
            if (poolIndex !== -1) {
                nodePools[poolIndex] = {
                    id: poolId,
                    label: nodePoolDiv.querySelector('.node-pool-label').value,
                    nodeCount,
                    gpuCount,
                    gpuType,
                    cpuCores,
                    memory
                };
            }
        }
        
        // Read node pool configurations
        // function readNodePoolConfigurations() {
        //     const nodePools = [];
        //     const nodePoolDivs = document.querySelectorAll('.node-pool');
            
        //     nodePoolDivs.forEach(poolDiv => {
        //         const poolId = parseInt(poolDiv.getAttribute('data-pool-id'));
        //         const nodeCount = parseInt(poolDiv.querySelector('.node-count').value);
        //         const gpuCount = parseInt(poolDiv.querySelector('.node-gpu-count').value);
        //         const cpuCores = parseInt(poolDiv.querySelector('.node-cpu').value);
        //         const memory = parseInt(poolDiv.querySelector('.node-memory').value);
        //         const gpuType = poolDiv.querySelector('.node-gpu-type').value;
        //         const label = poolDiv.querySelector('.node-pool-label').value;
                
        //         nodePools.push({
        //             id: poolId,
        //             label,
        //             nodeCount,
        //             gpuCount,
        //             gpuType,
        //             cpuCores,
        //             memory
        //         });
        //     });
            
        //     return nodePools;
        // }
        
        // Initialize all node pools in the cluster
        function initNodesFromPools() {
            // Clear existing nodes
            nodes = [];
            
            // Read current node pool configurations
            const pools = readNodePoolConfigurations();
            
            // Create nodes for each pool
            let nodeIndex = 1;
            pools.forEach(pool => {
                for (let i = 0; i < pool.nodeCount; i++) {
                    nodes.push({
                        id: nodeIndex++,
                        poolId: pool.id,
                        poolLabel: pool.label,
                        totalCpu: pool.cpuCores,
                        totalMemory: pool.memory,
                        totalGpu: pool.gpuType === 'CPU-Only' ? 0 : pool.gpuCount,
                        gpuType: pool.gpuType,
                        usedCpu: 0,
                        usedMemory: 0,
                        usedGpu: 0,
                        usedStorage: 0,
                        pods: []
                    });
                }
            });
            
            renderNodes();
            console.log(`Initialized cluster with ${nodes.length} nodes from ${pools.length} node pools`);
        }
        
        // Update node pool configuration from the UI while preserving existing pods
        function updateNodePoolsFromUI() {
            // Store current pods and their node assignments
            const activePodsWithAssignments = [];
            const pendingPodsToReschedule = [...pendingPods];
            
            // For each node, capture the pods and their current assignments
            nodes.forEach(node => {
                node.pods.forEach(pod => {
                    // Store the pod with its node ID so we can try to preserve placement
                    activePodsWithAssignments.push({
                        pod: { ...pod },
                        previousNodeId: node.id,
                        poolId: node.poolId,
                        poolLabel: node.poolLabel,
                        gpuType: node.gpuType
                    });
                });
            });
            
            console.log(`Updating cluster with ${activePodsWithAssignments.length} active pods and ${pendingPodsToReschedule.length} pending pods`);
            
            // Reset cluster state
            pods = [];
            pendingPods = [];
            
            // Initialize nodes from node pools
            initNodesFromPools();
            
            // First, try to place pods on nodes from the same pool if possible
            let scheduledCount = 0;
            let failedScheduling = [];
            
            activePodsWithAssignments.forEach(item => {
                const { pod, previousNodeId, poolId, poolLabel, gpuType } = item;
                
                // Try to find nodes from the same pool first
                const samePoolNodes = nodes.filter(node => 
                    node.poolId === poolId || 
                    node.poolLabel === poolLabel || 
                    node.gpuType === gpuType
                );
                
                // Sort nodes by least allocated resources first
                const sortedNodes = samePoolNodes.map(node => {
                    // Calculate resource utilization percentage
                    const utilization = (
                        node.usedCpu / node.totalCpu + 
                        node.usedMemory / node.totalMemory + 
                        (pod.cpuOnly ? 0 : node.usedGpu / node.totalGpu)
                    ) / (pod.cpuOnly ? 2 : 3);
                    return { node, utilization };
                }).sort((a, b) => a.utilization - b.utilization)
                  .map(item => item.node);
                
                // Try to schedule on a node from the same pool
                let scheduled = false;
                
                for (let i = 0; i < sortedNodes.length; i++) {
                    const node = sortedNodes[i];
                    
                    // Check if the node has compatible GPU type and sufficient resources
                    const gpuCompatible = pod.cpuOnly || node.gpuType === pod.gpuType;
                    const cpuAvailable = node.usedCpu + pod.cpu <= node.totalCpu;
                    const memoryAvailable = node.usedMemory + pod.memory <= node.totalMemory;
                    const gpuAvailable = pod.cpuOnly || node.usedGpu + pod.gpu <= node.totalGpu;
                    
                    if (gpuCompatible && cpuAvailable && memoryAvailable && gpuAvailable) {
                        // Assign pod to this node
                        node.usedCpu += pod.cpu;
                        node.usedMemory += pod.memory;
                        if (!pod.cpuOnly) {
                            node.usedGpu += pod.gpu;
                        }
                        node.usedStorage += pod.storage;
                        
                        // Add pod to node and global pods array
                        node.pods.push(pod);
                        pods.push(pod);
                        
                        scheduled = true;
                        scheduledCount++;
                        
                        console.log(`Preserved pod ${pod.id} (${pod.displayName}) on node ${node.id}`);
                        break;
                    }
                }
                
                // If couldn't schedule on same pool nodes, try any node
                if (!scheduled) {
                    failedScheduling.push(pod);
                }
            });
            
            // Try to schedule pods that couldn't be placed on their preferred nodes
            failedScheduling.forEach(pod => {
                schedulePod(pod);
            });
            
            // Now try to schedule previously pending pods
            pendingPodsToReschedule.forEach(pod => {
                schedulePod(pod);
            });
            
            // Update the UI
            renderNodes();
            renderPendingPods();
            
            console.log(`Updated cluster with ${nodes.length} nodes across ${readNodePoolConfigurations().length} node pools`);
            console.log(`Successfully preserved ${scheduledCount} pods, rescheduled ${failedScheduling.length} pods, with ${pendingPods.length} pending`);
            
            // Log the text UI after updating node pools
            if (consoleMode === 'text-ui') {
                logTextUI();
            }
        }
        
        // Initialize the application
        function init() {
            console.log("Initializing Kubernetes LLM Pod Scheduling Simulator");

            // Apply initial model filtering
            filterModels();

            // Update the model card
            updateModelCard();

            // Check CPU-only eligibility
            checkCPUOnlyEligibility();

            // Add the default node pool to the tracking array if empty
            if (nodePools.length === 0) {
                const defaultNodeCount = parseInt(document.querySelector('.node-count')?.value) || 1; // Dynamically fetch node count
                const defaultGpuCount = parseInt(document.querySelector('.node-gpu-count')?.value) || 0; // Dynamically fetch GPU count
                const defaultCpuCores = parseInt(document.querySelector('.node-cpu')?.value) || 16; // Dynamically fetch CPU cores
                const defaultMemory = parseInt(document.querySelector('.node-memory')?.value) || 64; // Dynamically fetch memory
                const defaultGpuType = document.querySelector('.node-gpu-type')?.value || 'CPU-Only'; // Dynamically fetch GPU type

                nodePools.push({
                    id: 1,
                    label: 'default',
                    nodeCount: defaultNodeCount,
                    gpuCount: defaultGpuCount,
                    gpuType: defaultGpuType,
                    cpuCores: defaultCpuCores,
                    memory: defaultMemory
                });
            }

            // Update the model requirements display (after a brief delay to avoid race conditions)
            setTimeout(() => {
                updateModelRequirements();

                // Initialize the node pool (after model requirements are set)
                initNodesFromPools();

                console.log("Application initialized successfully");
            }, 100);

            // Add input change listeners for all node pool inputs
            document.querySelectorAll('.node-pool').forEach(nodePool => {
                const inputs = nodePool.querySelectorAll('input, select');
                inputs.forEach(input => {
                    input.addEventListener('change', () => {
                        updateNodePoolSummary(nodePool);
                    });
                    input.addEventListener('input', () => {
                        updateNodePoolSummary(nodePool);
                    });
                });
            });
        }

        // Testing Examples Functions
        
        // Event handlers for test examples
        function setupTestExampleHandlers() {
            // Setup click handlers for test selection cards
            const testCards = document.querySelectorAll('.test-select-card');
            testCards.forEach(card => {
                card.addEventListener('click', function(e) {
                    // Don't trigger if clicking on a button
                    if (e.target.closest('button')) {
                        return;
                    }
                    
                    const testId = this.getAttribute('data-test-id');
                    showTestDetail(testId);
                });
            });
            
            // Toggle card expansion when clicking on the header (for old design)
            const testHeaders = document.querySelectorAll('.test-header');
            testHeaders.forEach(header => {
                header.addEventListener('click', function(e) {
                    // Don't expand/collapse if clicking on the Apply button
                    if (e.target.closest('.apply-test-btn')) {
                        return;
                    }
                    
                    const content = this.nextElementSibling;
                    const expandIcon = this.querySelector('.test-expand-icon');
                    
                    if (content.style.maxHeight === '1000px') {
                        content.style.maxHeight = '0px';
                        expandIcon.classList.remove('fa-chevron-up');
                        expandIcon.classList.add('fa-chevron-down');
                    } else {
                        content.style.maxHeight = '1000px';
                        expandIcon.classList.remove('fa-chevron-down');
                        expandIcon.classList.add('fa-chevron-up');
                    }
                });
            });
            
            // Show the selected test detail
            function showTestDetail(testId) {
                // Remove selected class from all cards
                document.querySelectorAll('.test-select-card').forEach(card => {
                    card.classList.remove('selected');
                });
                
                // Add selected class to clicked card
                const selectedCard = document.querySelector(`.test-select-card[data-test-id="${testId}"]`);
                if (selectedCard) {
                    selectedCard.classList.add('selected');
                }
                
                // Hide all test details
                document.querySelectorAll('.test-detail').forEach(detail => {
                    detail.classList.add('hidden');
                });
                
                // Show the selected test detail
                const selectedDetail = document.getElementById(`${testId}-detail`);
                if (selectedDetail) {
                    selectedDetail.classList.remove('hidden');
                }
            }
            
            // On page load, show the Large GPU Model test by default
            setTimeout(() => {
                showTestDetail('large-gpu-test');
            }, 100);
            
            // Collapse individual test card
            const collapseButtons = document.querySelectorAll('.collapse-test-btn');
            collapseButtons.forEach(button => {
                button.addEventListener('click', function() {
                    const content = this.closest('.test-content');
                    const header = content.previousElementSibling;
                    const expandIcon = header.querySelector('.test-expand-icon');
                    
                    content.style.maxHeight = '0px';
                    expandIcon.classList.remove('fa-chevron-up');
                    expandIcon.classList.add('fa-chevron-down');
                });
            });
            
            // Collapse all test cards
            const collapseAllButton = document.getElementById('collapse-all-tests');
            collapseAllButton.addEventListener('click', function() {
                const allContents = document.querySelectorAll('.test-content');
                const allIcons = document.querySelectorAll('.test-expand-icon');
                
                allContents.forEach(content => {
                    content.style.maxHeight = '0px';
                });
                
                allIcons.forEach(icon => {
                    icon.classList.remove('fa-chevron-up');
                    icon.classList.add('fa-chevron-down');
                });
            });
            
            // Apply test configuration button
            const applyButtons = document.querySelectorAll('.apply-test-btn');
            applyButtons.forEach(button => {
                button.addEventListener('click', function() {
                    const testId = this.getAttribute('data-test-id');
                    applyTestConfiguration(testId);
                });
            });
            
            // Run simulation button
            const runSimButtons = document.querySelectorAll('.run-simulation-btn');
            runSimButtons.forEach(button => {
                button.addEventListener('click', function() {
                    const testId = this.getAttribute('data-test-id');
                    runTestSimulation(testId);
                });
            });
            
            // Open test in new window button
            const openButtons = document.querySelectorAll('.open-test-btn');
            openButtons.forEach(button => {
                button.addEventListener('click', function() {
                    const testId = this.getAttribute('data-test-id');
                    openTestInNewWindow(testId);
                });
            });
        }
        
        // Apply a test configuration based on its ID
        function applyTestConfiguration(testId) {
            // Reset the cluster first to start clean
            resetCluster();
            
            console.log(`Applying test configuration: ${testId}`);
            
            switch(testId) {
                case 'cpu-only-test':
                    applyCpuOnlyTest();
                    break;
                case 'large-gpu-test':
                    applyLargeGpuTest();
                    break;
                case 'gpu-compatibility-test':
                    applyGpuCompatibilityTest();
                    break;
                case 'moe-model-test':
                    applyMoeModelTest();
                    break;
                case 'mixed-workload-test':
                    applyMixedWorkloadTest();
                    break;
                case 'resource-constraints-test':
                    applyResourceConstraintsTest();
                    break;
                case 'nvidia-nim-rag-test':
                    applyNvidiaRagTest();
                    break;
                default:
                    console.log(`Unknown test ID: ${testId}`);
            }
        }
        
        // Run a test simulation with step-by-step visualization and deploy appropriate models
        function runTestSimulation(testId) {
            // First apply the test configuration
            applyTestConfiguration(testId);
            
            // Then run the simulation with visualization
            setTimeout(() => {
                // Show the animation area
                getElement('scheduler-animation').classList.remove('hidden');
                
                // Run the simulation
                simulateScheduling();
                
                // After simulation completes, deploy appropriate models based on test type
                setTimeout(() => {
                    console.log(`Deploying models for test: ${testId}`);
                    
                    // Deploy appropriate models based on test ID
                    switch(testId) {
                        case 'mixed-workload-test':
                            // For mixed workload, deploy multiple models sequentially
                            deployMixedWorkloadModels();
                            break;
                        case 'resource-constraints-test':
                            // For resource constraints, deploy multiple instances to create constraint
                            deployResourceConstraintModels();
                            break;
                        case 'nvidia-nim-rag-test':
                            // For NVIDIA RAG pipeline, deploy the RAG components
                            deployNvidiaRagComponents();
                            break;
                        default:
                            // For other tests, just deploy a single pod with current settings
                            deployPod();
                    }
                }, 4000);
            }, 500);
            
            console.log(`Running simulation for test: ${testId}`);
        }
        
        // Deploy mixed workload models sequentially with different configurations
        function deployMixedWorkloadModels() {
            // First deploy Llama 70B on H100
            deployPod();
            
            // After first deployment, set up and deploy Mixtral on L40S
            setTimeout(() => {
                // Select Mixtral 8x7B model
                const modelSelect = document.getElementById('model');
                for (let i = 0; i < modelSelect.options.length; i++) {
                    if (modelSelect.options[i].value === 'mistralai-mixtral-8x7b') {
                        modelSelect.selectedIndex = i;
                        modelSelect.dispatchEvent(new Event('change'));
                        break;
                    }
                }
                
                // Select L40S GPU
                document.getElementById('gpu-type').value = 'L40S-48G';
                document.getElementById('gpu-type').dispatchEvent(new Event('change'));
                
                // Update model requirements
                updateModelRequirements();
                
                // Deploy Mixtral
                deployPod();
                
                // After second deployment, set up and deploy Gemma in CPU-only mode
                setTimeout(() => {
                    // Select Gemma 2B model
                    for (let i = 0; i < modelSelect.options.length; i++) {
                        if (modelSelect.options[i].value === 'google-gemma-2-2b') {
                            modelSelect.selectedIndex = i;
                            modelSelect.dispatchEvent(new Event('change'));
                            break;
                        }
                    }
                    
                    // Enable CPU-only mode
                    const cpuOnlyToggle = document.getElementById('cpu-only-toggle');
                    if (!cpuOnlyToggle.checked) {
                        cpuOnlyToggle.checked = true;
                        cpuOnlyToggle.dispatchEvent(new Event('change'));
                    }
                    
                    // Set CPU and memory values
                    document.getElementById('cpu-count').value = 6;
                    document.getElementById('memory-size').value = 24;
                    
                    // Update model requirements
                    updateModelRequirements();
                    
                    // Deploy Gemma
                    deployPod();
                }, 3000);
            }, 3000);
        }
        
        // Deploy resource constraint test models to create a resource contention scenario
        function deployResourceConstraintModels() {
            // First deploy Mixtral 8x7B with 2 replicas
            // Select Mixtral 8x7B model
            const modelSelect = document.getElementById('model');
            for (let i = 0; i < modelSelect.options.length; i++) {
                if (modelSelect.options[i].value === 'mistralai-mixtral-8x7b') {
                    modelSelect.selectedIndex = i;
                    modelSelect.dispatchEvent(new Event('change'));
                    break;
                }
            }
            
            // Set replicas to 2
            document.getElementById('replicas').value = 2;
            
            // Update model requirements
            updateModelRequirements();
            
            // Deploy Mixtral with 2 replicas
            deployPod();
            
            // After first deployment, set up and deploy Llama 70B with 2 replicas
            setTimeout(() => {
                // Select Llama 3.1 70B model
                for (let i = 0; i < modelSelect.options.length; i++) {
                    if (modelSelect.options[i].value === 'meta-llama-3-1-70b') {
                        modelSelect.selectedIndex = i;
                        modelSelect.dispatchEvent(new Event('change'));
                        break;
                    }
                }
                
                // Keep replicas at 2
                
                // Update model requirements
                updateModelRequirements();
                
                // Deploy Llama
                deployPod();
                
                // Finally, try to deploy one more Mixtral replica to trigger pending state
                setTimeout(() => {
                    // Select Mixtral 8x7B model again
                    for (let i = 0; i < modelSelect.options.length; i++) {
                        if (modelSelect.options[i].value === 'mistralai-mixtral-8x7b') {
                            modelSelect.selectedIndex = i;
                            modelSelect.dispatchEvent(new Event('change'));
                            break;
                        }
                    }
                    
                    // Set replicas to 1 for the final pod
                    document.getElementById('replicas').value = 1;
                    
                    // Update model requirements
                    updateModelRequirements();
                    
                    // Deploy one more Mixtral pod (should go to pending)
                    deployPod();
                }, 3000);
            }, 3000);
        }
        
        // Deploy NVIDIA RAG pipeline components
        function deployNvidiaRagComponents() {
            // First deploy the main LLM component (already configured in applyNvidiaRagTest)
            // Just need to deploy it
            deployPod();
            
            // For visualization purposes, simulate other RAG components being deployed
            // These would normally be separate customized containers in a real deployment
            setTimeout(() => {
                console.log("Deploying RAG pipeline components:");
                console.log("- NVIDIA LLM Inference Service: Active");
                console.log("- NVIDIA Embedding Service: Deploying...");
                console.log("- Vector Database Service: Pending");
                console.log("- Guardrails Service: Pending");
                
                setTimeout(() => {
                    console.log("- NVIDIA Embedding Service: Active");
                    console.log("- Vector Database Service: Deploying...");
                    console.log("- Guardrails Service: Pending");
                    
                    setTimeout(() => {
                        console.log("- Vector Database Service: Active");
                        console.log("- Guardrails Service: Deploying...");
                        
                        setTimeout(() => {
                            console.log("- Guardrails Service: Active");
                            console.log("Complete RAG pipeline deployed successfully!");
                        }, 1500);
                    }, 1500);
                }, 1500);
            }, 2000);
        }
        
        // Test 7: NVIDIA NIM RAG Pipeline
        function applyNvidiaRagTest() {
            console.log("Applying NVIDIA NIM RAG Pipeline Test...");
            
            // Configure node pools - we need high-performance H100 node pool
            // First, remove any existing node pools except the default one
            const nodePoolDivs = document.querySelectorAll('.node-pool');
            nodePoolDivs.forEach(div => {
                const poolId = div.getAttribute('data-pool-id');
                if (poolId !== '1') {
                    removeNodePool(poolId);
                }
            });
            
            // Configure default node pool for H100 GPUs with high capacity
            const defaultPool = document.querySelector('.node-pool[data-pool-id="1"]');
            if (defaultPool) {
                defaultPool.querySelector('.node-count').value = 2;
                defaultPool.querySelector('.node-gpu-count').value = 8;
                defaultPool.querySelector('.node-gpu-type').value = 'H100-80G';
                defaultPool.querySelector('.node-cpu').value = 128;
                defaultPool.querySelector('.node-memory').value = 512;
                defaultPool.querySelector('.node-pool-label').value = 'nvidia-rag-pool';
                
                // Update the summary
                updateNodePoolSummary(defaultPool);
            }
            
            // Update the cluster with new node pool configuration
            updateNodePoolsFromUI();
            
            // Disable CPU-only mode if enabled
            const cpuOnlyToggle = document.getElementById('cpu-only-toggle');
            if (cpuOnlyToggle.checked) {
                cpuOnlyToggle.checked = false;
                cpuOnlyToggle.dispatchEvent(new Event('change'));
            }
            
            // Select NVIDIA Llama model (ensuring we use an NVIDIA source model)
            const modelSelect = document.getElementById('model');
            for (let i = 0; i < modelSelect.options.length; i++) {
                if (modelSelect.options[i].value === 'nvidia-llama-3-1-70b') {
                    modelSelect.selectedIndex = i;
                    modelSelect.dispatchEvent(new Event('change'));
                    break;
                }
            }
            
            // Inference engine should auto-select to NVIDIA NIM
            
            // Update replicas
            document.getElementById('replicas').value = 1;
            
            // Update model requirements display
            updateModelRequirements();
            
            console.log("NVIDIA NIM RAG Pipeline Test configuration applied. Ready to deploy model.");
            console.log("-----------------------------------------------------------");
            console.log("This test simulates a production RAG deployment with the following components:");
            console.log("- NIM LLM 70B for query processing");
            console.log("- GPU-accelerated embedding service");
            console.log("- Vector search with pinned data");
            console.log("- Automated content moderation guardrails");
            console.log("All components use NVIDIA-optimized containers for maximum performance.");
            console.log("-----------------------------------------------------------");
        }
        
        // Run a test simulation with step-by-step visualization
        function runTestSimulation(testId) {
            // First apply the test configuration
            applyTestConfiguration(testId);
            
            // Then run the simulation with visualization
            setTimeout(() => {
                // Show the animation area
                getElement('scheduler-animation').classList.remove('hidden');
                
                // Run the simulation
                simulateScheduling();
                
                // After simulation completes, deploy a pod
                setTimeout(() => {
                    deployPod();
                }, 4000);
            }, 500);
            
            console.log(`Running simulation for test: ${testId}`);
        }
        
        // Open a test configuration in a new browser window
        function openTestInNewWindow(testId) {
            // Get current URL and add a query parameter for the test
            const url = new URL(window.location.href);
            url.searchParams.set('test', testId);
            
            // Open in new window
            window.open(url.toString(), '_blank');
            console.log(`Opening test ${testId} in new window`);
        }
        
        // Test 1: CPU-Only Model Deployment
        function applyCpuOnlyTest() {
            console.log("Applying CPU-Only Model Test...");
            
            // Configure node pools
            // First, remove any existing node pools except the default one
            const nodePoolDivs = document.querySelectorAll('.node-pool');
            nodePoolDivs.forEach(div => {
                const poolId = div.getAttribute('data-pool-id');
                if (poolId !== '1') {
                    removeNodePool(poolId);
                }
            });
            
            // Configure default node pool for CPU-only
            const defaultPool = document.querySelector('.node-pool[data-pool-id="1"]');
            if (defaultPool) {
                defaultPool.querySelector('.node-count').value = 3;
                defaultPool.querySelector('.node-gpu-count').value = 0;
                defaultPool.querySelector('.node-gpu-type').value = 'CPU-Only';
                defaultPool.querySelector('.node-cpu').value = 8;
                defaultPool.querySelector('.node-memory').value = 32;
                defaultPool.querySelector('.node-pool-label').value = 'cpu-pool';
                
                // Update the summary
                updateNodePoolSummary(defaultPool);
            }
            
            // Update the cluster with new node pool configuration
            updateNodePoolsFromUI();
            
            // Select Google Gemma 2B model
            const modelSelect = document.getElementById('model');
            for (let i = 0; i < modelSelect.options.length; i++) {
                if (modelSelect.options[i].value === 'google-gemma-2-2b') {
                    modelSelect.selectedIndex = i;
                    modelSelect.dispatchEvent(new Event('change'));
                    break;
                }
            }
            
            // Enable CPU-only mode
            const cpuOnlyToggle = document.getElementById('cpu-only-toggle');
            if (!cpuOnlyToggle.checked) {
                cpuOnlyToggle.checked = true;
                cpuOnlyToggle.dispatchEvent(new Event('change'));
            }
            
            // Set CPU and memory values
            document.getElementById('cpu-count').value = 6;
            document.getElementById('memory-size').value = 24;
            
            // Update replicas
            document.getElementById('replicas').value = 2;
            
            // Update model requirements display
            updateModelRequirements();
            
            console.log("CPU-Only Model Test configuration applied. Ready to deploy model.");
        }
        
        // Test 2: Large GPU Model
        function applyLargeGpuTest() {
            console.log("Applying Large GPU Model Test...");
            
            // Configure node pools
            // First, remove any existing node pools except the default one
            const nodePoolDivs = document.querySelectorAll('.node-pool');
            nodePoolDivs.forEach(div => {
                const poolId = div.getAttribute('data-pool-id');
                if (poolId !== '1') {
                    removeNodePool(poolId);
                }
            });
            
            // Configure default node pool for H100 GPUs
            const defaultPool = document.querySelector('.node-pool[data-pool-id="1"]');
            if (defaultPool) {
                defaultPool.querySelector('.node-count').value = 2;
                defaultPool.querySelector('.node-gpu-count').value = 4;
                defaultPool.querySelector('.node-gpu-type').value = 'H100-80G';
                defaultPool.querySelector('.node-cpu').value = 64;
                defaultPool.querySelector('.node-memory').value = 256;
                defaultPool.querySelector('.node-pool-label').value = 'h100-pool';
                
                // Update the summary
                updateNodePoolSummary(defaultPool);
            }
            
            // Update the cluster with new node pool configuration
            updateNodePoolsFromUI();
            
            // Disable CPU-only mode if enabled
            const cpuOnlyToggle = document.getElementById('cpu-only-toggle');
            if (cpuOnlyToggle.checked) {
                cpuOnlyToggle.checked = false;
                cpuOnlyToggle.dispatchEvent(new Event('change'));
            }
            
            // Select Meta Llama 3.1 70B model
            const modelSelect = document.getElementById('model');
            for (let i = 0; i < modelSelect.options.length; i++) {
                if (modelSelect.options[i].value === 'meta-llama-3-1-70b') {
                    modelSelect.selectedIndex = i;
                    modelSelect.dispatchEvent(new Event('change'));
                    break;
                }
            }
            
            // Select vLLM engine
            document.getElementById('inference-engine').value = 'vllm';
            
            // Select H100 GPU
            document.getElementById('gpu-type').value = 'H100-80G';
            
            // Update replicas
            document.getElementById('replicas').value = 2;
            
            // Update model requirements display
            updateModelRequirements();
            
            console.log("Large GPU Model Test configuration applied. Ready to deploy model.");
        }
        
        // Test 3: GPU Compatibility Test
        function applyGpuCompatibilityTest() {
            console.log("Applying GPU Compatibility Test...");
            
            // Create two node pools: one with A100 and one with H100
            // First, remove any existing node pools except the default one
            const nodePoolDivs = document.querySelectorAll('.node-pool');
            nodePoolDivs.forEach(div => {
                const poolId = div.getAttribute('data-pool-id');
                if (poolId !== '1') {
                    removeNodePool(poolId);
                }
            });
            
            // Configure default node pool for A100 GPUs
            const defaultPool = document.querySelector('.node-pool[data-pool-id="1"]');
            if (defaultPool) {
                defaultPool.querySelector('.node-count').value = 2;
                defaultPool.querySelector('.node-gpu-count').value = 4;
                defaultPool.querySelector('.node-gpu-type').value = 'A100-80G';
                defaultPool.querySelector('.node-cpu').value = 64;
                defaultPool.querySelector('.node-memory').value = 256;
                defaultPool.querySelector('.node-pool-label').value = 'a100-pool';
                
                // Update the summary
                updateNodePoolSummary(defaultPool);
            }
            
            // Add H100 node pool
            addNodePool();
            
            // Configure the new H100 node pool
            const newPool = document.querySelector('.node-pool[data-pool-id="2"]');
            if (newPool) {
                newPool.querySelector('.node-count').value = 1;
                newPool.querySelector('.node-gpu-count').value = 4;
                newPool.querySelector('.node-gpu-type').value = 'H100-80G';
                newPool.querySelector('.node-cpu').value = 64;
                newPool.querySelector('.node-memory').value = 256;
                newPool.querySelector('.node-pool-label').value = 'h100-pool';
                
                // Update the summary
                updateNodePoolSummary(newPool);
            }
            
            // Update the cluster with new node pool configuration
            updateNodePoolsFromUI();
            
            // Disable CPU-only mode if enabled
            const cpuOnlyToggle = document.getElementById('cpu-only-toggle');
            if (cpuOnlyToggle.checked) {
                cpuOnlyToggle.checked = false;
                cpuOnlyToggle.dispatchEvent(new Event('change'));
            }
            
            // Select NVIDIA Llama 3.3 70B model (which requires H100)
            const modelSelect = document.getElementById('model');
            for (let i = 0; i < modelSelect.options.length; i++) {
                if (modelSelect.options[i].value === 'nvidia-llama-3-3-70b') {
                    modelSelect.selectedIndex = i;
                    modelSelect.dispatchEvent(new Event('change'));
                    break;
                }
            }
            
            // Inference engine should auto-select to NVIDIA NIM
            
            // Update replicas to 2
            document.getElementById('replicas').value = 2;
            
            // Update model requirements display
            updateModelRequirements();
            
            console.log("GPU Compatibility Test configuration applied. Ready to deploy model.");
        }
        
        // Test 4: MoE Model & Advanced Settings
        function applyMoeModelTest() {
            console.log("Applying MoE Model & Advanced Settings Test...");
            
            // Configure node pools - we need a large A100 node pool
            // First, remove any existing node pools except the default one
            const nodePoolDivs = document.querySelectorAll('.node-pool');
            nodePoolDivs.forEach(div => {
                const poolId = div.getAttribute('data-pool-id');
                if (poolId !== '1') {
                    removeNodePool(poolId);
                }
            });
            
            // Configure default node pool for A100 GPUs with high capacity
            const defaultPool = document.querySelector('.node-pool[data-pool-id="1"]');
            if (defaultPool) {
                defaultPool.querySelector('.node-count').value = 1;
                defaultPool.querySelector('.node-gpu-count').value = 8;
                defaultPool.querySelector('.node-gpu-type').value = 'A100-80G';
                defaultPool.querySelector('.node-cpu').value = 96;
                defaultPool.querySelector('.node-memory').value = 384;
                defaultPool.querySelector('.node-pool-label').value = 'a100-high-mem';
                
                // Update the summary
                updateNodePoolSummary(defaultPool);
            }
            
            // Update the cluster with new node pool configuration
            updateNodePoolsFromUI();
            
            // Disable CPU-only mode if enabled
            const cpuOnlyToggle = document.getElementById('cpu-only-toggle');
            if (cpuOnlyToggle.checked) {
                cpuOnlyToggle.checked = false;
                cpuOnlyToggle.dispatchEvent(new Event('change'));
            }
            
            // Select Mixtral 8x7B model
            const modelSelect = document.getElementById('model');
            for (let i = 0; i < modelSelect.options.length; i++) {
                if (modelSelect.options[i].value === 'mistralai-mixtral-8x7b') {
                    modelSelect.selectedIndex = i;
                    modelSelect.dispatchEvent(new Event('change'));
                    break;
                }
            }
            
            // Select A100 GPU
            document.getElementById('gpu-type').value = 'A100-80G';
            document.getElementById('gpu-type').dispatchEvent(new Event('change'));
            
            // Select vLLM engine
            document.getElementById('inference-engine').value = 'vllm';
            document.getElementById('inference-engine').dispatchEvent(new Event('change'));
            
            // Expand advanced settings if collapsed
            const advancedContent = document.getElementById('advanced-content');
            const advancedIcon = document.getElementById('advanced-icon');
            if (!advancedContent.classList.contains('expanded')) {
                advancedContent.classList.add('expanded');
                advancedIcon.className = 'fas fa-chevron-up';
            }
            
            // Enable GPU override and set to 4
            const gpuOverrideToggle = document.getElementById('gpu-override-toggle');
            gpuOverrideToggle.checked = true;
            gpuOverrideToggle.dispatchEvent(new Event('change'));
            
            // Set GPU count to 4
            const overrideGpuSelect = document.getElementById('override-gpu-select');
            overrideGpuSelect.value = '4';
            overrideGpuSelect.dispatchEvent(new Event('change'));
            
            // Set vLLM multipliers
            document.getElementById('vllm-cpu').value = 1.5;
            document.getElementById('vllm-memory').value = 1.8;
            
            // Update replicas
            document.getElementById('replicas').value = 1;
            
            // Update model requirements display
            updateModelRequirements();
            
            console.log("MoE Model & Advanced Settings Test configuration applied. Ready to deploy model.");
        }
        
        // Test 5: Mixed Workload Test
        function applyMixedWorkloadTest() {
            console.log("Applying Mixed Workload Test...");
            
            // We need 3 node pools: H100, L40S, and CPU-only
            // First, remove any existing node pools except the default one
            const nodePoolDivs = document.querySelectorAll('.node-pool');
            nodePoolDivs.forEach(div => {
                const poolId = div.getAttribute('data-pool-id');
                if (poolId !== '1') {
                    removeNodePool(poolId);
                }
            });
            
            // Configure default node pool for H100 GPUs
            const defaultPool = document.querySelector('.node-pool[data-pool-id="1"]');
            if (defaultPool) {
                defaultPool.querySelector('.node-count').value = 2;
                defaultPool.querySelector('.node-gpu-count').value = 2;
                defaultPool.querySelector('.node-gpu-type').value = 'H100-80G';
                defaultPool.querySelector('.node-cpu').value = 64;
                defaultPool.querySelector('.node-memory').value = 256;
                defaultPool.querySelector('.node-pool-label').value = 'h100-pool';
                
                // Update the summary
                updateNodePoolSummary(defaultPool);
            }
            
            // Add L40S node pool
            addNodePool();
            
            // Configure the L40S node pool
            const l40sPool = document.querySelector('.node-pool[data-pool-id="2"]');
            if (l40sPool) {
                l40sPool.querySelector('.node-count').value = 3;
                l40sPool.querySelector('.node-gpu-count').value = 4;
                l40sPool.querySelector('.node-gpu-type').value = 'L40S-48G';
                l40sPool.querySelector('.node-cpu').value = 48;
                l40sPool.querySelector('.node-memory').value = 192;
                l40sPool.querySelector('.node-pool-label').value = 'l40s-pool';
                
                // Update the summary
                updateNodePoolSummary(l40sPool);
            }
            
            // Add CPU-only node pool
            addNodePool();
            
            // Configure the CPU-only node pool
            const cpuPool = document.querySelector('.node-pool[data-pool-id="3"]');
            if (cpuPool) {
                cpuPool.querySelector('.node-count').value = 4;
                cpuPool.querySelector('.node-gpu-count').value = 0;
                cpuPool.querySelector('.node-gpu-type').value = 'CPU-Only';
                cpuPool.querySelector('.node-cpu').value = 32;
                cpuPool.querySelector('.node-memory').value = 128;
                cpuPool.querySelector('.node-pool-label').value = 'cpu-pool';
                
                // Update the summary
                updateNodePoolSummary(cpuPool);
            }
            
            // Update the cluster with new node pool configuration
            updateNodePoolsFromUI();
            
            // Start with clean state for model setup
            console.log("Mixed Workload Test configuration applied. Ready to deploy models.");
            
            // Guide the user on next steps
            console.log("-----------------------------------------------------------");
            console.log("To complete the mixed workload test, deploy these models:");
            console.log("1. Meta Llama 3.1 70B on H100s - select model and deploy");
            console.log("2. Mixtral 8x7B on L40S GPUs - select model, change GPU to L40S, and deploy");
            console.log("3. Gemma 2B in CPU-only mode - select model, enable CPU-only toggle, and deploy");
            console.log("-----------------------------------------------------------");
        }
        
        // Test 6: Resource Constraints
        function applyResourceConstraintsTest() {
            console.log("Applying Resource Constraints Test...");
            
            // Configure for a single node pool with limited resources
            // First, remove any existing node pools except the default one
            const nodePoolDivs = document.querySelectorAll('.node-pool');
            nodePoolDivs.forEach(div => {
                const poolId = div.getAttribute('data-pool-id');
                if (poolId !== '1') {
                    removeNodePool(poolId);
                }
            });
            
            // Configure default node pool for H100 GPUs
            const defaultPool = document.querySelector('.node-pool[data-pool-id="1"]');
            if (defaultPool) {
                defaultPool.querySelector('.node-count').value = 2;
                defaultPool.querySelector('.node-gpu-count').value = 4;
                defaultPool.querySelector('.node-gpu-type').value = 'H100-80G';
                defaultPool.querySelector('.node-cpu').value = 64;
                defaultPool.querySelector('.node-memory').value = 256;
                defaultPool.querySelector('.node-pool-label').value = 'h100-pool';
                
                // Update the summary
                updateNodePoolSummary(defaultPool);
            }
            
            // Update the cluster with new node pool configuration
            updateNodePoolsFromUI();
            
            // Disable CPU-only mode if enabled
            const cpuOnlyToggle = document.getElementById('cpu-only-toggle');
            if (cpuOnlyToggle.checked) {
                cpuOnlyToggle.checked = false;
                cpuOnlyToggle.dispatchEvent(new Event('change'));
            }
            
            // Guide the user on next steps
            console.log("Resource Constraints Test configuration applied.");
            console.log("-----------------------------------------------------------");
            console.log("To complete the resource constraints test:");
            console.log("1. Deploy Mixtral 8x7B with 2 replicas (using 2 GPUs each)");
            console.log("2. Deploy Llama 3.1 70B with 2 replicas (using 2 GPUs each)");
            console.log("3. Try to deploy one more Mixtral replica - it should go to pending");
            console.log("4. Delete one pod to see the pending pod get scheduled");
            console.log("-----------------------------------------------------------");
        }
        
        // Check if there's a test parameter in the URL when page loads
        function checkForUrlTestParameter() {
            const urlParams = new URLSearchParams(window.location.search);
            const testParam = urlParams.get('test');
            
            if (testParam) {
                console.log(`Found test parameter in URL: ${testParam}`);
                // Apply the test configuration after a short delay to ensure the page is fully loaded
                setTimeout(() => {
                    applyTestConfiguration(testParam);
                }, 500);
            }
        }
        
        // Start the application when DOM is ready
        document.addEventListener('DOMContentLoaded', () => {
            init();
            setupTestExampleHandlers();
            checkForUrlTestParameter();
        });
        
        // Initialize dark mode based on user preference
        if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
            document.documentElement.classList.add('dark');
        }
        
        window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {
            if (event.matches) {
                document.documentElement.classList.add('dark');
            } else {
                document.documentElement.classList.remove('dark');
            }
        });
    </script>


</body></html>